import os
import sys
import json
import time
import torch
import threading
from datetime import datetime
from colorama import init, Fore, Back, Style

torch.cuda.empty_cache()
# é™åˆ¶PyTorchå†…å­˜åˆ†é…ç­–ç•¥ï¼Œå‡å°‘å†…å­˜ç¢ç‰‡
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'

from config.config import (
    load_config, save_config, get_default_config,
    load_low_memory_config, load_high_memory_config, load_rtx_4090_config,
    create_4gb_config, create_6gb_config, create_8gb_config, create_12gb_config,
    auto_config_by_gpu_memory
)

# åˆå§‹åŒ–colorama
init(autoreset=True)

# ğŸš¨ é¢å¤–çš„å†…å­˜ä¼˜åŒ–è®¾ç½®
if torch.cuda.is_available():
    torch.cuda.set_per_process_memory_fraction(0.85)  # åªä½¿ç”¨85%æ˜¾å­˜
    torch.cuda.reset_peak_memory_stats()
    print(f"{Fore.GREEN}ğŸ”§ æ§åˆ¶å°è®­ç»ƒå™¨å†…å­˜ä¼˜åŒ–é…ç½®å·²å¯ç”¨: max_split_size_mb=128, æ˜¾å­˜é™åˆ¶=85%{Style.RESET_ALL}")

class GPUOptimizer:
    """GPUä¼˜åŒ–å™¨ - ä¸“é—¨é’ˆå¯¹RTX 4090ç­‰é«˜ç«¯GPUçš„ä¼˜åŒ–"""
    
    def __init__(self):
        # ğŸš¨ åˆå§‹åŒ–æ—¶ç«‹å³æ‰§è¡Œå†…å­˜ä¼˜åŒ–
        torch.cuda.empty_cache()
        
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.tf32_enabled = False
        self.compile_enabled = False
        
    def enable_tf32(self):
        """å¯ç”¨TF32åŠ é€Ÿï¼ˆRTX 30/40ç³»åˆ—ï¼‰"""
        if torch.cuda.is_available():
            torch.backends.cuda.matmul.allow_tf32 = True
            torch.backends.cudnn.allow_tf32 = True
            self.tf32_enabled = True
            print(f"{Fore.GREEN}âœ… TF32åŠ é€Ÿå·²å¯ç”¨{Style.RESET_ALL}")
        else:
            print(f"{Fore.RED}âŒ CUDAä¸å¯ç”¨ï¼Œæ— æ³•å¯ç”¨TF32{Style.RESET_ALL}")
    
    def disable_tf32(self):
        """ç¦ç”¨TF32åŠ é€Ÿ"""
        if torch.cuda.is_available():
            torch.backends.cuda.matmul.allow_tf32 = False
            torch.backends.cudnn.allow_tf32 = False
            self.tf32_enabled = False
            print(f"{Fore.YELLOW}âš ï¸  TF32åŠ é€Ÿå·²ç¦ç”¨{Style.RESET_ALL}")
        else:
            print(f"{Fore.RED}âŒ CUDAä¸å¯ç”¨ï¼Œæ— éœ€ç¦ç”¨TF32{Style.RESET_ALL}")
    
    def enable_compile(self):
        """å¯ç”¨æ¨¡å‹ç¼–è¯‘ä¼˜åŒ–ï¼ˆPyTorch 2.0+ï¼‰"""
        try:
            if hasattr(torch, 'compile'):
                self.compile_enabled = True
                print(f"{Fore.GREEN}âœ… æ¨¡å‹ç¼–è¯‘ä¼˜åŒ–å·²å¯ç”¨{Style.RESET_ALL}")
            else:
                print(f"{Fore.YELLOW}âš ï¸  å½“å‰PyTorchç‰ˆæœ¬ä¸æ”¯æŒæ¨¡å‹ç¼–è¯‘{Style.RESET_ALL}")
        except Exception as e:
            print(f"{Fore.RED}âŒ å¯ç”¨æ¨¡å‹ç¼–è¯‘å¤±è´¥: {e}{Style.RESET_ALL}")
    
    def disable_compile(self):
        """ç¦ç”¨æ¨¡å‹ç¼–è¯‘ä¼˜åŒ–"""
        self.compile_enabled = False
        print(f"{Fore.YELLOW}âš ï¸  æ¨¡å‹ç¼–è¯‘ä¼˜åŒ–å·²ç¦ç”¨{Style.RESET_ALL}")
    
    def optimize_model(self, model):
        """ä¼˜åŒ–æ¨¡å‹"""
        if self.compile_enabled and hasattr(torch, 'compile'):
            try:
                model = torch.compile(model, mode='max-autotune')
                print(f"{Fore.GREEN}âœ… æ¨¡å‹ç¼–è¯‘ä¼˜åŒ–å®Œæˆ{Style.RESET_ALL}")
            except Exception as e:
                print(f"{Fore.YELLOW}âš ï¸  æ¨¡å‹ç¼–è¯‘å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ¨¡å‹: {e}{Style.RESET_ALL}")
        return model
    
    def get_optimal_batch_size(self, model, input_shape, max_memory_gb=20):
        """è‡ªåŠ¨è®¡ç®—æœ€ä¼˜æ‰¹æ¬¡å¤§å°"""
        if not torch.cuda.is_available():
            return 1
        
        try:
            # æ¸…ç©ºç¼“å­˜
            torch.cuda.empty_cache()
            
            # æµ‹è¯•ä¸åŒæ‰¹æ¬¡å¤§å°
            batch_sizes = [1, 2, 4, 6, 8, 12, 16, 20, 24]
            optimal_batch_size = 1
            
            for batch_size in batch_sizes:
                try:
                    # åˆ›å»ºæµ‹è¯•è¾“å…¥
                    test_input = torch.randn(batch_size, *input_shape[1:]).cuda()
                    
                    # å‰å‘ä¼ æ’­æµ‹è¯•
                    with torch.no_grad():
                        _ = model(test_input)
                    
                    # æ£€æŸ¥æ˜¾å­˜ä½¿ç”¨
                    memory_used = torch.cuda.memory_allocated() / 1024**3  # GB
                    if memory_used < max_memory_gb * 0.8:  # ä¿ç•™20%ä½™é‡
                        optimal_batch_size = batch_size
                    else:
                        break
                        
                except RuntimeError as e:
                    if "out of memory" in str(e):
                        break
                    else:
                        raise e
                finally:
                    torch.cuda.empty_cache()
            
            print(f"{Fore.GREEN}ğŸ¯ æ¨èæ‰¹æ¬¡å¤§å°: {optimal_batch_size}{Style.RESET_ALL}")
            return optimal_batch_size
            
        except Exception as e:
            print(f"{Fore.YELLOW}âš ï¸  è‡ªåŠ¨æ‰¹æ¬¡å¤§å°è®¡ç®—å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤å€¼{Style.RESET_ALL}")
            return 4

class ModelCompatibilityChecker:
    """æ¨¡å‹å…¼å®¹æ€§æ£€æŸ¥å™¨"""
    
    def __init__(self):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    def check_model_compatibility(self, checkpoint_path, new_config):
        """æ£€æŸ¥æ¨¡å‹å…¼å®¹æ€§"""
        try:
            # åŠ è½½æ£€æŸ¥ç‚¹
            checkpoint = torch.load(checkpoint_path, map_location=self.device, weights_only=False)
            old_state_dict = checkpoint['generator_state_dict']
            
            # æå–æ—§æ¨¡å‹é…ç½®
            old_config = self._extract_model_config_from_state_dict(old_state_dict)
            
            # è·å–æ–°é…ç½®
            new_num_blocks = new_config['model']['num_blocks']
            new_num_features = new_config['model']['num_features']
            
            print(f"{Fore.YELLOW}æ—§æ¨¡å‹é…ç½®: blocks={old_config['num_blocks']}, features={old_config['num_features']}{Style.RESET_ALL}")
            print(f"{Fore.YELLOW}æ–°æ¨¡å‹é…ç½®: blocks={new_num_blocks}, features={new_num_features}{Style.RESET_ALL}")
            
            # æ£€æŸ¥å…¼å®¹æ€§
            if old_config['num_blocks'] == new_num_blocks and old_config['num_features'] == new_num_features:
                print(f"{Fore.GREEN}âœ… æ¨¡å‹é…ç½®å®Œå…¨å…¼å®¹{Style.RESET_ALL}")
                return True, "å®Œå…¨å…¼å®¹"
            else:
                print(f"{Fore.YELLOW}âš ï¸  æ¨¡å‹é…ç½®ä¸å…¼å®¹ï¼Œéœ€è¦è°ƒæ•´{Style.RESET_ALL}")
                return False, f"é…ç½®ä¸åŒ¹é…: æ—§æ¨¡å‹({old_config['num_blocks']}, {old_config['num_features']}) vs æ–°é…ç½®({new_num_blocks}, {new_num_features})"
                
        except Exception as e:
            return False, f"æ£€æŸ¥å¤±è´¥: {str(e)}"
    
    def _extract_model_config_from_state_dict(self, state_dict):
        """ä»çŠ¶æ€å­—å…¸ä¸­æå–æ¨¡å‹é…ç½®"""
        # é€šè¿‡åˆ†ææƒé‡å½¢çŠ¶æ¥æ¨æ–­æ¨¡å‹å‚æ•°
        num_features = 64  # é»˜è®¤å€¼
        num_blocks = 6     # é»˜è®¤å€¼
        
        # åˆ†æç¬¬ä¸€ä¸ªå·ç§¯å±‚æ¥ç¡®å®šç‰¹å¾æ•°
        if 'conv_first.weight' in state_dict:
            num_features = state_dict['conv_first.weight'].shape[0]
            print(f"ğŸ” ä»conv_first.weightæ£€æµ‹åˆ°ç‰¹å¾æ•°: {num_features}")
        
        # è®¡ç®—RRDBå—çš„æ•°é‡
        rrdb_count = 0
        for key in state_dict.keys():
            if key.startswith('rrdb_blocks.') and '.dense1.conv1.weight' in key:
                # æå–å—ç´¢å¼•
                import re
                match = re.match(r'rrdb_blocks\.(\d+)\.dense1\.conv1\.weight', key)
                if match:
                    block_idx = int(match.group(1))
                    rrdb_count = max(rrdb_count, block_idx + 1)
        
        if rrdb_count > 0:
            num_blocks = rrdb_count
            print(f"ğŸ” ä»rrdb_blocksæ£€æµ‹åˆ°å—æ•°: {num_blocks}")
        
        print(f"ğŸ” æå–çš„æ¨¡å‹é…ç½®: {num_blocks}å—, {num_features}ç‰¹å¾")
        return {
            'num_blocks': num_blocks,
            'num_features': num_features
        }

    def adjust_checkpoint_for_new_config(self, checkpoint_path, new_config, output_path=None):
        """è°ƒæ•´æ£€æŸ¥ç‚¹ä»¥é€‚åº”æ–°é…ç½®"""
        try:
            print(f"{Fore.CYAN}ğŸ”§ æ­£åœ¨è°ƒæ•´æ¨¡å‹æ£€æŸ¥ç‚¹...{Style.RESET_ALL}")
            
            # åŠ è½½æ£€æŸ¥ç‚¹
            checkpoint = torch.load(checkpoint_path, map_location=self.device, weights_only=False)
            old_state_dict = checkpoint['generator_state_dict']
            
            # æ˜¾ç¤ºåŸå§‹æ£€æŸ¥ç‚¹ä¿¡æ¯
            if 'epoch' in checkpoint:
                print(f"{Fore.CYAN}åŸå§‹æ£€æŸ¥ç‚¹è®­ç»ƒè½®æ•°: {checkpoint['epoch']}{Style.RESET_ALL}")
            if 'best_psnr' in checkpoint:
                print(f"{Fore.CYAN}åŸå§‹æ£€æŸ¥ç‚¹æœ€ä½³PSNR: {checkpoint['best_psnr']:.4f} dB{Style.RESET_ALL}")
            
            # æå–é…ç½®ä¿¡æ¯
            old_config = self._extract_model_config_from_state_dict(old_state_dict)
            new_model_config = new_config['model']
            
            print(f"{Fore.CYAN}åŸå§‹æ¨¡å‹é…ç½®: {old_config['num_blocks']}å—, {old_config['num_features']}ç‰¹å¾{Style.RESET_ALL}")
            print(f"{Fore.CYAN}ç›®æ ‡æ¨¡å‹é…ç½®: {new_model_config['num_blocks']}å—, {new_model_config['num_features']}ç‰¹å¾{Style.RESET_ALL}")
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒæ•´
            if (old_config['num_blocks'] == new_model_config['num_blocks'] and 
                old_config['num_features'] == new_model_config['num_features']):
                print(f"{Fore.GREEN}âœ… æ¨¡å‹é…ç½®å·²åŒ¹é…ï¼Œæ— éœ€è°ƒæ•´{Style.RESET_ALL}")
                return True, checkpoint_path
            
            # åˆ›å»ºæ–°æ¨¡å‹ä»¥è·å–ç›®æ ‡çŠ¶æ€å­—å…¸ç»“æ„
            from src.models.esrgan import LiteRealESRGAN
            new_model = LiteRealESRGAN(
                num_blocks=new_model_config['num_blocks'],
                num_features=new_model_config['num_features']
            )
            new_model_state_dict = new_model.state_dict()
            
            # è°ƒæ•´æƒé‡
            adjusted_state_dict = self._adjust_weights(old_state_dict, new_model_state_dict, old_config, new_model_config)
            
            # æ›´æ–°æ£€æŸ¥ç‚¹ - ä¿ç•™æ‰€æœ‰åŸå§‹å…ƒæ•°æ®
            checkpoint['generator_state_dict'] = adjusted_state_dict
            
            # ç”Ÿæˆè¾“å‡ºè·¯å¾„
            if output_path is None:
                base_name = os.path.splitext(os.path.basename(checkpoint_path))[0]
                output_path = os.path.join(
                    os.path.dirname(checkpoint_path),
                    f"{base_name}_adjusted.pth"
                )
            
            # ä¿å­˜è°ƒæ•´åçš„æ£€æŸ¥ç‚¹
            torch.save(checkpoint, output_path)
            print(f"{Fore.GREEN}âœ… è°ƒæ•´åçš„æ¨¡å‹å·²ä¿å­˜: {os.path.basename(output_path)}{Style.RESET_ALL}")
            
            # æ˜¾ç¤ºè°ƒæ•´åçš„æ£€æŸ¥ç‚¹ä¿¡æ¯
            if 'epoch' in checkpoint:
                print(f"{Fore.GREEN}âœ… ä¿ç•™è®­ç»ƒè½®æ•°: {checkpoint['epoch']}{Style.RESET_ALL}")
            if 'best_psnr' in checkpoint:
                print(f"{Fore.GREEN}âœ… ä¿ç•™æœ€ä½³PSNR: {checkpoint['best_psnr']:.4f} dB{Style.RESET_ALL}")
            
            return True, output_path
            
        except Exception as e:
            print(f"{Fore.RED}âŒ æ¨¡å‹è°ƒæ•´å¤±è´¥: {str(e)}{Style.RESET_ALL}")
            import traceback
            traceback.print_exc()
            return False, str(e)

    def _adjust_weights(self, old_state_dict, new_model_state_dict, old_config, new_config):
        """è°ƒæ•´æƒé‡ä»¥åŒ¹é…æ–°æ¨¡å‹ç»“æ„"""
        adjusted_state_dict = {}
        
        print(f"{Fore.CYAN}ğŸ”§ å¼€å§‹æƒé‡è°ƒæ•´...{Style.RESET_ALL}")
        print(f"ğŸ”§ ä» {old_config['num_blocks']}å—/{old_config['num_features']}ç‰¹å¾ -> {new_config['num_blocks']}å—/{new_config['num_features']}ç‰¹å¾")
        
        # è·å–é…ç½®ä¿¡æ¯
        old_blocks = old_config['num_blocks']
        old_features = old_config['num_features']
        new_blocks = new_config['num_blocks']
        new_features = new_config['num_features']
        
        # å¤„ç†æ‰€æœ‰æ–°æ¨¡å‹éœ€è¦çš„æƒé‡
        for key, new_weight in new_model_state_dict.items():
            if key in old_state_dict:
                old_weight = old_state_dict[key]
                if old_weight.shape == new_weight.shape:
                    # å½¢çŠ¶ç›¸åŒï¼Œç›´æ¥å¤åˆ¶
                    adjusted_state_dict[key] = old_weight.clone()
                    print(f"âœ… {key}: ç›´æ¥å¤åˆ¶ {old_weight.shape}")
                else:
                    # å½¢çŠ¶ä¸åŒï¼Œéœ€è¦è°ƒæ•´
                    adjusted_weight = self._smart_resize_weight(old_weight, new_weight.shape, key)
                    adjusted_state_dict[key] = adjusted_weight
                    print(f"ğŸ”§ {key}: è°ƒæ•´ {old_weight.shape} -> {new_weight.shape}")
            else:
                # æ–°å¢çš„æƒé‡
                if self._is_new_rrdb_block(key, old_blocks):
                    # å¯¹äºæ–°å¢çš„RRDBå—ï¼Œå¤åˆ¶ç°æœ‰å—çš„æƒé‡
                    source_key = self._get_source_block_key(key, old_state_dict, old_blocks)
                    if source_key and source_key in old_state_dict:
                        source_weight = old_state_dict[source_key]
                        if source_weight.shape == new_weight.shape:
                            # æ·»åŠ å°çš„éšæœºå™ªå£°ä»¥é¿å…å®Œå…¨ç›¸åŒ
                            noise = torch.randn_like(source_weight) * 0.01
                            adjusted_state_dict[key] = source_weight + noise
                            print(f"ğŸ”„ {key}: å¤åˆ¶è‡ª {source_key} (æ·»åŠ å™ªå£°)")
                        else:
                            # éœ€è¦è°ƒæ•´å°ºå¯¸åå¤åˆ¶
                            adjusted_weight = self._smart_resize_weight(source_weight, new_weight.shape, key)
                            noise = torch.randn_like(adjusted_weight) * 0.01
                            adjusted_state_dict[key] = adjusted_weight + noise
                            print(f"ğŸ”„ {key}: ä» {source_key} è°ƒæ•´å¹¶æ·»åŠ å™ªå£° {source_weight.shape} -> {new_weight.shape}")
                    else:
                        # éšæœºåˆå§‹åŒ–
                        adjusted_state_dict[key] = self._initialize_weight(new_weight)
                        print(f"ğŸ² {key}: éšæœºåˆå§‹åŒ– {new_weight.shape}")
                else:
                    # å…¶ä»–æ–°å¢æƒé‡ï¼Œéšæœºåˆå§‹åŒ–
                    adjusted_state_dict[key] = self._initialize_weight(new_weight)
                    print(f"ğŸ² {key}: éšæœºåˆå§‹åŒ– {new_weight.shape}")
        
        print(f"{Fore.GREEN}âœ… æƒé‡è°ƒæ•´å®Œæˆï¼Œå…±å¤„ç† {len(adjusted_state_dict)} ä¸ªæƒé‡{Style.RESET_ALL}")
        return adjusted_state_dict

    def smart_adjust_features_enhanced(self, checkpoint_path, new_features, use_progressive=True, steps=3):
        """
        å¢å¼ºç‰ˆæ™ºèƒ½ç‰¹å¾æ•°è°ƒæ•´ï¼Œæ”¯æŒæ¸è¿›å¼è°ƒæ•´å’Œé”™è¯¯æ¢å¤
        """
        try:
            print(f"{Fore.CYAN}ğŸš€ å¢å¼ºç‰ˆæ™ºèƒ½ç‰¹å¾æ•°è°ƒæ•´{Style.RESET_ALL}")
            
            # 1. æ£€æµ‹å½“å‰ç‰¹å¾æ•°
            detected_config = self._detect_checkpoint_config(checkpoint_path)
            if not detected_config:
                return False, "æ— æ³•æ£€æµ‹æ£€æŸ¥ç‚¹é…ç½®"
            
            old_features = detected_config['num_features']
            print(f"ğŸ“Š æ£€æµ‹åˆ°å½“å‰ç‰¹å¾æ•°: {old_features}")
            print(f"ğŸ¯ ç›®æ ‡ç‰¹å¾æ•°: {new_features}")
            
            if old_features == new_features:
                print(f"{Fore.YELLOW}âš ï¸  ç‰¹å¾æ•°å·²ç»æ˜¯ {new_features}ï¼Œæ— éœ€è°ƒæ•´{Style.RESET_ALL}")
                return True, checkpoint_path
            
            # 2. å¤‡ä»½åŸå§‹æ£€æŸ¥ç‚¹
            backup_path = checkpoint_path.replace('.pth', '_backup.pth')
            import shutil
            shutil.copy2(checkpoint_path, backup_path)
            print(f"ğŸ’¾ å·²å¤‡ä»½åŸå§‹æ£€æŸ¥ç‚¹: {os.path.basename(backup_path)}")
            
            # 3. é€‰æ‹©è°ƒæ•´ç­–ç•¥
            feature_diff = abs(new_features - old_features)
            
            if use_progressive and feature_diff > 20:
                # å¤§å¹…è°ƒæ•´ä½¿ç”¨æ¸è¿›å¼
                print(f"ğŸ“ˆ ç‰¹å¾æ•°å˜åŒ–è¾ƒå¤§({feature_diff})ï¼Œä½¿ç”¨æ¸è¿›å¼è°ƒæ•´")
                success, result = self._progressive_feature_adjust(checkpoint_path, old_features, new_features, steps)
            else:
                # å°å¹…è°ƒæ•´ä½¿ç”¨ç›´æ¥è°ƒæ•´
                print(f"ğŸ”§ ç‰¹å¾æ•°å˜åŒ–è¾ƒå°({feature_diff})ï¼Œä½¿ç”¨ç›´æ¥è°ƒæ•´")
                success, result = self._smart_adjust_features(checkpoint_path, old_features, new_features)
            
            if success:
                # 4. æœ€ç»ˆéªŒè¯
                if self._validate_rrdb_structure(torch.load(result, weights_only=False)['generator_state_dict'], new_features):
                    print(f"{Fore.GREEN}ğŸ‰ æ™ºèƒ½ç‰¹å¾æ•°è°ƒæ•´æˆåŠŸå®Œæˆ!{Style.RESET_ALL}")
                    return True, result
                else:
                    print(f"{Fore.RED}âŒ æœ€ç»ˆéªŒè¯å¤±è´¥{Style.RESET_ALL}")
                    return False, "æœ€ç»ˆéªŒè¯å¤±è´¥"
            else:
                print(f"{Fore.RED}âŒ è°ƒæ•´è¿‡ç¨‹å¤±è´¥: {result}{Style.RESET_ALL}")
                return False, result
                
        except Exception as e:
            print(f"{Fore.RED}âŒ å¢å¼ºç‰ˆè°ƒæ•´å¤±è´¥: {str(e)}{Style.RESET_ALL}")
            import traceback
            traceback.print_exc()
            return False, str(e)

    def _detect_checkpoint_config(self, checkpoint_path):
        """æ£€æµ‹æ£€æŸ¥ç‚¹çš„é…ç½®ä¿¡æ¯"""
        try:
            checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)
            if 'generator_state_dict' in checkpoint:
                return self._extract_model_config_from_state_dict(checkpoint['generator_state_dict'])
            return self._extract_model_config_from_state_dict(checkpoint)
        except Exception as e:
            print(f"{Fore.RED}âŒ æ£€æµ‹æ£€æŸ¥ç‚¹é…ç½®å¤±è´¥: {str(e)}{Style.RESET_ALL}")
            return None

    def _validate_rrdb_structure(self, state_dict, target_features):
        """éªŒè¯RRDBç»“æ„æ˜¯å¦ç¬¦åˆç›®æ ‡ç‰¹å¾æ•°"""
        try:
            # æ£€æŸ¥ç¬¬ä¸€ä¸ªå·ç§¯å±‚
            if 'conv_first.weight' in state_dict:
                if state_dict['conv_first.weight'].shape[0] != target_features:
                    print(f"{Fore.RED}âŒ conv_first.weight ç‰¹å¾æ•°ä¸åŒ¹é…: {state_dict['conv_first.weight'].shape[0]} != {target_features}{Style.RESET_ALL}")
                    return False
            
            # æ£€æŸ¥RRDBå—çš„ç¬¬ä¸€ä¸ªå·ç§¯å±‚
            for key in state_dict:
                if key.startswith('rrdb_blocks.') and '.dense1.conv1.weight' in key:
                    if state_dict[key].shape[1] != target_features:
                        print(f"{Fore.RED}âŒ {key} è¾“å…¥é€šé“ä¸åŒ¹é…: {state_dict[key].shape[1]} != {target_features}{Style.RESET_ALL}")
                        return False
            return True
        except Exception as e:
            print(f"{Fore.RED}âŒ éªŒè¯RRDBç»“æ„å¤±è´¥: {str(e)}{Style.RESET_ALL}")
            return False

    def _verify_feature_adjustment(self, checkpoint_path, target_features):
        """éªŒè¯ç‰¹å¾æ•°è°ƒæ•´ç»“æœ"""
        try:
            checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)
            state_dict = checkpoint['generator_state_dict']
            return self._validate_rrdb_structure(state_dict, target_features)
        except Exception as e:
            print(f"{Fore.RED}âŒ éªŒè¯è°ƒæ•´ç»“æœå¤±è´¥: {str(e)}{Style.RESET_ALL}")
            return False

    def _smart_adjust_features(self, checkpoint_path, old_features, new_features):
        """æ™ºèƒ½è°ƒæ•´ç‰¹å¾æ•°çš„æ ¸å¿ƒæ–¹æ³•"""
        try:
            print(f"{Fore.CYAN}ğŸš€ å¼€å§‹æ™ºèƒ½ç‰¹å¾æ•°è°ƒæ•´: {old_features} -> {new_features}{Style.RESET_ALL}")
            
            # åŠ è½½æ£€æŸ¥ç‚¹
            checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)
            old_state_dict = checkpoint['generator_state_dict']
            
            # åˆ›å»ºç›®æ ‡æ¨¡å‹
            from src.models.esrgan import LiteRealESRGAN
            target_model = LiteRealESRGAN(
                num_blocks=6,  # å‡è®¾å—æ•°ä¸å˜
                num_features=new_features
            )
            new_state_dict = target_model.state_dict()
            
            # è°ƒæ•´æƒé‡
            adjusted_state_dict = self._adjust_features_weights(old_state_dict, new_state_dict, old_features, new_features)
            
            # æ›´æ–°æ£€æŸ¥ç‚¹
            checkpoint['generator_state_dict'] = adjusted_state_dict
            
            # ä¿å­˜ç»“æœ
            output_path = checkpoint_path.replace('.pth', f'_features_{new_features}.pth')
            torch.save(checkpoint, output_path)
            print(f"{Fore.GREEN}âœ… ç‰¹å¾æ•°è°ƒæ•´å®Œæˆï¼Œä¿å­˜è‡³: {os.path.basename(output_path)}{Style.RESET_ALL}")
            
            return True, output_path
            
        except Exception as e:
            print(f"{Fore.RED}âŒ æ™ºèƒ½ç‰¹å¾æ•°è°ƒæ•´å¤±è´¥: {str(e)}{Style.RESET_ALL}")
            return False, str(e)
    
    def _adjust_features_weights(self, old_state_dict, new_state_dict, old_features, new_features):
        """
        è°ƒæ•´æƒé‡ä»¥åŒ¹é…æ–°çš„ç‰¹å¾æ•°
        æ”¯æŒæ‰©å±•å’Œæ”¶ç¼©ç‰¹å¾æ•°ï¼Œç‰¹åˆ«é’ˆå¯¹RRDBå¯†é›†è¿æ¥å±‚ä¼˜åŒ–
        """
        adjusted_state_dict = {}
        
        print(f"{Fore.CYAN}ğŸ”§ æƒé‡è°ƒæ•´è¯¦æƒ…: {old_features} -> {new_features} ç‰¹å¾æ•°{Style.RESET_ALL}")
        
        for key, new_weight in new_state_dict.items():
            if key in old_state_dict:
                old_weight = old_state_dict[key]
                
                try:
                    if old_weight.shape == new_weight.shape:
                        # å½¢çŠ¶ç›¸åŒï¼Œç›´æ¥å¤åˆ¶
                        adjusted_state_dict[key] = old_weight.clone()
                        print(f"âœ… {key}: ç›´æ¥å¤åˆ¶ {old_weight.shape}")
                        
                    elif 'conv' in key and 'weight' in key and len(old_weight.shape) == 4:
                        # å·ç§¯å±‚æƒé‡éœ€è¦ç‰¹æ®Šå¤„ç†
                        if 'rrdb_blocks' in key and 'dense' in key:
                            # RRDBå¯†é›†è¿æ¥å±‚
                            adjusted_weight = self._adjust_rrdb_dense_weight(old_weight, new_weight, key, old_features, new_features)
                            adjusted_state_dict[key] = adjusted_weight
                            print(f"ğŸ”— {key}: RRDBå¯†é›†è°ƒæ•´ {old_weight.shape} -> {new_weight.shape}")
                        elif self._is_direct_feature_related(key, old_weight, new_weight, old_features, new_features):
                            # ç›´æ¥ç‰¹å¾ç›¸å…³çš„æƒé‡
                            adjusted_weight = self._adjust_direct_feature_weight(old_weight, new_weight, key, old_features, new_features)
                            adjusted_state_dict[key] = adjusted_weight
                            print(f"ğŸ”§ {key}: ç›´æ¥ç‰¹å¾è°ƒæ•´ {old_weight.shape} -> {new_weight.shape}")
                        else:
                            # å…¶ä»–å·ç§¯å±‚ï¼Œä½¿ç”¨é€šç”¨è°ƒæ•´
                            adjusted_weight = self._adjust_general_conv_weight(old_weight, new_weight.shape, key)
                            adjusted_state_dict[key] = adjusted_weight
                            print(f"ğŸ”„ {key}: é€šç”¨è°ƒæ•´ {old_weight.shape} -> {new_weight.shape}")
                            
                    elif 'bias' in key and len(old_weight.shape) == 1:
                        # åç½®è°ƒæ•´
                        if self._is_direct_feature_related(key, old_weight, new_weight, old_features, new_features):
                            adjusted_weight = self._adjust_feature_bias(old_weight, new_weight, old_features, new_features)
                            adjusted_state_dict[key] = adjusted_weight
                            print(f"ğŸ”§ {key}: ç‰¹å¾åç½®è°ƒæ•´ {old_weight.shape} -> {new_weight.shape}")
                        else:
                            adjusted_state_dict[key] = old_weight.clone()
                            print(f"âœ… {key}: åç½®ç›´æ¥å¤åˆ¶ {old_weight.shape}")
                    else:
                        # å…¶ä»–ç±»å‹æƒé‡ï¼Œå°è¯•é€šç”¨è°ƒæ•´
                        adjusted_weight = self._adjust_general_weight(old_weight, new_weight.shape, key)
                        adjusted_state_dict[key] = adjusted_weight
                        print(f"ğŸ”„ {key}: å…¶ä»–è°ƒæ•´ {old_weight.shape} -> {new_weight.shape}")
                        
                except Exception as e:
                    print(f"{Fore.RED}ğŸ›‘ è°ƒæ•´å¤±è´¥è¯¦æƒ…:{Style.RESET_ALL}")
                    print(f"   æ“ä½œ: {key}")
                    print(f"   ç›®æ ‡å½¢çŠ¶: {new_weight.shape}")
                    print(f"   åŸå§‹å½¢çŠ¶: {old_weight.shape}")
                    print(f"   å±‚ç±»å‹: {'RRDBå¯†é›†å±‚' if 'dense' in key else 'æ™®é€šå·ç§¯å±‚'}")
                    print(f"   é”™è¯¯: {str(e)}")
                    raise
            else:
                # æ–°å¢çš„æƒé‡ï¼Œéšæœºåˆå§‹åŒ–
                adjusted_state_dict[key] = self._initialize_weight_smart(new_weight, key)
                print(f"ğŸ² {key}: éšæœºåˆå§‹åŒ– {new_weight.shape}")
        
        print(f"{Fore.GREEN}âœ… æƒé‡è°ƒæ•´å®Œæˆï¼Œå…±å¤„ç† {len(adjusted_state_dict)} ä¸ªæƒé‡{Style.RESET_ALL}")
        return adjusted_state_dict
    
    def _is_direct_feature_related(self, key, old_weight, new_weight, old_features, new_features):
        """åˆ¤æ–­æ˜¯å¦æ˜¯ç›´æ¥ç‰¹å¾ç›¸å…³çš„æƒé‡"""
        if 'conv' in key and 'weight' in key and len(old_weight.shape) == 4:
            old_out, old_in, _, _ = old_weight.shape
            new_out, new_in, _, _ = new_weight.shape
            
            # æ£€æŸ¥è¾“å‡ºæˆ–è¾“å…¥é€šé“æ˜¯å¦ç›´æ¥åŒ¹é…ç‰¹å¾æ•°å˜åŒ–
            return (old_out == old_features and new_out == new_features) or \
                   (old_in == old_features and new_in == new_features)
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯åç½®ä¸”é•¿åº¦åŒ¹é…ç‰¹å¾æ•°å˜åŒ–
        if 'bias' in key and len(old_weight.shape) == 1:
            return old_weight.shape[0] == old_features and new_weight.shape[0] == new_features
        
        return False
    
    def _adjust_rrdb_dense_weight(self, old_weight, new_weight, key, old_features, new_features):
        """
        ä¸“é—¨å¤„ç†RRDBå¯†é›†è¿æ¥å±‚çš„æƒé‡è°ƒæ•´
        ä¿®å¤é€šé“æ•°è®¡ç®—é”™è¯¯ï¼Œå¢åŠ åŠ¨æ€å¢é•¿ç‡è®¡ç®—
        """
        old_out, old_in, old_h, old_w = old_weight.shape
        new_out, new_in, new_h, new_w = new_weight.shape
        
        # è§£æå¯†é›†å±‚ä¿¡æ¯
        parts = key.split('.')
        block_idx = int(parts[1]) if len(parts) > 1 else 0
        dense_part = parts[2] if len(parts) > 2 else ""
        conv_part = parts[3] if len(parts) > 3 else ""
        
        # æå–denseå’Œconvçš„ç´¢å¼•
        try:
            dense_idx = int(dense_part.replace('dense', ''))
            conv_idx = int(conv_part.replace('conv', ''))
        except (ValueError, IndexError):
            print(f"{Fore.YELLOW}âš ï¸  æ— æ³•è§£æå±‚ç´¢å¼•ï¼Œä½¿ç”¨é»˜è®¤è®¡ç®—: {key}{Style.RESET_ALL}")
            dense_idx = 1
            conv_idx = 1
        
        # è®¡ç®—å½“å‰å±‚åœ¨å¯†é›†å—ä¸­çš„åºå·
        layer_order = (dense_idx - 1) * 5 + conv_idx
        print(f"    ğŸ”— RRDB Block{block_idx} Dense{dense_idx} Conv{conv_idx} (åºå·:{layer_order})")
        
        # åŠ¨æ€è®¡ç®—å¢é•¿ç‡ï¼ˆä»å®é™…é€šé“æ•°åæ¨ï¼‰
        if layer_order == 1:
            # ç¬¬ä¸€å±‚çš„è¾“å…¥é€šé“åº”è¯¥ç­‰äºåŸºç¡€ç‰¹å¾æ•°
            growth_rate = 32  # é»˜è®¤ä¸º32ï¼Œç¬¬ä¸€å±‚ä¸ä¾èµ–å¢é•¿ç‡
        else:
            # ä»å®é™…é€šé“æ•°åæ¨å¢é•¿ç‡
            growth_rate = max(1, (old_in - old_features) // (layer_order - 1))
        print(f"    ğŸ”¢ åŠ¨æ€è®¡ç®—å¢é•¿ç‡: {growth_rate}")
        
        # è®¡ç®—é¢„æœŸé€šé“æ•°
        expected_old_in = old_features + growth_rate * (layer_order - 1)
        expected_new_in = new_features + growth_rate * (layer_order - 1)
        print(f"    ğŸ“Š é€šé“è®¡ç®—: {old_features}+{growth_rate}Ã—{layer_order-1} = {expected_old_in}")
        print(f"    ğŸ¯ ç›®æ ‡é€šé“: {new_features}+{growth_rate}Ã—{layer_order-1} = {expected_new_in}")
        
        # éªŒè¯å®é™…è¾“å…¥é€šé“æ•°
        if old_in != expected_old_in:
            print(f"    âš ï¸  é€šé“æ•°å¼‚å¸¸: å®é™…({old_in}) != é¢„æœŸ({expected_old_in})")
            # åŸºäºå®é™…å€¼é‡æ–°è®¡ç®—å¢é•¿ç‡
            growth_rate = max(1, (old_in - old_features) // max(1, layer_order - 1))
            expected_new_in = new_features + growth_rate * (layer_order - 1)
            print(f"    ğŸ”„ ä¿®æ­£å¢é•¿ç‡: {growth_rate}, ä¿®æ­£ç›®æ ‡é€šé“: {expected_new_in}")
        
        # ç¡®ä¿ç›®æ ‡è¾“å…¥é€šé“åˆç†
        target_in = new_in
        if abs(expected_new_in - new_in) > 10:  # å…è®¸å°èŒƒå›´è¯¯å·®
            print(f"    âš ï¸  ç›®æ ‡é€šé“ä¸åŒ¹é…: è®¡ç®—({expected_new_in}) vs å®é™…({new_in})")
            target_in = expected_new_in
            # åˆ›å»ºè°ƒæ•´åçš„ç›®æ ‡å½¢çŠ¶
            new_weight_tensor = torch.zeros((new_out, target_in, new_h, new_w), 
                                          dtype=old_weight.dtype, 
                                          device=old_weight.device)
        else:
            new_weight_tensor = torch.zeros_like(new_weight)
        
        # æ™ºèƒ½æƒé‡å¤åˆ¶å’Œæ‰©å±•
        min_in = min(old_in, target_in)
        
        # å¤åˆ¶ç°æœ‰æƒé‡
        new_weight_tensor[:, :min_in] = old_weight[:, :min_in].clone()
        
        if target_in > old_in:
            # æ‰©å±•è¾“å…¥é€šé“
            remaining = target_in - old_in
            print(f"    ğŸ“ˆ æ‰©å±•å¯†é›†è¿æ¥è¾“å…¥é€šé“: +{remaining}")
            
            # ä½¿ç”¨æ™ºèƒ½æ‰©å±•ç­–ç•¥
            with torch.no_grad():
                if remaining <= old_in:
                    # å¤åˆ¶ç°æœ‰é€šé“å¹¶æ·»åŠ å™ªå£°
                    for i in range(remaining):
                        src_idx = i % old_in
                        dst_idx = old_in + i
                        new_weight_tensor[:, dst_idx] = old_weight[:, src_idx] * 0.8
                        noise = torch.randn_like(old_weight[:, src_idx]) * 0.01
                        new_weight_tensor[:, dst_idx] += noise
                else:
                    # å¤§é‡æ‰©å±•ä½¿ç”¨Kaimingåˆå§‹åŒ–
                    new_channels = new_weight_tensor[:, old_in:target_in]
                    torch.nn.init.kaiming_normal_(new_channels, mode='fan_in', nonlinearity='leaky_relu')
                    noise = torch.randn_like(new_channels) * 0.01
                    new_weight_tensor[:, old_in:target_in] = new_channels + noise
        
        elif target_in < old_in:
            # æ”¶ç¼©è¾“å…¥é€šé“
            print(f"    ğŸ“‰ æ”¶ç¼©å¯†é›†è¿æ¥è¾“å…¥é€šé“: -{old_in - target_in}")
        
        return new_weight_tensor

    def _adjust_direct_feature_weight(self, old_weight, new_weight, key, old_features, new_features):
        """
        è°ƒæ•´ç›´æ¥ç‰¹å¾ç›¸å…³çš„æƒé‡ï¼ˆå¦‚conv_firstç­‰ï¼‰
        """
        old_out, old_in, old_h, old_w = old_weight.shape
        new_out, new_in, new_h, new_w = new_weight.shape
        
        # åˆ›å»ºæ–°æƒé‡å¼ é‡
        new_weight_tensor = torch.zeros_like(new_weight)
        
        if old_out == old_features and new_out == new_features:
            # è¾“å‡ºé€šé“è°ƒæ•´
            min_out = min(old_out, new_out)
            new_weight_tensor[:min_out] = old_weight[:min_out].clone()
            
            if new_out > old_out:
                # æ‰©å±•è¾“å‡ºé€šé“
                remaining = new_out - old_out
                print(f"    ğŸ“ˆ æ‰©å±•è¾“å‡ºé€šé“: +{remaining}")
                
                # ä½¿ç”¨Kaimingåˆå§‹åŒ–æ–°å¢éƒ¨åˆ†
                with torch.no_grad():
                    torch.nn.init.kaiming_normal_(new_weight_tensor[old_out:], mode='fan_out', nonlinearity='leaky_relu')
        
        elif old_in == old_features and new_in == new_features:
            # è¾“å…¥é€šé“è°ƒæ•´
            min_in = min(old_in, new_in)
            new_weight_tensor[:, :min_in] = old_weight[:, :min_in].clone()
            
            if new_in > old_in:
                # æ‰©å±•è¾“å…¥é€šé“
                remaining = new_in - old_in
                print(f"    ğŸ“ˆ æ‰©å±•è¾“å…¥é€šé“: +{remaining}")
                
                # ä½¿ç”¨Kaimingåˆå§‹åŒ–æ–°å¢éƒ¨åˆ†
                with torch.no_grad():
                    torch.nn.init.kaiming_normal_(new_weight_tensor[:, old_in:], mode='fan_in', nonlinearity='leaky_relu')
        
        return new_weight_tensor

    def _adjust_feature_bias(self, old_bias, new_bias, old_features, new_features):
        """
        è°ƒæ•´ç‰¹å¾ç›¸å…³çš„åç½®
        """
        new_bias_tensor = torch.zeros_like(new_bias)
        min_features = min(old_features, new_features)
        new_bias_tensor[:min_features] = old_bias[:min_features].clone()
        
        if new_features > old_features:
            # æ‰©å±•åç½®ï¼Œæ–°å¢éƒ¨åˆ†åˆå§‹åŒ–ä¸º0
            remaining = new_features - old_features
            print(f"    ğŸ“ˆ æ‰©å±•åç½®: +{remaining}")
            new_bias_tensor[old_features:] = 0.0
        elif new_features < old_features:
            # æ”¶ç¼©åç½®
            print(f"    ğŸ“‰ æ”¶ç¼©åç½®: -{old_features - new_features}")
        
        return new_bias_tensor

    def _adjust_general_conv_weight(self, old_weight, new_shape, key):
        """
        é€šç”¨å·ç§¯æƒé‡è°ƒæ•´æ–¹æ³•
        """
        if old_weight.shape == new_shape:
            return old_weight.clone()
        
        old_out, old_in, old_h, old_w = old_weight.shape
        new_out, new_in, new_h, new_w = new_shape
        
        # åˆ›å»ºæ–°æƒé‡
        new_weight = torch.zeros(new_shape, dtype=old_weight.dtype, device=old_weight.device)
        
        # å¤åˆ¶å¯ä»¥å¤åˆ¶çš„éƒ¨åˆ†
        min_out = min(old_out, new_out)
        min_in = min(old_in, new_in)
        min_h = min(old_h, new_h)
        min_w = min(old_w, new_w)
        
        new_weight[:min_out, :min_in, :min_h, :min_w] = old_weight[:min_out, :min_in, :min_h, :min_w].clone()
        
        # å¯¹äºæ–°å¢çš„éƒ¨åˆ†ï¼Œä½¿ç”¨Kaimingåˆå§‹åŒ–
        if new_out > old_out or new_in > old_in:
            with torch.no_grad():
                # ä¿å­˜å·²å¤åˆ¶éƒ¨åˆ†
                copied_part = new_weight[:min_out, :min_in, :min_h, :min_w].clone()
                # æ•´ä½“åˆå§‹åŒ–
                torch.nn.init.kaiming_normal_(new_weight, mode='fan_in', nonlinearity='leaky_relu')
                # æ¢å¤å·²å¤åˆ¶éƒ¨åˆ†
                new_weight[:min_out, :min_in, :min_h, :min_w] = copied_part
        
        return new_weight

    def _adjust_general_weight(self, old_weight, new_shape, key):
        """
        é€šç”¨æƒé‡è°ƒæ•´æ–¹æ³•
        """
        if old_weight.shape == new_shape:
            return old_weight.clone()
        
        # åˆ›å»ºæ–°æƒé‡å¹¶ä½¿ç”¨æ™ºèƒ½åˆå§‹åŒ–
        new_weight = torch.zeros(new_shape, dtype=old_weight.dtype, device=old_weight.device)
        return self._initialize_weight_smart(new_weight, key)
    
    def _initialize_weight_smart(self, weight_tensor, key):
        """
        æ™ºèƒ½æƒé‡åˆå§‹åŒ–
        """
        with torch.no_grad():
            if 'conv' in key and len(weight_tensor.shape) == 4:
                # å·ç§¯å±‚ä½¿ç”¨Kaimingåˆå§‹åŒ–
                torch.nn.init.kaiming_normal_(weight_tensor, mode='fan_in', nonlinearity='leaky_relu')
            elif 'bias' in key:
                # åç½®åˆå§‹åŒ–ä¸º0
                torch.nn.init.zeros_(weight_tensor)
            elif len(weight_tensor.shape) == 2:
                # çº¿æ€§å±‚ä½¿ç”¨Xavieråˆå§‹åŒ–
                torch.nn.init.xavier_uniform_(weight_tensor)
            else:
                # å…¶ä»–æƒ…å†µä½¿ç”¨æ­£æ€åˆ†å¸ƒ
                torch.nn.init.normal_(weight_tensor, mean=0, std=0.02)
        
        return weight_tensor
    
    def _progressive_feature_adjust(self, checkpoint_path, old_features, new_features, steps=3):
        """
        æ¸è¿›å¼ç‰¹å¾æ•°è°ƒæ•´ï¼Œé¿å…ä¸€æ¬¡æ€§å¤§å¹…è°ƒæ•´å¯¼è‡´çš„é—®é¢˜
        """
        print(f"{Fore.CYAN}ğŸš€ å¼€å§‹æ¸è¿›å¼ç‰¹å¾æ•°è°ƒæ•´: {old_features} -> {new_features} (åˆ†{steps}æ­¥){Style.RESET_ALL}")
        
        current_features = old_features
        # è®¡ç®—æ¯æ­¥å¢é‡ï¼ˆç¡®ä¿æœ€åä¸€æ­¥èƒ½åˆ°è¾¾ç›®æ ‡ï¼‰
        increment = (new_features - old_features) // steps
        if increment == 0:
            increment = 1
        
        base_name = os.path.splitext(os.path.basename(checkpoint_path))[0]
        checkpoint_dir = os.path.dirname(checkpoint_path)
        
        for step in range(steps):
            try:
                # è®¡ç®—å½“å‰æ­¥éª¤çš„ç›®æ ‡ç‰¹å¾æ•°
                if step == steps - 1:
                    target_features = new_features
                else:
                    target_features = current_features + increment
                    # ç¡®ä¿ä¸ä¼šè¶…è¿‡ç›®æ ‡
                    if (new_features > old_features and target_features > new_features) or \
                       (new_features < old_features and target_features < new_features):
                        target_features = new_features
                
                if target_features == current_features:
                    continue
                
                print(f"\n{Fore.YELLOW}ğŸ“ˆ æ­¥éª¤ {step+1}/{steps}: {current_features} -> {target_features}{Style.RESET_ALL}")
                
                # åŠ è½½å½“å‰æ£€æŸ¥ç‚¹
                if step == 0:
                    current_checkpoint_path = checkpoint_path
                else:
                    current_checkpoint_path = os.path.join(checkpoint_dir, f"{base_name}_step_{step}_features_{current_features}.pth")
                
                checkpoint = torch.load(current_checkpoint_path, map_location='cpu', weights_only=False)
                old_state_dict = checkpoint['generator_state_dict']
                
                # åˆ›å»ºç›®æ ‡æ¨¡å‹
                from src.models.esrgan import LiteRealESRGAN
                target_model = LiteRealESRGAN(
                    num_blocks=6,  # ä½¿ç”¨é»˜è®¤å—æ•°
                    num_features=target_features
                )
                new_state_dict = target_model.state_dict()
                
                # è°ƒæ•´æƒé‡
                adjusted_state_dict = self._adjust_features_weights(
                    old_state_dict, new_state_dict, current_features, target_features
                )
                
                # æ›´æ–°æ£€æŸ¥ç‚¹
                checkpoint['generator_state_dict'] = adjusted_state_dict
                
                # ä¿å­˜ä¸­é—´ç»“æœ
                step_output_path = os.path.join(checkpoint_dir, f"{base_name}_step_{step+1}_features_{target_features}.pth")
                torch.save(checkpoint, step_output_path)
                print(f"{Fore.GREEN}âœ… æ­¥éª¤ {step+1} å®Œæˆï¼Œä¿å­˜è‡³: {os.path.basename(step_output_path)}{Style.RESET_ALL}")
                
                # éªŒè¯å½“å‰æ­¥éª¤
                if self._verify_feature_adjustment(step_output_path, target_features):
                    current_features = target_features
                    print(f"{Fore.GREEN}âœ… æ­¥éª¤ {step+1} éªŒè¯é€šè¿‡{Style.RESET_ALL}")
                else:
                    print(f"{Fore.RED}âŒ æ­¥éª¤ {step+1} éªŒè¯å¤±è´¥ï¼Œåœæ­¢æ¸è¿›è°ƒæ•´{Style.RESET_ALL}")
                    return False, f"æ­¥éª¤ {step+1} éªŒè¯å¤±è´¥"
                
            except Exception as e:
                print(f"{Fore.RED}âŒ æ­¥éª¤ {step+1} è°ƒæ•´å¤±è´¥: {str(e)}{Style.RESET_ALL}")
                import traceback
                traceback.print_exc()
                return False, f"æ­¥éª¤ {step+1} å¤±è´¥: {str(e)}"
        
        # è¿”å›æœ€ç»ˆç»“æœ
        final_path = os.path.join(checkpoint_dir, f"{base_name}_features_{new_features}.pth")
        shutil.copy2(step_output_path, final_path)
        return True, final_path

    def _smart_resize_weight(self, old_weight, new_shape, key):
        """æ™ºèƒ½è°ƒæ•´æƒé‡å°ºå¯¸çš„é€šç”¨æ–¹æ³•"""
        if old_weight.shape == new_shape:
            return old_weight.clone()
            
        # åˆ›å»ºæ–°æƒé‡å¼ é‡
        new_weight = torch.zeros(new_shape, dtype=old_weight.dtype, device=old_weight.device)
        
        # è®¡ç®—å¯å¤åˆ¶çš„ç»´åº¦å¤§å°
        min_dims = [min(old_dim, new_dim) for old_dim, new_dim in zip(old_weight.shape, new_shape)]
        
        # åˆ›å»ºåˆ‡ç‰‡å…ƒç»„
        slices = tuple(slice(0, dim) for dim in min_dims)
        
        # å¤åˆ¶å¯å¤åˆ¶çš„éƒ¨åˆ†
        new_weight[slices] = old_weight[slices].clone()
        
        # å¯¹äºå·ç§¯å±‚ï¼Œåˆå§‹åŒ–æ–°å¢éƒ¨åˆ†
        if 'conv' in key and len(new_shape) == 4:
            with torch.no_grad():
                # ä¿å­˜å·²å¤åˆ¶éƒ¨åˆ†
                copied_part = new_weight[slices].clone()
                # æ•´ä½“åˆå§‹åŒ–
                torch.nn.init.kaiming_normal_(new_weight, mode='fan_in', nonlinearity='leaky_relu')
                # æ¢å¤å·²å¤åˆ¶éƒ¨åˆ†
                new_weight[slices] = copied_part
        
        # å¯¹äºåç½®ï¼Œæ–°å¢éƒ¨åˆ†åˆå§‹åŒ–ä¸º0
        elif 'bias' in key:
            new_weight[min_dims[0]:] = 0.0
            
        return new_weight

    def _initialize_weight(self, weight_tensor):
        """åˆå§‹åŒ–æ–°æƒé‡"""
        with torch.no_grad():
            if len(weight_tensor.shape) == 4:  # å·ç§¯å±‚
                torch.nn.init.kaiming_normal_(weight_tensor, mode='fan_in', nonlinearity='leaky_relu')
            elif len(weight_tensor.shape) == 1:  # åç½®
                torch.nn.init.zeros_(weight_tensor)
            else:  # å…¶ä»–
                torch.nn.init.normal_(weight_tensor, mean=0, std=0.02)
        return weight_tensor

    def _is_new_rrdb_block(self, key, old_blocks):
        """åˆ¤æ–­æ˜¯å¦æ˜¯æ–°å¢çš„RRDBå—"""
        import re
        match = re.match(r'rrdb_blocks\.(\d+)\.', key)
        if match:
            block_idx = int(match.group(1))
            return block_idx >= old_blocks
        return False

    def _get_source_block_key(self, key, old_state_dict, old_blocks):
        """è·å–æºå—çš„æƒé‡é”®"""
        if old_blocks == 0:
            return None
            
        import re
        match = re.match(r'(rrdb_blocks\.)(\d+)(\..+)', key)
        if match:
            prefix = match.group(1)
            block_idx = int(match.group(2))
            suffix = match.group(3)
            
            # ä½¿ç”¨æœ€åä¸€ä¸ªæ—§å—ä½œä¸ºæº
            source_idx = old_blocks - 1
            source_key = f"{prefix}{source_idx}{suffix}"
            
            if source_key in old_state_dict:
                return source_key
        return None