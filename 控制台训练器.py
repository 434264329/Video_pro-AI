import os
import sys
import json
import time
import torch
import threading
import re
from datetime import datetime
from colorama import init, Fore, Back, Style

torch.cuda.empty_cache()
# é™åˆ¶PyTorchå†…å­˜åˆ†é…ç­–ç•¥ï¼Œå‡å°‘å†…å­˜ç¢ç‰‡
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'

from config.config import (
    load_config, save_config, get_default_config,
    load_low_memory_config, load_high_memory_config, load_rtx_4090_config,
    create_4gb_config, create_6gb_config, create_8gb_config, create_12gb_config,
    auto_config_by_gpu_memory
)

# åˆå§‹åŒ–colorama
init(autoreset=True)

# ğŸš¨ é¢å¤–çš„å†…å­˜ä¼˜åŒ–è®¾ç½®
if torch.cuda.is_available():
    torch.cuda.set_per_process_memory_fraction(0.85)  # åªä½¿ç”¨85%æ˜¾å­˜
    torch.cuda.reset_peak_memory_stats()
    print(f"{Fore.GREEN}ğŸ”§ æ§åˆ¶å°è®­ç»ƒå™¨å†…å­˜ä¼˜åŒ–é…ç½®å·²å¯ç”¨: max_split_size_mb=128, æ˜¾å­˜é™åˆ¶=85%{Style.RESET_ALL}")

class GPUOptimizer:
    """GPUä¼˜åŒ–å™¨ - ä¸“é—¨é’ˆå¯¹RTX 4090ç­‰é«˜ç«¯GPUçš„ä¼˜åŒ–"""
    
    def __init__(self):
        # ğŸš¨ åˆå§‹åŒ–æ—¶ç«‹å³æ‰§è¡Œå†…å­˜ä¼˜åŒ–
        torch.cuda.empty_cache()
        
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.tf32_enabled = False
        self.compile_enabled = False
        
    def enable_tf32(self):
        """å¯ç”¨TF32åŠ é€Ÿï¼ˆRTX 30/40ç³»åˆ—ï¼‰"""
        if torch.cuda.is_available():
            torch.backends.cuda.matmul.allow_tf32 = True
            torch.backends.cudnn.allow_tf32 = True
            self.tf32_enabled = True
            print(f"{Fore.GREEN}âœ… TF32åŠ é€Ÿå·²å¯ç”¨{Style.RESET_ALL}")
        else:
            print(f"{Fore.RED}âŒ CUDAä¸å¯ç”¨ï¼Œæ— æ³•å¯ç”¨TF32{Style.RESET_ALL}")
    
    def disable_tf32(self):
        """ç¦ç”¨TF32åŠ é€Ÿ"""
        if torch.cuda.is_available():
            torch.backends.cuda.matmul.allow_tf32 = False
            torch.backends.cudnn.allow_tf32 = False
            self.tf32_enabled = False
            print(f"{Fore.YELLOW}âš ï¸  TF32åŠ é€Ÿå·²ç¦ç”¨{Style.RESET_ALL}")
    
    def enable_compile(self):
        """å¯ç”¨æ¨¡å‹ç¼–è¯‘ä¼˜åŒ–ï¼ˆPyTorch 2.0+ï¼‰"""
        try:
            if hasattr(torch, 'compile'):
                self.compile_enabled = True
                print(f"{Fore.GREEN}âœ… æ¨¡å‹ç¼–è¯‘ä¼˜åŒ–å·²å¯ç”¨{Style.RESET_ALL}")
            else:
                print(f"{Fore.YELLOW}âš ï¸  å½“å‰PyTorchç‰ˆæœ¬ä¸æ”¯æŒæ¨¡å‹ç¼–è¯‘{Style.RESET_ALL}")
        except Exception as e:
            print(f"{Fore.RED}âŒ å¯ç”¨æ¨¡å‹ç¼–è¯‘å¤±è´¥: {e}{Style.RESET_ALL}")
    
    def disable_compile(self):
        """ç¦ç”¨æ¨¡å‹ç¼–è¯‘ä¼˜åŒ–"""
        self.compile_enabled = False
        print(f"{Fore.YELLOW}âš ï¸  æ¨¡å‹ç¼–è¯‘ä¼˜åŒ–å·²ç¦ç”¨{Style.RESET_ALL}")
    
    def optimize_model(self, model):
        """ä¼˜åŒ–æ¨¡å‹"""
        if self.compile_enabled and hasattr(torch, 'compile'):
            try:
                model = torch.compile(model, mode='max-autotune')
                print(f"{Fore.GREEN}âœ… æ¨¡å‹ç¼–è¯‘ä¼˜åŒ–å®Œæˆ{Style.RESET_ALL}")
            except Exception as e:
                print(f"{Fore.YELLOW}âš ï¸  æ¨¡å‹ç¼–è¯‘å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ¨¡å‹: {e}{Style.RESET_ALL}")
        return model
    
    def get_optimal_batch_size(self, model, input_shape, max_memory_gb=20):
        """è‡ªåŠ¨è®¡ç®—æœ€ä¼˜æ‰¹æ¬¡å¤§å°"""
        if not torch.cuda.is_available():
            return 1
        
        try:
            # æ¸…ç©ºç¼“å­˜
            torch.cuda.empty_cache()
            
            # æµ‹è¯•ä¸åŒæ‰¹æ¬¡å¤§å°
            batch_sizes = [1, 2, 4, 6, 8, 12, 16, 20, 24]
            optimal_batch_size = 1
            
            for batch_size in batch_sizes:
                try:
                    # åˆ›å»ºæµ‹è¯•è¾“å…¥
                    test_input = torch.randn(batch_size, *input_shape[1:]).cuda()
                    
                    # å‰å‘ä¼ æ’­æµ‹è¯•
                    with torch.no_grad():
                        _ = model(test_input)
                    
                    # æ£€æŸ¥æ˜¾å­˜ä½¿ç”¨
                    memory_used = torch.cuda.memory_allocated() / 1024**3  # GB
                    if memory_used < max_memory_gb * 0.8:  # ä¿ç•™20%ä½™é‡
                        optimal_batch_size = batch_size
                    else:
                        break
                        
                except RuntimeError as e:
                    if "out of memory" in str(e):
                        break
                    else:
                        raise e
                finally:
                    torch.cuda.empty_cache()
            
            print(f"{Fore.GREEN}ğŸ¯ æ¨èæ‰¹æ¬¡å¤§å°: {optimal_batch_size}{Style.RESET_ALL}")
            return optimal_batch_size
            
        except Exception as e:
            print(f"{Fore.YELLOW}âš ï¸  è‡ªåŠ¨æ‰¹æ¬¡å¤§å°è®¡ç®—å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤å€¼{Style.RESET_ALL}")
            return 4

class ModelCompatibilityChecker:
    """æ¨¡å‹å…¼å®¹æ€§æ£€æŸ¥å™¨"""
    
    def __init__(self):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    def check_model_compatibility(self, checkpoint_path, new_config):
        """æ£€æŸ¥æ¨¡å‹å…¼å®¹æ€§"""
        try:
            # åŠ è½½æ£€æŸ¥ç‚¹
            checkpoint = torch.load(checkpoint_path, map_location=self.device, weights_only=False)
            old_state_dict = checkpoint['generator_state_dict']
            
            # æå–æ—§æ¨¡å‹é…ç½®
            old_config = self._extract_model_config_from_state_dict(old_state_dict)
            
            # è·å–æ–°é…ç½®
            new_num_blocks = new_config['model']['num_blocks']
            new_num_features = new_config['model']['num_features']
            
            print(f"{Fore.YELLOW}æ—§æ¨¡å‹é…ç½®: blocks={old_config['num_blocks']}, features={old_config['num_features']}{Style.RESET_ALL}")
            print(f"{Fore.YELLOW}æ–°æ¨¡å‹é…ç½®: blocks={new_num_blocks}, features={new_num_features}{Style.RESET_ALL}")
            
            # æ£€æŸ¥å…¼å®¹æ€§
            if old_config['num_blocks'] == new_num_blocks and old_config['num_features'] == new_num_features:
                print(f"{Fore.GREEN}âœ… æ¨¡å‹é…ç½®å®Œå…¨å…¼å®¹{Style.RESET_ALL}")
                return True, "å®Œå…¨å…¼å®¹"
            else:
                print(f"{Fore.YELLOW}âš ï¸  æ¨¡å‹é…ç½®ä¸å…¼å®¹ï¼Œéœ€è¦è°ƒæ•´{Style.RESET_ALL}")
                return False, f"é…ç½®ä¸åŒ¹é…: æ—§æ¨¡å‹({old_config['num_blocks']}, {old_config['num_features']}) vs æ–°é…ç½®({new_num_blocks}, {new_num_features})"
                
        except Exception as e:
            return False, f"æ£€æŸ¥å¤±è´¥: {str(e)}"
    
    def _extract_model_config_from_state_dict(self, state_dict):
        """ä»çŠ¶æ€å­—å…¸ä¸­æå–æ¨¡å‹é…ç½®"""
        # é€šè¿‡åˆ†ææƒé‡å½¢çŠ¶æ¥æ¨æ–­æ¨¡å‹å‚æ•°
        num_features = 64  # é»˜è®¤å€¼
        num_blocks = 6     # é»˜è®¤å€¼
        
        # åˆ†æç¬¬ä¸€ä¸ªå·ç§¯å±‚æ¥ç¡®å®šç‰¹å¾æ•°
        if 'conv_first.weight' in state_dict:
            num_features = state_dict['conv_first.weight'].shape[0]
            print(f"ğŸ” ä»conv_first.weightæ£€æµ‹åˆ°ç‰¹å¾æ•°: {num_features}")
        
        # è®¡ç®—RRDBå—çš„æ•°é‡
        rrdb_count = 0
        for key in state_dict.keys():
            if key.startswith('rrdb_blocks.') and '.dense1.conv1.weight' in key:
                # æå–å—ç´¢å¼•
                import re
                match = re.match(r'rrdb_blocks\.(\d+)\.dense1\.conv1\.weight', key)
                if match:
                    block_idx = int(match.group(1))
                    rrdb_count = max(rrdb_count, block_idx + 1)
        
        if rrdb_count > 0:
            num_blocks = rrdb_count
            print(f"ğŸ” ä»rrdb_blocksæ£€æµ‹åˆ°å—æ•°: {num_blocks}")
        
        print(f"ğŸ” æå–çš„æ¨¡å‹é…ç½®: {num_blocks}å—, {num_features}ç‰¹å¾")
        return {
            'num_blocks': num_blocks,
            'num_features': num_features
        }

    def adjust_checkpoint_for_new_config(self, checkpoint_path, new_config, output_path=None):
        """è°ƒæ•´æ£€æŸ¥ç‚¹ä»¥é€‚åº”æ–°é…ç½®"""
        try:
            print(f"{Fore.CYAN}ğŸ”§ æ­£åœ¨è°ƒæ•´æ¨¡å‹æ£€æŸ¥ç‚¹...{Style.RESET_ALL}")
            
            # åŠ è½½æ£€æŸ¥ç‚¹
            checkpoint = torch.load(checkpoint_path, map_location=self.device, weights_only=False)
            old_state_dict = checkpoint['generator_state_dict']
            
            # æ˜¾ç¤ºåŸå§‹æ£€æŸ¥ç‚¹ä¿¡æ¯
            if 'epoch' in checkpoint:
                print(f"{Fore.CYAN}åŸå§‹æ£€æŸ¥ç‚¹è®­ç»ƒè½®æ•°: {checkpoint['epoch']}{Style.RESET_ALL}")
            if 'best_psnr' in checkpoint:
                print(f"{Fore.CYAN}åŸå§‹æ£€æŸ¥ç‚¹æœ€ä½³PSNR: {checkpoint['best_psnr']:.4f} dB{Style.RESET_ALL}")
            
            # æå–é…ç½®ä¿¡æ¯
            old_config = self._extract_model_config_from_state_dict(old_state_dict)
            new_model_config = new_config['model']
            
            print(f"{Fore.CYAN}åŸå§‹æ¨¡å‹é…ç½®: {old_config['num_blocks']}å—, {old_config['num_features']}ç‰¹å¾{Style.RESET_ALL}")
            print(f"{Fore.CYAN}ç›®æ ‡æ¨¡å‹é…ç½®: {new_model_config['num_blocks']}å—, {new_model_config['num_features']}ç‰¹å¾{Style.RESET_ALL}")
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒæ•´
            if (old_config['num_blocks'] == new_model_config['num_blocks'] and 
                old_config['num_features'] == new_model_config['num_features']):
                print(f"{Fore.GREEN}âœ… æ¨¡å‹é…ç½®å·²åŒ¹é…ï¼Œæ— éœ€è°ƒæ•´{Style.RESET_ALL}")
                return True, checkpoint_path
            
            # åˆ›å»ºæ–°æ¨¡å‹ä»¥è·å–ç›®æ ‡çŠ¶æ€å­—å…¸ç»“æ„
            from src.models.esrgan import LiteRealESRGAN
            new_model = LiteRealESRGAN(
                num_blocks=new_model_config['num_blocks'],
                num_features=new_model_config['num_features']
            )
            new_model_state_dict = new_model.state_dict()
            
            # è°ƒæ•´æƒé‡
            adjusted_state_dict = self._adjust_weights(old_state_dict, new_model_state_dict, old_config, new_model_config)
            
            # æ›´æ–°æ£€æŸ¥ç‚¹ - ä¿ç•™æ‰€æœ‰åŸå§‹å…ƒæ•°æ®
            checkpoint['generator_state_dict'] = adjusted_state_dict
            # ä¿ç•™åŸå§‹çš„epochã€best_psnrã€optimizer_state_dictç­‰ä¿¡æ¯
            # è¿™äº›ä¿¡æ¯åœ¨è°ƒæ•´åä»ç„¶æœ‰æ•ˆï¼Œå› ä¸ºæˆ‘ä»¬åªæ˜¯è°ƒæ•´äº†æ¨¡å‹ç»“æ„
            
            # ç”Ÿæˆè¾“å‡ºè·¯å¾„
            if output_path is None:
                base_name = os.path.splitext(os.path.basename(checkpoint_path))[0]
                output_path = os.path.join(
                    os.path.dirname(checkpoint_path),
                    f"{base_name}_adjusted.pth"
                )
            
            # ä¿å­˜è°ƒæ•´åçš„æ£€æŸ¥ç‚¹
            torch.save(checkpoint, output_path)
            print(f"{Fore.GREEN}âœ… è°ƒæ•´åçš„æ¨¡å‹å·²ä¿å­˜: {os.path.basename(output_path)}{Style.RESET_ALL}")
            
            # æ˜¾ç¤ºè°ƒæ•´åçš„æ£€æŸ¥ç‚¹ä¿¡æ¯
            if 'epoch' in checkpoint:
                print(f"{Fore.GREEN}âœ… ä¿ç•™è®­ç»ƒè½®æ•°: {checkpoint['epoch']}{Style.RESET_ALL}")
            if 'best_psnr' in checkpoint:
                print(f"{Fore.GREEN}âœ… ä¿ç•™æœ€ä½³PSNR: {checkpoint['best_psnr']:.4f} dB{Style.RESET_ALL}")
            
            return True, output_path
            
        except Exception as e:
            print(f"{Fore.RED}âŒ æ¨¡å‹è°ƒæ•´å¤±è´¥: {str(e)}{Style.RESET_ALL}")
            import traceback
            traceback.print_exc()
            return False, str(e)

    def _adjust_weights(self, old_state_dict, new_model_state_dict, old_config, new_config):
        """è°ƒæ•´æƒé‡ä»¥åŒ¹é…æ–°æ¨¡å‹ç»“æ„"""
        adjusted_state_dict = {}
        
        print(f"{Fore.CYAN}ğŸ”§ å¼€å§‹æƒé‡è°ƒæ•´...{Style.RESET_ALL}")
        print(f"ğŸ”§ ä» {old_config['num_blocks']}å—/{old_config['num_features']}ç‰¹å¾ -> {new_config['num_blocks']}å—/{new_config['num_features']}ç‰¹å¾")
        
        # è·å–é…ç½®ä¿¡æ¯
        old_blocks = old_config['num_blocks']
        old_features = old_config['num_features']
        new_blocks = new_config['num_blocks']
        new_features = new_config['num_features']
        
        # å¤„ç†æ‰€æœ‰æ–°æ¨¡å‹éœ€è¦çš„æƒé‡
        for key, new_weight in new_model_state_dict.items():
            if key in old_state_dict:
                old_weight = old_state_dict[key]
                if old_weight.shape == new_weight.shape:
                    # å½¢çŠ¶ç›¸åŒï¼Œç›´æ¥å¤åˆ¶
                    adjusted_state_dict[key] = old_weight.clone()
                    print(f"âœ… {key}: ç›´æ¥å¤åˆ¶ {old_weight.shape}")
                else:
                    # å½¢çŠ¶ä¸åŒï¼Œéœ€è¦è°ƒæ•´
                    adjusted_weight = self._smart_resize_weight(old_weight, new_weight.shape, key)
                    adjusted_state_dict[key] = adjusted_weight
                    print(f"ğŸ”§ {key}: è°ƒæ•´ {old_weight.shape} -> {new_weight.shape}")
            else:
                # æ–°å¢çš„æƒé‡
                if self._is_new_rrdb_block(key, old_blocks):
                    # å¯¹äºæ–°å¢çš„RRDBå—ï¼Œå¤åˆ¶ç°æœ‰å—çš„æƒé‡
                    source_key = self._get_source_block_key(key, old_state_dict, old_blocks)
                    if source_key and source_key in old_state_dict:
                        source_weight = old_state_dict[source_key]
                        if source_weight.shape == new_weight.shape:
                            # æ·»åŠ å°çš„éšæœºå™ªå£°ä»¥é¿å…å®Œå…¨ç›¸åŒ
                            noise = torch.randn_like(source_weight) * 0.01
                            adjusted_state_dict[key] = source_weight + noise
                            print(f"ğŸ”„ {key}: å¤åˆ¶è‡ª {source_key} (æ·»åŠ å™ªå£°)")
                        else:
                            # éœ€è¦è°ƒæ•´å°ºå¯¸åå¤åˆ¶
                            adjusted_weight = self._smart_resize_weight(source_weight, new_weight.shape, key)
                            noise = torch.randn_like(adjusted_weight) * 0.01
                            adjusted_state_dict[key] = adjusted_weight + noise
                            print(f"ğŸ”„ {key}: ä» {source_key} è°ƒæ•´å¹¶æ·»åŠ å™ªå£° {source_weight.shape} -> {new_weight.shape}")
                    else:
                        # éšæœºåˆå§‹åŒ–
                        adjusted_state_dict[key] = self._initialize_weight(new_weight)
                        print(f"ğŸ² {key}: éšæœºåˆå§‹åŒ– {new_weight.shape}")
                else:
                    # å…¶ä»–æ–°å¢æƒé‡ï¼Œéšæœºåˆå§‹åŒ–
                    adjusted_state_dict[key] = self._initialize_weight(new_weight)
                    print(f"ğŸ² {key}: éšæœºåˆå§‹åŒ– {new_weight.shape}")
        
        print(f"{Fore.GREEN}âœ… æƒé‡è°ƒæ•´å®Œæˆï¼Œå…±å¤„ç† {len(adjusted_state_dict)} ä¸ªæƒé‡{Style.RESET_ALL}")
        return adjusted_state_dict
    def smart_adjust_features_enhanced(self, checkpoint_path, new_features, use_progressive=True, steps=3):
        """
        å¢å¼ºç‰ˆæ™ºèƒ½ç‰¹å¾æ•°è°ƒæ•´ï¼Œæ”¯æŒæ¸è¿›å¼è°ƒæ•´å’Œé”™è¯¯æ¢å¤
        """
        try:
            print(f"{Fore.CYAN}ğŸš€ å¢å¼ºç‰ˆæ™ºèƒ½ç‰¹å¾æ•°è°ƒæ•´{Style.RESET_ALL}")
            
            # 1. æ£€æµ‹å½“å‰ç‰¹å¾æ•°
            detected_config = self._detect_checkpoint_config(checkpoint_path)
            if not detected_config:
                return False, "æ— æ³•æ£€æµ‹æ£€æŸ¥ç‚¹é…ç½®"
            
            old_features = detected_config['num_features']
            print(f"ğŸ“Š æ£€æµ‹åˆ°å½“å‰ç‰¹å¾æ•°: {old_features}")
            print(f"ğŸ¯ ç›®æ ‡ç‰¹å¾æ•°: {new_features}")
            
            if old_features == new_features:
                print(f"{Fore.YELLOW}âš ï¸  ç‰¹å¾æ•°å·²ç»æ˜¯ {new_features}ï¼Œæ— éœ€è°ƒæ•´{Style.RESET_ALL}")
                return True, checkpoint_path
            
            # 2. å¤‡ä»½åŸå§‹æ£€æŸ¥ç‚¹
            backup_path = checkpoint_path.replace('.pth', '_backup.pth')
            import shutil
            shutil.copy2(checkpoint_path, backup_path)
            print(f"ğŸ’¾ å·²å¤‡ä»½åŸå§‹æ£€æŸ¥ç‚¹: {os.path.basename(backup_path)}")
            
            # 3. ç›´æ¥è°ƒæ•´ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œé¿å…å¤æ‚çš„æ¸è¿›å¼è°ƒæ•´ï¼‰
            print(f"ğŸ”§ å¼€å§‹ç›´æ¥ç‰¹å¾æ•°è°ƒæ•´")
            success, result = self._smart_adjust_features_direct(checkpoint_path, old_features, new_features)
            
            if success:
                # 4. æœ€ç»ˆéªŒè¯
                print(f"{Fore.GREEN}ğŸ‰ æ™ºèƒ½ç‰¹å¾æ•°è°ƒæ•´æˆåŠŸå®Œæˆ!{Style.RESET_ALL}")
                return True, result
            else:
                print(f"{Fore.RED}âŒ è°ƒæ•´è¿‡ç¨‹å¤±è´¥: {result}{Style.RESET_ALL}")
                return False, result
                
        except Exception as e:
            print(f"{Fore.RED}âŒ å¢å¼ºç‰ˆè°ƒæ•´å¤±è´¥: {str(e)}{Style.RESET_ALL}")
            import traceback
            traceback.print_exc()
            return False, str(e)

    def _smart_adjust_features_direct(self, checkpoint_path, old_features, new_features):
        """
        ç›´æ¥ç‰¹å¾æ•°è°ƒæ•´æ–¹æ³•
        """
        try:
            print(f"{Fore.CYAN}ğŸ”§ ç›´æ¥è°ƒæ•´ç‰¹å¾æ•°: {old_features} -> {new_features}{Style.RESET_ALL}")
            
            # åŠ è½½æ£€æŸ¥ç‚¹
            checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)
            old_state_dict = checkpoint['generator_state_dict']
            
            # æ£€æµ‹æ£€æŸ¥ç‚¹çš„å®é™…é…ç½®
            checkpoint_config = self._detect_checkpoint_config(checkpoint_path)
            if not checkpoint_config:
                raise Exception("æ— æ³•æ£€æµ‹æ£€æŸ¥ç‚¹é…ç½®")
            
            detected_blocks = checkpoint_config['num_blocks']
            detected_features = checkpoint_config['num_features']
            
            print(f"{Fore.CYAN}ğŸ“Š æ£€æµ‹åˆ°æ£€æŸ¥ç‚¹é…ç½®: {detected_blocks}å—, {detected_features}ç‰¹å¾{Style.RESET_ALL}")
            
            # åˆ›å»ºç›®æ ‡æ¨¡å‹ - ä½¿ç”¨æ£€æµ‹åˆ°çš„å—æ•°
            from src.models.esrgan import LiteRealESRGAN
            target_model = LiteRealESRGAN(
                num_blocks=detected_blocks,  # ä½¿ç”¨æ£€æµ‹åˆ°çš„å—æ•°
                num_features=new_features
            )
            new_state_dict = target_model.state_dict()
            
            # è°ƒæ•´æƒé‡
            adjusted_state_dict = self._adjust_features_weights_enhanced(
                old_state_dict, new_state_dict, old_features, new_features
            )
            
            # æ›´æ–°æ£€æŸ¥ç‚¹
            checkpoint['generator_state_dict'] = adjusted_state_dict
            
            # ğŸ”¥ æ¸…ç†ä¼˜åŒ–å™¨çŠ¶æ€ï¼Œé¿å…å°ºå¯¸ä¸åŒ¹é…
            if 'g_optimizer_state_dict' in checkpoint:
                del checkpoint['g_optimizer_state_dict']
                print(f"{Fore.YELLOW}ğŸ§¹ å·²æ¸…ç†ç”Ÿæˆå™¨ä¼˜åŒ–å™¨çŠ¶æ€{Style.RESET_ALL}")
            
            if 'd_optimizer_state_dict' in checkpoint:
                del checkpoint['d_optimizer_state_dict']
                print(f"{Fore.YELLOW}ğŸ§¹ å·²æ¸…ç†åˆ¤åˆ«å™¨ä¼˜åŒ–å™¨çŠ¶æ€{Style.RESET_ALL}")
            
            if 'g_scheduler_state_dict' in checkpoint:
                del checkpoint['g_scheduler_state_dict']
                print(f"{Fore.YELLOW}ğŸ§¹ å·²æ¸…ç†ç”Ÿæˆå™¨è°ƒåº¦å™¨çŠ¶æ€{Style.RESET_ALL}")
            
            if 'd_scheduler_state_dict' in checkpoint:
                del checkpoint['d_scheduler_state_dict']
                print(f"{Fore.YELLOW}ğŸ§¹ å·²æ¸…ç†åˆ¤åˆ«å™¨è°ƒåº¦å™¨çŠ¶æ€{Style.RESET_ALL}")
            
            # ä¿å­˜ç»“æœ
            base_name = os.path.splitext(os.path.basename(checkpoint_path))[0]
            checkpoint_dir = os.path.dirname(checkpoint_path)
            output_path = os.path.join(checkpoint_dir, f"{base_name}_features_{new_features}.pth")
            
            torch.save(checkpoint, output_path)
            print(f"{Fore.GREEN}âœ… è°ƒæ•´å®Œæˆï¼Œä¿å­˜è‡³: {os.path.basename(output_path)}{Style.RESET_ALL}")
            
            return True, output_path
            
        except Exception as e:
            print(f"{Fore.RED}âŒ ç›´æ¥è°ƒæ•´å¤±è´¥: {str(e)}{Style.RESET_ALL}")
            import traceback
            traceback.print_exc()
            return False, str(e)

    def _adjust_features_weights_enhanced(self, old_state_dict, new_state_dict, old_features, new_features):
        """
        å¢å¼ºç‰ˆæƒé‡è°ƒæ•´æ–¹æ³•ï¼Œä¿®å¤æ‰€æœ‰å·²çŸ¥é—®é¢˜
        """
        adjusted_state_dict = {}
        
        print(f"{Fore.CYAN}ğŸ”§ æƒé‡è°ƒæ•´è¯¦æƒ…: {old_features} -> {new_features} ç‰¹å¾æ•°{Style.RESET_ALL}")
        
        for key, new_weight in new_state_dict.items():
            try:
                if key in old_state_dict:
                    old_weight = old_state_dict[key]
                    
                    if old_weight.shape == new_weight.shape:
                        # å½¢çŠ¶ç›¸åŒï¼Œç›´æ¥å¤åˆ¶
                        adjusted_state_dict[key] = old_weight.clone()
                        print(f"âœ… {key}: ç›´æ¥å¤åˆ¶ {old_weight.shape}")
                        
                    elif 'conv' in key and 'weight' in key and len(old_weight.shape) == 4:
                        # å·ç§¯å±‚æƒé‡å¤„ç†
                        adjusted_weight = self._adjust_conv_weight_enhanced(old_weight, new_weight, key, old_features, new_features)
                        adjusted_state_dict[key] = adjusted_weight
                        print(f"ğŸ”§ {key}: å·ç§¯è°ƒæ•´ {old_weight.shape} -> {new_weight.shape}")
                        
                    elif 'bias' in key and len(old_weight.shape) == 1:
                        # åç½®å¤„ç†
                        adjusted_weight = self._adjust_bias_enhanced(old_weight, new_weight, key, old_features, new_features)
                        adjusted_state_dict[key] = adjusted_weight
                        print(f"ğŸ”§ {key}: åç½®è°ƒæ•´ {old_weight.shape} -> {new_weight.shape}")
                        
                    else:
                        # å…¶ä»–æƒé‡ï¼Œæ™ºèƒ½è°ƒæ•´
                        adjusted_weight = self._smart_resize_weight_safe(old_weight, new_weight.shape, key)
                        adjusted_state_dict[key] = adjusted_weight
                        print(f"ğŸ”„ {key}: æ™ºèƒ½è°ƒæ•´ {old_weight.shape} -> {new_weight.shape}")
                        
                else:
                    # æ–°å¢æƒé‡ï¼Œæ™ºèƒ½åˆå§‹åŒ–
                    adjusted_state_dict[key] = self._initialize_weight_smart(new_weight, key)
                    print(f"ğŸ² {key}: æ™ºèƒ½åˆå§‹åŒ– {new_weight.shape}")
                    
            except Exception as e:
                print(f"{Fore.RED}ğŸ›‘ å¤„ç† {key} æ—¶å‡ºé”™: {str(e)}{Style.RESET_ALL}")
                # å‡ºé”™æ—¶ä½¿ç”¨æ™ºèƒ½åˆå§‹åŒ–
                adjusted_state_dict[key] = self._initialize_weight_smart(new_weight, key)
                print(f"ğŸ”„ {key}: é”™è¯¯æ¢å¤ï¼Œä½¿ç”¨æ™ºèƒ½åˆå§‹åŒ–")
        
        print(f"{Fore.GREEN}âœ… æƒé‡è°ƒæ•´å®Œæˆï¼Œå…±å¤„ç† {len(adjusted_state_dict)} ä¸ªæƒé‡{Style.RESET_ALL}")
        return adjusted_state_dict

    def _adjust_conv_weight_enhanced(self, old_weight, new_weight, key, old_features, new_features):
        """
        å¢å¼ºç‰ˆå·ç§¯æƒé‡è°ƒæ•´
        """
        old_out, old_in, old_h, old_w = old_weight.shape
        new_out, new_in, new_h, new_w = new_weight.shape
        
        # åˆ›å»ºæ–°æƒé‡å¼ é‡
        new_weight_tensor = torch.zeros_like(new_weight)
        
        # ç‰¹æ®Šå¤„ç†RRDBå¯†é›†è¿æ¥å±‚
        if 'rrdb_blocks' in key and 'dense' in key:
            return self._adjust_rrdb_dense_weight_enhanced(old_weight, new_weight, key, old_features, new_features)
        
        # å¤„ç†ç¬¬ä¸€ä¸ªå·ç§¯å±‚ï¼ˆconv_firstï¼‰
        elif 'conv_first' in key:
            # è¾“å‡ºé€šé“ä»old_featuresè°ƒæ•´åˆ°new_features
            min_out = min(old_out, new_out)
            new_weight_tensor[:min_out] = old_weight[:min_out]
            
            if new_out > old_out:
                # æ‰©å±•è¾“å‡ºé€šé“
                with torch.no_grad():
                    torch.nn.init.kaiming_normal_(new_weight_tensor[old_out:], mode='fan_out', nonlinearity='leaky_relu')
            
            return new_weight_tensor
        
        # å¤„ç†æœ€åçš„å·ç§¯å±‚
        elif 'conv_last' in key or 'conv_hr' in key:
            # è¾“å…¥é€šé“ä»old_featuresè°ƒæ•´åˆ°new_features
            min_in = min(old_in, new_in)
            new_weight_tensor[:, :min_in] = old_weight[:, :min_in]
            
            if new_in > old_in:
                # æ‰©å±•è¾“å…¥é€šé“
                with torch.no_grad():
                    torch.nn.init.kaiming_normal_(new_weight_tensor[:, old_in:], mode='fan_in', nonlinearity='leaky_relu')
            
            return new_weight_tensor
        
        # å…¶ä»–å·ç§¯å±‚ï¼Œé€šç”¨å¤„ç†
        else:
            min_out = min(old_out, new_out)
            min_in = min(old_in, new_in)
            new_weight_tensor[:min_out, :min_in] = old_weight[:min_out, :min_in]
            
            # åˆå§‹åŒ–æ–°å¢éƒ¨åˆ†
            if new_out > old_out or new_in > old_in:
                with torch.no_grad():
                    torch.nn.init.kaiming_normal_(new_weight_tensor, mode='fan_in', nonlinearity='leaky_relu')
                    # ä¿ç•™å·²å¤åˆ¶çš„éƒ¨åˆ†
                    new_weight_tensor[:min_out, :min_in] = old_weight[:min_out, :min_in]
            
            return new_weight_tensor

    def _adjust_rrdb_dense_weight_enhanced(self, old_weight, new_weight, key, old_features, new_features):
        """
        å¢å¼ºç‰ˆRRDBå¯†é›†è¿æ¥å±‚æƒé‡è°ƒæ•´
        """
        old_out, old_in, old_h, old_w = old_weight.shape
        new_out, new_in, new_h, new_w = new_weight.shape
        
        # è§£æå±‚ä¿¡æ¯
        parts = key.split('.')
        try:
            block_idx = int(parts[1])
            dense_idx = int(parts[2][-1])
            conv_idx = int(parts[3][-1])
        except (IndexError, ValueError):
            # è§£æå¤±è´¥ï¼Œä½¿ç”¨é€šç”¨æ–¹æ³•
            return self._smart_resize_weight_safe(old_weight, new_weight.shape, key)
        
        # è®¡ç®—æœŸæœ›çš„è¾“å…¥é€šé“æ•°
        growth_rate = 32
        layer_order = (dense_idx - 1) * 5 + conv_idx
        
        expected_old_in = old_features + growth_rate * (layer_order - 1)
        expected_new_in = new_features + growth_rate * (layer_order - 1)
        
        print(f"    ğŸ”— RRDB Block{block_idx} Dense{dense_idx} Conv{conv_idx}")
        print(f"    ğŸ“Š é€šé“åˆ†æ: æ—§{old_in}(æœŸæœ›{expected_old_in}), æ–°{new_in}(æœŸæœ›{expected_new_in})")
        
        # åˆ›å»ºæ–°æƒé‡å¼ é‡
        new_weight_tensor = torch.zeros_like(new_weight)
        
        # å¤åˆ¶ç°æœ‰æƒé‡ï¼ˆå®‰å…¨å¤åˆ¶ï¼‰
        min_in = min(old_in, new_in)
        min_out = min(old_out, new_out)
        new_weight_tensor[:min_out, :min_in] = old_weight[:min_out, :min_in]
        
        # å¤„ç†è¾“å…¥é€šé“æ‰©å±•
        if new_in > old_in:
            remaining = new_in - old_in
            print(f"    ğŸ“ˆ æ‰©å±•è¾“å…¥é€šé“: +{remaining}")
            
            with torch.no_grad():
                if remaining <= old_in and old_in > 0:
                    # å¤åˆ¶ç°æœ‰é€šé“å¹¶æ·»åŠ å°å™ªå£°
                    for i in range(remaining):
                        src_idx = i % old_in
                        dst_idx = old_in + i
                        if dst_idx < new_in:
                            new_weight_tensor[:min_out, dst_idx] = old_weight[:min_out, src_idx] * 0.9
                            noise = torch.randn_like(old_weight[:min_out, src_idx]) * 0.01
                            new_weight_tensor[:min_out, dst_idx] += noise
                else:
                    # ä½¿ç”¨Kaimingåˆå§‹åŒ–æ–°å¢é€šé“
                    if old_in < new_in:
                        torch.nn.init.kaiming_normal_(new_weight_tensor[:, old_in:], mode='fan_in', nonlinearity='leaky_relu')
        
        # å¤„ç†è¾“å‡ºé€šé“æ‰©å±•
        if new_out > old_out:
            with torch.no_grad():
                torch.nn.init.kaiming_normal_(new_weight_tensor[old_out:, :], mode='fan_out', nonlinearity='leaky_relu')
        
        return new_weight_tensor

    def _adjust_bias_enhanced(self, old_bias, new_bias, key, old_features, new_features):
        """
        å¢å¼ºç‰ˆåç½®è°ƒæ•´
        """
        new_bias_tensor = torch.zeros_like(new_bias)
        
        # å¤åˆ¶ç°æœ‰åç½®
        min_size = min(old_bias.shape[0], new_bias.shape[0])
        new_bias_tensor[:min_size] = old_bias[:min_size]
        
        # æ–°å¢åç½®åˆå§‹åŒ–ä¸º0
        if new_bias.shape[0] > old_bias.shape[0]:
            new_bias_tensor[old_bias.shape[0]:] = 0.0
        
        return new_bias_tensor

    def _smart_resize_weight_safe(self, old_weight, new_shape, key):
        """
        å®‰å…¨çš„æƒé‡å°ºå¯¸è°ƒæ•´æ–¹æ³•
        """
        if old_weight.shape == new_shape:
            return old_weight.clone()
        
        # åˆ›å»ºæ–°æƒé‡å¼ é‡
        new_weight = torch.zeros(new_shape, dtype=old_weight.dtype, device=old_weight.device)
        
        # è®¡ç®—å¯å¤åˆ¶çš„ç»´åº¦
        min_dims = [min(old_dim, new_dim) for old_dim, new_dim in zip(old_weight.shape, new_shape)]
        
        # å®‰å…¨å¤åˆ¶
        try:
            if len(old_weight.shape) == 4:  # 4Då·ç§¯æƒé‡
                new_weight[:min_dims[0], :min_dims[1], :min_dims[2], :min_dims[3]] = \
                    old_weight[:min_dims[0], :min_dims[1], :min_dims[2], :min_dims[3]]
            elif len(old_weight.shape) == 2:  # 2Dçº¿æ€§æƒé‡
                new_weight[:min_dims[0], :min_dims[1]] = old_weight[:min_dims[0], :min_dims[1]]
            elif len(old_weight.shape) == 1:  # 1Dåç½®
                new_weight[:min_dims[0]] = old_weight[:min_dims[0]]
            else:
                # é€šç”¨å¤åˆ¶
                slices = tuple(slice(0, dim) for dim in min_dims)
                new_weight[slices] = old_weight[slices]
        except Exception as e:
            print(f"    âš ï¸ å¤åˆ¶æƒé‡æ—¶å‡ºé”™: {str(e)}, ä½¿ç”¨åˆå§‹åŒ–")
        
        # åˆå§‹åŒ–æ–°å¢éƒ¨åˆ†
        if any(new_dim > old_dim for new_dim, old_dim in zip(new_shape, old_weight.shape)):
            with torch.no_grad():
                if 'conv' in key and len(new_shape) == 4:
                    torch.nn.init.kaiming_normal_(new_weight, mode='fan_in', nonlinearity='leaky_relu')
                    # æ¢å¤å·²å¤åˆ¶çš„éƒ¨åˆ†
                    if len(old_weight.shape) == 4:
                        new_weight[:min_dims[0], :min_dims[1], :min_dims[2], :min_dims[3]] = \
                            old_weight[:min_dims[0], :min_dims[1], :min_dims[2], :min_dims[3]]
                elif 'bias' in key:
                    # åç½®æ–°å¢éƒ¨åˆ†ä¿æŒä¸º0
                    pass
                else:
                    torch.nn.init.normal_(new_weight, mean=0, std=0.02)
                    # æ¢å¤å·²å¤åˆ¶çš„éƒ¨åˆ†
                    slices = tuple(slice(0, dim) for dim in min_dims)
                    new_weight[slices] = old_weight[slices]
        
        return new_weight

    def _initialize_weight_smart(self, weight_tensor, key):
        """
        æ™ºèƒ½æƒé‡åˆå§‹åŒ–
        """
        with torch.no_grad():
            if 'conv' in key and len(weight_tensor.shape) == 4:
                # å·ç§¯å±‚ä½¿ç”¨Kaimingåˆå§‹åŒ–
                torch.nn.init.kaiming_normal_(weight_tensor, mode='fan_in', nonlinearity='leaky_relu')
            elif 'bias' in key:
                # åç½®åˆå§‹åŒ–ä¸º0
                torch.nn.init.zeros_(weight_tensor)
            elif len(weight_tensor.shape) == 2:
                # çº¿æ€§å±‚ä½¿ç”¨Xavieråˆå§‹åŒ–
                torch.nn.init.xavier_uniform_(weight_tensor)
            else:
                # å…¶ä»–æƒ…å†µä½¿ç”¨æ­£æ€åˆ†å¸ƒ
                torch.nn.init.normal_(weight_tensor, mean=0, std=0.02)
        
        return weight_tensor

    # ... existing code ...
    
    def _adjust_features_weights(self, old_state_dict, new_state_dict, old_features, new_features):
        """
        è°ƒæ•´æƒé‡ä»¥åŒ¹é…æ–°çš„ç‰¹å¾æ•°
        æ”¯æŒæ‰©å±•å’Œæ”¶ç¼©ç‰¹å¾æ•°ï¼Œç‰¹åˆ«é’ˆå¯¹RRDBå¯†é›†è¿æ¥å±‚ä¼˜åŒ–
        """
        adjusted_state_dict = {}
        
        print(f"{Fore.CYAN}ğŸ”§ æƒé‡è°ƒæ•´è¯¦æƒ…: {old_features} -> {new_features} ç‰¹å¾æ•°{Style.RESET_ALL}")
        
        for key, new_weight in new_state_dict.items():
            if key in old_state_dict:
                old_weight = old_state_dict[key]
                
                try:
                    if old_weight.shape == new_weight.shape:
                        # å½¢çŠ¶ç›¸åŒï¼Œç›´æ¥å¤åˆ¶
                        adjusted_state_dict[key] = old_weight.clone()
                        print(f"âœ… {key}: ç›´æ¥å¤åˆ¶ {old_weight.shape}")
                        
                    elif 'conv' in key and 'weight' in key and len(old_weight.shape) == 4:
                        # å·ç§¯å±‚æƒé‡éœ€è¦ç‰¹æ®Šå¤„ç†
                        if 'rrdb_blocks' in key and 'dense' in key:
                            # RRDBå¯†é›†è¿æ¥å±‚
                            adjusted_weight = self._adjust_rrdb_dense_weight(old_weight, new_weight, key, old_features, new_features)
                            adjusted_state_dict[key] = adjusted_weight
                            print(f"ğŸ”— {key}: RRDBå¯†é›†è°ƒæ•´ {old_weight.shape} -> {new_weight.shape}")
                        elif self._is_direct_feature_related(key, old_weight, new_weight, old_features, new_features):
                            # ç›´æ¥ç‰¹å¾ç›¸å…³çš„æƒé‡
                            adjusted_weight = self._adjust_direct_feature_weight(old_weight, new_weight, key, old_features, new_features)
                            adjusted_state_dict[key] = adjusted_weight
                            print(f"ğŸ”§ {key}: ç›´æ¥ç‰¹å¾è°ƒæ•´ {old_weight.shape} -> {new_weight.shape}")
                        else:
                            # å…¶ä»–å·ç§¯å±‚ï¼Œä½¿ç”¨é€šç”¨è°ƒæ•´
                            adjusted_weight = self._adjust_general_conv_weight(old_weight, new_weight.shape, key)
                            adjusted_state_dict[key] = adjusted_weight
                            print(f"ğŸ”„ {key}: é€šç”¨è°ƒæ•´ {old_weight.shape} -> {new_weight.shape}")
                            
                    elif 'bias' in key and len(old_weight.shape) == 1:
                        # åç½®è°ƒæ•´
                        if self._is_direct_feature_related(key, old_weight, new_weight, old_features, new_features):
                            adjusted_weight = self._adjust_feature_bias(old_weight, new_weight, old_features, new_features)
                            adjusted_state_dict[key] = adjusted_weight
                            print(f"ğŸ”§ {key}: ç‰¹å¾åç½®è°ƒæ•´ {old_weight.shape} -> {new_weight.shape}")
                        else:
                            adjusted_state_dict[key] = old_weight.clone()
                            print(f"âœ… {key}: åç½®ç›´æ¥å¤åˆ¶ {old_weight.shape}")
                    else:
                        # å…¶ä»–ç±»å‹æƒé‡ï¼Œå°è¯•é€šç”¨è°ƒæ•´
                        adjusted_weight = self._adjust_general_weight(old_weight, new_weight.shape, key)
                        adjusted_state_dict[key] = adjusted_weight
                        print(f"ğŸ”„ {key}: å…¶ä»–è°ƒæ•´ {old_weight.shape} -> {new_weight.shape}")
                        
                except Exception as e:
                    print(f"{Fore.RED}ğŸ›‘ è°ƒæ•´å¤±è´¥è¯¦æƒ…:{Style.RESET_ALL}")
                    print(f"   æ“ä½œ: {key}")
                    print(f"   ç›®æ ‡å½¢çŠ¶: {new_weight.shape}")
                    print(f"   åŸå§‹å½¢çŠ¶: {old_weight.shape}")
                    print(f"   å±‚ç±»å‹: {'RRDBå¯†é›†å±‚' if 'dense' in key else 'æ™®é€šå·ç§¯å±‚'}")
                    print(f"   é”™è¯¯: {str(e)}")
                    raise
            else:
                # æ–°å¢çš„æƒé‡ï¼Œéšæœºåˆå§‹åŒ–
                adjusted_state_dict[key] = self._initialize_weight_smart(new_weight, key)
                print(f"ğŸ² {key}: éšæœºåˆå§‹åŒ– {new_weight.shape}")
        
        print(f"{Fore.GREEN}âœ… æƒé‡è°ƒæ•´å®Œæˆï¼Œå…±å¤„ç† {len(adjusted_state_dict)} ä¸ªæƒé‡{Style.RESET_ALL}")
        return adjusted_state_dict
    
    def _is_direct_feature_related(self, key, old_weight, new_weight, old_features, new_features):
        """åˆ¤æ–­æ˜¯å¦æ˜¯ç›´æ¥ç‰¹å¾ç›¸å…³çš„æƒé‡"""
        if 'conv' in key and 'weight' in key and len(old_weight.shape) == 4:
            old_out, old_in, _, _ = old_weight.shape
            new_out, new_in, _, _ = new_weight.shape
            
            # æ£€æŸ¥è¾“å‡ºæˆ–è¾“å…¥é€šé“æ˜¯å¦ç›´æ¥åŒ¹é…ç‰¹å¾æ•°å˜åŒ–
            return (old_out == old_features and new_out == new_features) or \
                   (old_in == old_features and new_in == new_features)
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯åç½®ä¸”é•¿åº¦åŒ¹é…ç‰¹å¾æ•°å˜åŒ–
        if 'bias' in key and len(old_weight.shape) == 1:
            return old_weight.shape[0] == old_features and new_weight.shape[0] == new_features
        
        return False
    
    def _adjust_rrdb_dense_weight(self, old_weight, new_weight, key, old_features, new_features):
        """
        ä¸“é—¨å¤„ç†RRDBå¯†é›†è¿æ¥å±‚çš„æƒé‡è°ƒæ•´
        ä¿®å¤é€šé“æ•°è®¡ç®—é”™è¯¯ï¼Œå¢åŠ åŠ¨æ€å¢é•¿ç‡è®¡ç®—
        """
        old_out, old_in, old_h, old_w = old_weight.shape
        new_out, new_in, new_h, new_w = new_weight.shape
        
        # è§£æå¯†é›†å±‚ä¿¡æ¯
        parts = key.split('.')
        block_idx = int(parts[1])
        dense_idx = int(parts[2][-1])
        conv_idx = int(parts[3][-1])
        
        # åŠ¨æ€è®¡ç®—å¢é•¿ç‡
        growth_rate = 32
        layer_order = (dense_idx - 1) * 5 + conv_idx
        
        print(f"    ğŸ”— RRDB Block{block_idx} Dense{dense_idx} Conv{conv_idx} (åºå·:{layer_order})")
        print(f"    ğŸ“Š é€šé“åˆ†æ: æ—§è¾“å…¥{old_in}, æ–°è¾“å…¥{new_in}")
        
        # åˆ›å»ºæ–°æƒé‡å¼ é‡
        new_weight_tensor = torch.zeros_like(new_weight)
        
        # å¤åˆ¶ç°æœ‰æƒé‡
        min_in = min(old_in, new_in)
        new_weight_tensor[:, :min_in] = old_weight[:, :min_in].clone()
        
        if new_in > old_in:
            # æ‰©å±•è¾“å…¥é€šé“
            remaining = new_in - old_in
            print(f"    ğŸ“ˆ æ‰©å±•å¯†é›†è¿æ¥è¾“å…¥é€šé“: +{remaining}")
            
            with torch.no_grad():
                if remaining <= old_in:
                    # å¤åˆ¶ç°æœ‰é€šé“å¹¶æ·»åŠ å™ªå£°
                    for i in range(remaining):
                        src_idx = i % old_in
                        dst_idx = old_in + i
                        new_weight_tensor[:, dst_idx] = old_weight[:, src_idx] * 0.8
                        noise = torch.randn_like(old_weight[:, src_idx]) * 0.01
                        new_weight_tensor[:, dst_idx] += noise
                else:
                    # ä½¿ç”¨Kaimingåˆå§‹åŒ–
                    torch.nn.init.kaiming_normal_(new_weight_tensor[:, old_in:], mode='fan_in', nonlinearity='leaky_relu')
        
        elif new_in < old_in:
            # æ”¶ç¼©è¾“å…¥é€šé“
            print(f"    ğŸ“‰ æ”¶ç¼©å¯†é›†è¿æ¥è¾“å…¥é€šé“: -{old_in - new_in}")
        
        return new_weight_tensor

    def _adjust_direct_feature_weight(self, old_weight, new_weight, key, old_features, new_features):
        """
        è°ƒæ•´ç›´æ¥ç‰¹å¾ç›¸å…³çš„æƒé‡ï¼ˆå¦‚conv_firstç­‰ï¼‰
        """
        old_out, old_in, old_h, old_w = old_weight.shape
        new_out, new_in, new_h, new_w = new_weight.shape
        
        # åˆ›å»ºæ–°æƒé‡å¼ é‡
        new_weight_tensor = torch.zeros_like(new_weight)
        
        if old_out == old_features and new_out == new_features:
            # è¾“å‡ºé€šé“è°ƒæ•´
            min_out = min(old_out, new_out)
            new_weight_tensor[:min_out] = old_weight[:min_out]
            
            if new_out > old_out:
                # æ‰©å±•è¾“å‡ºé€šé“
                remaining = new_out - old_out
                print(f"    ğŸ“ˆ æ‰©å±•è¾“å‡ºé€šé“: +{remaining}")
                
                # ä½¿ç”¨Kaimingåˆå§‹åŒ–
                with torch.no_grad():
                    torch.nn.init.kaiming_normal_(new_weight_tensor[old_out:], mode='fan_out', nonlinearity='leaky_relu')
            
        elif old_in == old_features and new_in == new_features:
            # è¾“å…¥é€šé“è°ƒæ•´
            min_in = min(old_in, new_in)
            new_weight_tensor[:, :min_in] = old_weight[:, :min_in]
            
            if new_in > old_in:
                # æ‰©å±•è¾“å…¥é€šé“
                remaining = new_in - old_in
                print(f"    ğŸ“ˆ æ‰©å±•è¾“å…¥é€šé“: +{remaining}")
                
                # ä½¿ç”¨Kaimingåˆå§‹åŒ–
                with torch.no_grad():
                    torch.nn.init.kaiming_normal_(new_weight_tensor[:, old_in:], mode='fan_in', nonlinearity='leaky_relu')
        
        return new_weight_tensor

    def _adjust_feature_bias(self, old_bias, new_bias, old_features, new_features):
        """
        è°ƒæ•´ç‰¹å¾ç›¸å…³çš„åç½®
        """
        new_bias_tensor = torch.zeros_like(new_bias)
        min_features = min(old_features, new_features)
        new_bias_tensor[:min_features] = old_bias[:min_features]
        
        if new_features > old_features:
            # æ‰©å±•åç½®ï¼Œæ–°å¢éƒ¨åˆ†åˆå§‹åŒ–ä¸º0
            remaining = new_features - old_features
            print(f"    ğŸ“ˆ æ‰©å±•åç½®: +{remaining}")
            new_bias_tensor[old_features:] = 0.0
        elif new_features < old_features:
            # æ”¶ç¼©åç½®
            print(f"    ğŸ“‰ æ”¶ç¼©åç½®: -{old_features - new_features}")
        
        return new_bias_tensor

    def _adjust_general_conv_weight(self, old_weight, new_shape, key):
        """
        é€šç”¨å·ç§¯æƒé‡è°ƒæ•´æ–¹æ³•
        """
        if old_weight.shape == new_shape:
            return old_weight.clone()
        
        old_out, old_in, old_h, old_w = old_weight.shape
        new_out, new_in, new_h, new_w = new_shape
        
        # åˆ›å»ºæ–°æƒé‡
        new_weight = torch.zeros(new_shape, dtype=old_weight.dtype, device=old_weight.device)
        
        # å¤åˆ¶å¯ä»¥å¤åˆ¶çš„éƒ¨åˆ†
        min_out = min(old_out, new_out)
        min_in = min(old_in, new_in)
        min_h = min(old_h, new_h)
        min_w = min(old_w, new_w)
        
        new_weight[:min_out, :min_in, :min_h, :min_w] = old_weight[:min_out, :min_in, :min_h, :min_w]
        
        # å¯¹äºæ–°å¢çš„éƒ¨åˆ†ï¼Œä½¿ç”¨Kaimingåˆå§‹åŒ–
        if new_out > old_out or new_in > old_in:
            with torch.no_grad():
                torch.nn.init.kaiming_normal_(new_weight, mode='fan_in', nonlinearity='leaky_relu')
                # ä¿ç•™å·²å¤åˆ¶çš„éƒ¨åˆ†
                new_weight[:min_out, :min_in, :min_h, :min_w] = old_weight[:min_out, :min_in, :min_h, :min_w]
        
        return new_weight

    def _adjust_general_weight(self, old_weight, new_shape, key):
        """
        é€šç”¨æƒé‡è°ƒæ•´æ–¹æ³•
        """
        if old_weight.shape == new_shape:
            return old_weight.clone()
        
        # åˆ›å»ºæ–°æƒé‡å¹¶ä½¿ç”¨æ™ºèƒ½åˆå§‹åŒ–
        new_weight = torch.zeros(new_shape, dtype=old_weight.dtype, device=old_weight.device)
        return self._initialize_weight_smart(new_weight, key)
    

    
    def _initialize_weight_smart(self, weight_tensor, key):
        """
        æ™ºèƒ½æƒé‡åˆå§‹åŒ–
        """
        with torch.no_grad():
            if 'conv' in key and len(weight_tensor.shape) == 4:
                # å·ç§¯å±‚ä½¿ç”¨Xavieråˆå§‹åŒ–
                torch.nn.init.xavier_uniform_(weight_tensor)
            elif 'bias' in key:
                # åç½®åˆå§‹åŒ–ä¸º0
                torch.nn.init.zeros_(weight_tensor)
            elif len(weight_tensor.shape) == 2:
                # çº¿æ€§å±‚ä½¿ç”¨Xavieråˆå§‹åŒ–
                torch.nn.init.xavier_uniform_(weight_tensor)
            else:
                # å…¶ä»–æƒ…å†µä½¿ç”¨æ­£æ€åˆ†å¸ƒ
                torch.nn.init.normal_(weight_tensor, mean=0, std=0.02)
        
        return weight_tensor
    
    def _progressive_feature_adjust(self, checkpoint_path, old_features, new_features, steps=3):
        """
        æ¸è¿›å¼ç‰¹å¾æ•°è°ƒæ•´ï¼Œé¿å…ä¸€æ¬¡æ€§å¤§å¹…è°ƒæ•´å¯¼è‡´çš„é—®é¢˜
        """
        print(f"{Fore.CYAN}ğŸš€ å¼€å§‹æ¸è¿›å¼ç‰¹å¾æ•°è°ƒæ•´: {old_features} -> {new_features} (åˆ†{steps}æ­¥){Style.RESET_ALL}")
        
        current_features = old_features
        # è®¡ç®—æ¯æ­¥å¢é‡ï¼ˆç¡®ä¿æœ€åä¸€æ­¥èƒ½åˆ°è¾¾ç›®æ ‡ï¼‰
        increment = (new_features - old_features) // steps
        if increment == 0:
            increment = 1
        
        base_name = os.path.splitext(os.path.basename(checkpoint_path))[0]
        checkpoint_dir = os.path.dirname(checkpoint_path)
        
        for step in range(steps):
            try:
                # è®¡ç®—å½“å‰æ­¥éª¤çš„ç›®æ ‡ç‰¹å¾æ•°
                if step == steps - 1:
                    target_features = new_features
                else:
                    target_features = current_features + increment
                    # ç¡®ä¿ä¸ä¼šè¶…è¿‡ç›®æ ‡
                    if (new_features > old_features and target_features > new_features) or \
                       (new_features < old_features and target_features < new_features):
                        target_features = new_features
                
                if target_features == current_features:
                    continue
                
                print(f"\n{Fore.YELLOW}ğŸ“ˆ æ­¥éª¤ {step+1}/{steps}: {current_features} -> {target_features}{Style.RESET_ALL}")
                
                # åŠ è½½å½“å‰æ£€æŸ¥ç‚¹
                if step == 0:
                    current_checkpoint_path = checkpoint_path
                else:
                    current_checkpoint_path = os.path.join(checkpoint_dir, f"{base_name}_step_{step}_features_{current_features}.pth")
                
                checkpoint = torch.load(current_checkpoint_path, map_location='cpu', weights_only=False)
                old_state_dict = checkpoint['generator_state_dict']
                
                # åˆ›å»ºç›®æ ‡æ¨¡å‹
                from src.models.esrgan import LiteRealESRGAN
                target_model = LiteRealESRGAN(
                    num_blocks=6,  # ä½¿ç”¨é»˜è®¤å—æ•°
                    num_features=target_features
                )
                new_state_dict = target_model.state_dict()
                
                # è°ƒæ•´æƒé‡
                adjusted_state_dict = self._adjust_features_weights(
                    old_state_dict, new_state_dict, current_features, target_features
                )
                
                # æ›´æ–°æ£€æŸ¥ç‚¹
                checkpoint['generator_state_dict'] = adjusted_state_dict
                
                # ä¿å­˜ä¸­é—´ç»“æœ
                step_output_path = os.path.join(checkpoint_dir, f"{base_name}_step_{step+1}_features_{target_features}.pth")
                torch.save(checkpoint, step_output_path)
                print(f"{Fore.GREEN}âœ… æ­¥éª¤ {step+1} å®Œæˆï¼Œä¿å­˜è‡³: {os.path.basename(step_output_path)}{Style.RESET_ALL}")
                
                # éªŒè¯å½“å‰æ­¥éª¤
                if self._verify_feature_adjustment(step_output_path, target_features):
                    current_features = target_features
                    print(f"{Fore.GREEN}âœ… æ­¥éª¤ {step+1} éªŒè¯é€šè¿‡{Style.RESET_ALL}")
                else:
                    print(f"{Fore.RED}âŒ æ­¥éª¤ {step+1} éªŒè¯å¤±è´¥ï¼Œåœæ­¢æ¸è¿›è°ƒæ•´{Style.RESET_ALL}")
                    return False, f"æ­¥éª¤ {step+1} éªŒè¯å¤±è´¥"
                
            except Exception as e:
                print(f"{Fore.RED}âŒ æ­¥éª¤ {step+1} è°ƒæ•´å¤±è´¥: {str(e)}{Style.RESET_ALL}")
                import traceback
                traceback.print_exc()
                return False, f"æ­¥éª¤ {step+1} å¤±è´¥: {str(e)}"
        
        # è¿”å›æœ€ç»ˆç»“æœ
        import shutil
        final_path = os.path.join(checkpoint_dir, f"{base_name}_features_{new_features}.pth")
        shutil.copy2(step_output_path, final_path)
        return True, final_path

    def _validate_rrdb_structure(self, state_dict, num_features):
        """
        éªŒè¯RRDBç»“æ„çš„é€šé“æ•°æ˜¯å¦æ­£ç¡®
        """
        print(f"{Fore.CYAN}ğŸ” éªŒè¯RRDBç»“æ„é€šé“æ•°...{Style.RESET_ALL}")
        
        growth_rate = 32
        errors = []
        
        for key, weight in state_dict.items():
            if 'rrdb_blocks' in key and 'dense' in key and 'conv' in key and 'weight' in key:
                parts = key.split('.')
                dense_idx = int(parts[2][-1])
                conv_idx = int(parts[3][-1])
                
                layer_order = (dense_idx - 1) * 5 + conv_idx
                expected_in = num_features + growth_rate * (layer_order - 1)
                actual_in = weight.shape[1]
                
                if actual_in != expected_in:
                    errors.append(f"{key}: é¢„æœŸ{expected_in}, å®é™…{actual_in}")
        
        if errors:
            print(f"{Fore.RED}âŒ å‘ç° {len(errors)} ä¸ªé€šé“æ•°é”™è¯¯:{Style.RESET_ALL}")
            for error in errors[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªé”™è¯¯
                print(f"    {error}")
            if len(errors) > 5:
                print(f"    ... è¿˜æœ‰ {len(errors)-5} ä¸ªé”™è¯¯")
            return False
        else:
            print(f"{Fore.GREEN}âœ… RRDBç»“æ„éªŒè¯é€šè¿‡{Style.RESET_ALL}")
            return True

    def _verify_feature_adjustment(self, checkpoint_path, expected_features):
        """
        éªŒè¯ç‰¹å¾æ•°è°ƒæ•´ç»“æœ
        """
        try:
            print(f"{Fore.CYAN}ğŸ” éªŒè¯è°ƒæ•´ç»“æœ...{Style.RESET_ALL}")
            
            # 1. æ£€æµ‹ç‰¹å¾æ•°
            detected_config = self._detect_checkpoint_config(checkpoint_path)
            if detected_config and detected_config['num_features'] == expected_features:
                print(f"{Fore.GREEN}âœ… ç‰¹å¾æ•°éªŒè¯é€šè¿‡: {expected_features}{Style.RESET_ALL}")
            else:
                print(f"{Fore.RED}âŒ ç‰¹å¾æ•°éªŒè¯å¤±è´¥{Style.RESET_ALL}")
                return False
            
            # 2. æµ‹è¯•æ¨¡å‹åŠ è½½
            from src.models.esrgan import LiteRealESRGAN
            model = LiteRealESRGAN(
                num_blocks=6,  # ä½¿ç”¨é»˜è®¤å€¼è€Œä¸æ˜¯self.config
                num_features=expected_features
            )
            
            checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)
            model.load_state_dict(checkpoint['generator_state_dict'])
            print(f"{Fore.GREEN}âœ… æ¨¡å‹åŠ è½½éªŒè¯é€šè¿‡{Style.RESET_ALL}")
            
            # 3. æµ‹è¯•å‰å‘ä¼ æ’­
            model.eval()
            test_input = torch.randn(1, 3, 64, 64)
            with torch.no_grad():
                output = model(test_input)
            print(f"{Fore.GREEN}âœ… å‰å‘ä¼ æ’­éªŒè¯é€šè¿‡: {test_input.shape} -> {output.shape}{Style.RESET_ALL}")
            
            return True
            
        except Exception as e:
            print(f"{Fore.RED}âŒ éªŒè¯å¤±è´¥: {str(e)}{Style.RESET_ALL}")
            return False
    
    def _is_new_rrdb_block(self, key, old_blocks):
        """åˆ¤æ–­æ˜¯å¦æ˜¯æ–°å¢çš„RRDBå—"""
        import re
        match = re.match(r'rrdb_blocks\.(\d+)\.', key)
        if match:
            block_idx = int(match.group(1))
            return block_idx >= old_blocks
        return False
    
    def _get_source_block_key(self, key, old_state_dict, old_blocks):
        """è·å–æºå—çš„æƒé‡é”®"""
        if old_blocks == 0:
            return None
            
        import re
        match = re.match(r'(rrdb_blocks\.)(\d+)(\..+)', key)
        if match:
            prefix = match.group(1)
            block_idx = int(match.group(2))
            suffix = match.group(3)
            
            # ä½¿ç”¨æœ€åä¸€ä¸ªæ—§å—ä½œä¸ºæº
            source_idx = old_blocks - 1
            source_key = f"{prefix}{source_idx}{suffix}"
            
            if source_key in old_state_dict:
                return source_key
        return None
    
    def _initialize_weight(self, weight_tensor):
        """åˆå§‹åŒ–æ–°æƒé‡"""
        with torch.no_grad():
            if len(weight_tensor.shape) == 4:  # å·ç§¯å±‚
                torch.nn.init.kaiming_normal_(weight_tensor, mode='fan_in', nonlinearity='leaky_relu')
            elif len(weight_tensor.shape) == 1:  # åç½®
                torch.nn.init.zeros_(weight_tensor)
            else:  # å…¶ä»–
                torch.nn.init.normal_(weight_tensor, mean=0, std=0.02)
        return weight_tensor
    
    def _smart_resize_weight(self, old_weight, new_shape, key):
        """æ™ºèƒ½è°ƒæ•´æƒé‡å°ºå¯¸çš„é€šç”¨æ–¹æ³•"""
        if old_weight.shape == new_shape:
            return old_weight.clone()
            
        # åˆ›å»ºæ–°æƒé‡å¼ é‡
        new_weight = torch.zeros(new_shape, dtype=old_weight.dtype, device=old_weight.device)
        
        # è®¡ç®—å¯å¤åˆ¶çš„ç»´åº¦å¤§å°
        min_dims = [min(old_dim, new_dim) for old_dim, new_dim in zip(old_weight.shape, new_shape)]
        
        # åˆ›å»ºåˆ‡ç‰‡å…ƒç»„
        slices = tuple(slice(0, dim) for dim in min_dims)
        
        # å¤åˆ¶å¯å¤åˆ¶çš„éƒ¨åˆ†
        new_weight[slices] = old_weight[slices].clone()
        
        # å¯¹äºå·ç§¯å±‚ï¼Œåˆå§‹åŒ–æ–°å¢éƒ¨åˆ†
        if 'conv' in key and len(new_shape) == 4:
            with torch.no_grad():
                # ä¿å­˜å·²å¤åˆ¶éƒ¨åˆ†
                copied_part = new_weight[slices].clone()
                # æ•´ä½“åˆå§‹åŒ–
                torch.nn.init.kaiming_normal_(new_weight, mode='fan_in', nonlinearity='leaky_relu')
                # æ¢å¤å·²å¤åˆ¶éƒ¨åˆ†
                new_weight[slices] = copied_part
        
        # å¯¹äºåç½®ï¼Œæ–°å¢éƒ¨åˆ†åˆå§‹åŒ–ä¸º0
        elif 'bias' in key:
            new_weight[min_dims[0]:] = 0.0
            
        return new_weight
    def _detect_checkpoint_config(self, checkpoint_path):
        """æ£€æµ‹æ£€æŸ¥ç‚¹çš„æ¨¡å‹é…ç½®"""
        try:
            checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)
            
            # è·å–çŠ¶æ€å­—å…¸
            state_dict = None
            if 'generator_state_dict' in checkpoint:
                state_dict = checkpoint['generator_state_dict']
            elif 'model_state_dict' in checkpoint:
                state_dict = checkpoint['model_state_dict']
            elif 'state_dict' in checkpoint:
                state_dict = checkpoint['state_dict']
            else:
                if any(key.startswith(('conv_first', 'rrdb_blocks', 'conv_last')) for key in checkpoint.keys()):
                    state_dict = checkpoint
                else:
                    return None
            
            if state_dict is None:
                return None
            
            # æ£€æµ‹ç‰¹å¾æ•°
            num_features = None
            for key, tensor in state_dict.items():
                if 'conv_first.weight' in key:
                    num_features = tensor.shape[0]
                    break
            
            # æ£€æµ‹å—æ•°
            num_blocks = 0
            for key in state_dict.keys():
                if 'rrdb_blocks.' in key:
                    import re
                    block_match = re.search(r'rrdb_blocks\.(\d+)\.', key)
                    if block_match:
                        block_num = int(block_match.group(1))
                        num_blocks = max(num_blocks, block_num + 1)
            
            if num_blocks > 0 and num_features is not None:
                return {
                    'num_blocks': num_blocks,
                    'num_features': num_features
                }
            else:
                return None
                
        except Exception as e:
            return None

class ConsoleTrainer:
    def __init__(self):
        """åˆå§‹åŒ–æ§åˆ¶å°è®­ç»ƒå™¨"""
        self.config = load_config()
        self.gpu_info = self.get_gpu_info()
        self.compatibility_checker = ModelCompatibilityChecker()
        self.gpu_optimizer = GPUOptimizer()
        
        # æ ¹æ®GPUè‡ªåŠ¨è°ƒæ•´é…ç½®
        self.check_and_adjust_memory_config()
        
        # å¦‚æœæ˜¯RTX 4090ï¼Œè‡ªåŠ¨å¯ç”¨ä¼˜åŒ–
        if self.gpu_info["available"] and "4090" in self.gpu_info.get("name", ""):
            self.config = load_rtx_4090_config()
            if self.config.get("rtx_4090", {}).get("tf32_enabled", False):
                self.gpu_optimizer.enable_tf32()
            if self.config.get("rtx_4090", {}).get("compile_enabled", False):
                self.gpu_optimizer.enable_compile()
            print(f"{Fore.GREEN}ğŸš€ æ£€æµ‹åˆ°RTX 4090ï¼Œå·²è‡ªåŠ¨å¯ç”¨ä¸“ç”¨ä¼˜åŒ–{Style.RESET_ALL}")

    def check_and_adjust_memory_config(self):
        """æ£€æŸ¥GPUæ˜¾å­˜å¹¶è‡ªåŠ¨è°ƒæ•´é…ç½®"""
        if not self.gpu_info["available"]:
            return
        
        gpu_memory = self.gpu_info["memory"]
        print(f"{Fore.CYAN}æ£€æµ‹åˆ°GPUæ˜¾å­˜: {gpu_memory:.1f}GB{Style.RESET_ALL}")
        
        # ä½¿ç”¨è‡ªåŠ¨é…ç½®
        auto_config = auto_config_by_gpu_memory(gpu_memory)
        
        # åˆå¹¶é…ç½®ï¼ˆä¿ç•™ç”¨æˆ·è‡ªå®šä¹‰è®¾ç½®ï¼‰
        for key, value in auto_config.items():
            if key not in self.config:
                self.config[key] = value
            elif isinstance(value, dict):
                for sub_key, sub_value in value.items():
                    if sub_key not in self.config[key]:
                        self.config[key][sub_key] = sub_value
        
        print(f"{Fore.GREEN}âœ… å·²æ ¹æ®GPUæ˜¾å­˜è‡ªåŠ¨è°ƒæ•´é…ç½®{Style.RESET_ALL}")

    def get_gpu_info(self):
        """è·å–GPUä¿¡æ¯"""
        gpu_info = {
            "available": torch.cuda.is_available(),
            "name": "",
            "memory": 0.0,
            "count": 0
        }
        
        if gpu_info["available"]:
            try:
                gpu_info["name"] = torch.cuda.get_device_name(0)
                gpu_info["memory"] = torch.cuda.get_device_properties(0).total_memory / 1024**3  # GB
                gpu_info["count"] = torch.cuda.device_count()
            except Exception as e:
                print(f"{Fore.YELLOW}âš ï¸  è·å–GPUä¿¡æ¯å¤±è´¥: {e}{Style.RESET_ALL}")
        
        return gpu_info

    def clear_screen(self):
        """æ¸…å±"""
        os.system('cls' if os.name == 'nt' else 'clear')

    def print_header(self):
        """æ‰“å°æ ‡é¢˜"""
        print(f"\n{Fore.CYAN}{'='*60}{Style.RESET_ALL}")
        print(f"{Fore.YELLOW}ğŸ¤– AIå›¾åƒè¶…åˆ†è¾¨ç‡è®­ç»ƒæ§åˆ¶å°{Style.RESET_ALL}")
        print(f"{Fore.CYAN}{'='*60}{Style.RESET_ALL}")

    def print_gpu_info(self):
        """æ‰“å°GPUä¿¡æ¯"""
        if self.gpu_info["available"]:
            print(f"\n{Fore.GREEN}ğŸ® GPUä¿¡æ¯:{Style.RESET_ALL}")
            print(f"è®¾å¤‡: {self.gpu_info['name']}")
            print(f"æ˜¾å­˜: {self.gpu_info['memory']:.1f} GB")
            print(f"æ•°é‡: {self.gpu_info['count']}")
            
            # æ˜¾ç¤ºä¼˜åŒ–çŠ¶æ€
            if hasattr(self, 'gpu_optimizer'):
                print(f"TF32: {'âœ…å¯ç”¨' if self.gpu_optimizer.tf32_enabled else 'âŒç¦ç”¨'}")
                print(f"ç¼–è¯‘: {'âœ…å¯ç”¨' if self.gpu_optimizer.compile_enabled else 'âŒç¦ç”¨'}")
        else:
            print(f"\n{Fore.RED}âŒ æœªæ£€æµ‹åˆ°å¯ç”¨GPUï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒ{Style.RESET_ALL}")

    def print_main_menu(self):
        """æ‰“å°ä¸»èœå•"""
        print(f"\n{Fore.CYAN}ğŸ“‹ ä¸»èœå•:{Style.RESET_ALL}")
        print(f"{Fore.WHITE}1.{Style.RESET_ALL} å¼€å§‹æ–°è®­ç»ƒ")
        print(f"{Fore.WHITE}2.{Style.RESET_ALL} å¢é‡è®­ç»ƒ")
        print(f"{Fore.WHITE}3.{Style.RESET_ALL} éªŒè¯æ¨¡å‹")
        print(f"{Fore.WHITE}4.{Style.RESET_ALL} é…ç½®ç®¡ç†")
        print(f"{Fore.WHITE}5.{Style.RESET_ALL} GPUä¼˜åŒ–è®¾ç½®")
        print(f"{Fore.WHITE}6.{Style.RESET_ALL} æ£€æŸ¥ç‚¹ç®¡ç†")
        print(f"{Fore.WHITE}7.{Style.RESET_ALL} æ€§èƒ½ç›‘æ§")
        print(f"{Fore.WHITE}8.{Style.RESET_ALL} é€€å‡ºç¨‹åº")

    def start_incremental_training(self):
        """å¯åŠ¨å¢é‡è®­ç»ƒ"""
        # æ£€æŸ¥æ•°æ®ç›®å½•
        if not self._check_data_directories():
            return
        
        # é€‰æ‹©æ£€æŸ¥ç‚¹æ–‡ä»¶
        checkpoint_files = [f for f in os.listdir('checkpoints') if f.endswith('.pth')]
        if not checkpoint_files:
            print(f"{Fore.RED}âŒ æ²¡æœ‰æ‰¾åˆ°æ£€æŸ¥ç‚¹æ–‡ä»¶{Style.RESET_ALL}")
            return
        
        print(f"\n{Fore.CYAN}ğŸ“ å¯ç”¨çš„æ£€æŸ¥ç‚¹æ–‡ä»¶:{Style.RESET_ALL}")
        for i, file in enumerate(checkpoint_files, 1):
            print(f"{i}. {file}")
        
        try:
            choice = int(input(f"\n{Fore.CYAN}è¯·é€‰æ‹©æ£€æŸ¥ç‚¹æ–‡ä»¶ (1-{len(checkpoint_files)}): {Style.RESET_ALL}"))
            if 1 <= choice <= len(checkpoint_files):
                selected_file = checkpoint_files[choice - 1]
                checkpoint_path = os.path.join('checkpoints', selected_file)
                
                # å¦‚æœé€‰æ‹©çš„æ˜¯è°ƒæ•´æ–‡ä»¶ï¼Œå…ˆåˆ é™¤å®ƒï¼Œä½¿ç”¨åŸå§‹æ–‡ä»¶é‡æ–°è°ƒæ•´
                if '_adjusted' in selected_file:
                    original_file = selected_file.replace('_adjusted', '')
                    original_path = os.path.join('checkpoints', original_file)
                    
                    if os.path.exists(original_path):
                        # åˆ é™¤æœ‰é—®é¢˜çš„è°ƒæ•´æ–‡ä»¶
                        try:
                            os.remove(checkpoint_path)
                            print(f"{Fore.GREEN}âœ… å·²åˆ é™¤æœ‰é—®é¢˜çš„è°ƒæ•´æ–‡ä»¶: {selected_file}{Style.RESET_ALL}")
                        except Exception as e:
                            print(f"{Fore.YELLOW}âš ï¸  åˆ é™¤è°ƒæ•´æ–‡ä»¶å¤±è´¥: {e}{Style.RESET_ALL}")
                        
                        # ä½¿ç”¨åŸå§‹æ–‡ä»¶
                        checkpoint_path = original_path
                        selected_file = original_file
                        print(f"{Fore.CYAN}ğŸ”„ æ”¹ç”¨åŸå§‹æ–‡ä»¶: {selected_file}{Style.RESET_ALL}")
                
                # è‡ªåŠ¨æ£€æµ‹æ£€æŸ¥ç‚¹é…ç½®å¹¶åŒ¹é…
                print(f"\n{Fore.CYAN}ğŸ” æ£€æµ‹æ£€æŸ¥ç‚¹é…ç½®...{Style.RESET_ALL}")
                checkpoint_config = self._detect_checkpoint_config(checkpoint_path)
                
                if checkpoint_config:
                    current_blocks = self.config['model']['num_blocks']
                    current_features = self.config['model']['num_features']
                    checkpoint_blocks = checkpoint_config['num_blocks']
                    checkpoint_features = checkpoint_config['num_features']
                    
                    print(f"\n{Fore.CYAN}ğŸ“Š é…ç½®å¯¹æ¯”:{Style.RESET_ALL}")
                    print(f"{Fore.CYAN}æ£€æŸ¥ç‚¹æ¨¡å‹: {checkpoint_blocks}å—, {checkpoint_features}ç‰¹å¾{Style.RESET_ALL}")
                    print(f"{Fore.CYAN}å½“å‰é…ç½®:   {current_blocks}å—, {current_features}ç‰¹å¾{Style.RESET_ALL}")
                    
                    # æ£€æŸ¥æ˜¯å¦å®Œå…¨åŒ¹é…
                    blocks_match = current_blocks == checkpoint_blocks
                    features_match = current_features == checkpoint_features
                    
                    if blocks_match and features_match:
                        print(f"{Fore.GREEN}âœ… é…ç½®å®Œå…¨åŒ¹é…ï¼Œå¯ä»¥ç›´æ¥åŠ è½½{Style.RESET_ALL}")
                    else:
                        print(f"{Fore.YELLOW}âš ï¸  é…ç½®ä¸åŒ¹é…ï¼{Style.RESET_ALL}")
                        if not blocks_match:
                            print(f"{Fore.YELLOW}  - å—æ•°ä¸åŒ¹é…: {current_blocks} vs {checkpoint_blocks}{Style.RESET_ALL}")
                        if not features_match:
                            print(f"{Fore.YELLOW}  - ç‰¹å¾æ•°ä¸åŒ¹é…: {current_features} vs {checkpoint_features}{Style.RESET_ALL}")
                        
                        # å¼ºåˆ¶åˆ·æ–°è¾“å‡ºç¼“å†²åŒº
                        import sys
                        sys.stdout.flush()
                        
                        # ğŸ”¥ æ–°å¢ï¼šæ™ºèƒ½ç‰¹å¾æ•°è°ƒæ•´é€‰é¡¹
                        if not features_match and blocks_match:
                            # åªæœ‰ç‰¹å¾æ•°ä¸åŒ¹é…ï¼Œæä¾›æ™ºèƒ½è°ƒæ•´é€‰é¡¹
                            print(f"\n{Fore.CYAN}ğŸ¯ æ£€æµ‹åˆ°ä»…ç‰¹å¾æ•°ä¸åŒ¹é…ï¼Œæä¾›æ™ºèƒ½è°ƒæ•´é€‰é¡¹:{Style.RESET_ALL}")
                            print(f"{Fore.WHITE}1.{Style.RESET_ALL} æ™ºèƒ½è°ƒæ•´æ£€æŸ¥ç‚¹ç‰¹å¾æ•°ä»¥åŒ¹é…é…ç½® ({checkpoint_features} -> {current_features}) ğŸ”¥æ¨è")
                            print(f"{Fore.WHITE}2.{Style.RESET_ALL} è°ƒæ•´é…ç½®ä»¥åŒ¹é…æ£€æŸ¥ç‚¹ ({current_features} -> {checkpoint_features})")
                            print(f"{Fore.WHITE}3.{Style.RESET_ALL} ä½¿ç”¨é€šç”¨å…¼å®¹æ€§è°ƒæ•´")
                            print(f"{Fore.WHITE}4.{Style.RESET_ALL} å–æ¶ˆæ“ä½œ")
                            
                            # å¼ºåˆ¶åˆ·æ–°è¾“å‡ºç¼“å†²åŒº
                            sys.stdout.flush()
                            
                            feature_choice = input(f"\n{Fore.CYAN}è¯·é€‰æ‹© (1-4): {Style.RESET_ALL}").strip()
                            
                            if feature_choice == '1':
                                # æ™ºèƒ½ç‰¹å¾æ•°è°ƒæ•´
                                success, result = self.compatibility_checker.smart_adjust_features_enhanced(
                                    checkpoint_path, current_features
                                )
                                if success:
                                    checkpoint_path = result
                                    print(f"{Fore.GREEN}âœ… ç‰¹å¾æ•°è°ƒæ•´æˆåŠŸï¼{Style.RESET_ALL}")
                                else:
                                    print(f"{Fore.RED}âŒ ç‰¹å¾æ•°è°ƒæ•´å¤±è´¥: {result}{Style.RESET_ALL}")
                                    return
                            elif feature_choice == '2':
                                # è°ƒæ•´é…ç½®ä»¥åŒ¹é…æ£€æŸ¥ç‚¹
                                self._adjust_config_to_match_checkpoint(checkpoint_config)
                                print(f"{Fore.GREEN}âœ… å·²è°ƒæ•´é…ç½®ä»¥åŒ¹é…æ£€æŸ¥ç‚¹{Style.RESET_ALL}")
                            elif feature_choice == '3':
                                # ä½¿ç”¨é€šç”¨å…¼å®¹æ€§è°ƒæ•´
                                print(f"{Fore.CYAN}ğŸ”§ æ­£åœ¨ä½¿ç”¨é€šç”¨å…¼å®¹æ€§è°ƒæ•´...{Style.RESET_ALL}")
                                success, result = self.compatibility_checker.adjust_checkpoint_for_new_config(
                                    checkpoint_path, self.config
                                )
                                if success:
                                    checkpoint_path = result
                                    print(f"{Fore.GREEN}âœ… é€šç”¨è°ƒæ•´æˆåŠŸ: {os.path.basename(result)}{Style.RESET_ALL}")
                                else:
                                    print(f"{Fore.RED}âŒ é€šç”¨è°ƒæ•´å¤±è´¥: {result}{Style.RESET_ALL}")
                                    return
                            else:
                                print(f"{Fore.YELLOW}âŒ ç”¨æˆ·å–æ¶ˆæ“ä½œ{Style.RESET_ALL}")
                                return
                        else:
                            # å…¶ä»–ä¸åŒ¹é…æƒ…å†µï¼Œä½¿ç”¨åŸæœ‰é€»è¾‘
                            print(f"\n{Fore.CYAN}è¯·é€‰æ‹©å¤„ç†æ–¹å¼:{Style.RESET_ALL}")
                            print(f"{Fore.WHITE}1.{Style.RESET_ALL} è‡ªåŠ¨è°ƒæ•´å½“å‰é…ç½®ä»¥åŒ¹é…æ£€æŸ¥ç‚¹ (æ¨è)")
                            print(f"{Fore.WHITE}2.{Style.RESET_ALL} è°ƒæ•´æ£€æŸ¥ç‚¹ä»¥é€‚åº”å½“å‰é…ç½®")
                            print(f"{Fore.WHITE}3.{Style.RESET_ALL} å–æ¶ˆæ“ä½œ")
                            
                            config_choice = input(f"\n{Fore.CYAN}è¯·é€‰æ‹© (1-3): {Style.RESET_ALL}").strip()
                            
                            if config_choice == '1':
                                # è°ƒæ•´å½“å‰é…ç½®ä»¥åŒ¹é…æ£€æŸ¥ç‚¹
                                self._adjust_config_to_match_checkpoint(checkpoint_config)
                                print(f"{Fore.GREEN}âœ… å·²è°ƒæ•´é…ç½®ä»¥åŒ¹é…æ£€æŸ¥ç‚¹{Style.RESET_ALL}")
                            elif config_choice == '2':
                                # è°ƒæ•´æ£€æŸ¥ç‚¹ä»¥é€‚åº”å½“å‰é…ç½®
                                print(f"{Fore.CYAN}ğŸ”§ æ­£åœ¨è°ƒæ•´æ£€æŸ¥ç‚¹...{Style.RESET_ALL}")
                                success, result = self.compatibility_checker.adjust_checkpoint_for_new_config(
                                    checkpoint_path, self.config
                                )
                                
                                if success:
                                    checkpoint_path = result
                                    print(f"{Fore.GREEN}âœ… æ£€æŸ¥ç‚¹è°ƒæ•´æˆåŠŸ: {os.path.basename(result)}{Style.RESET_ALL}")
                                else:
                                    print(f"{Fore.RED}âŒ æ£€æŸ¥ç‚¹è°ƒæ•´å¤±è´¥: {result}{Style.RESET_ALL}")
                                    return
                            else:
                                print(f"{Fore.YELLOW}âŒ ç”¨æˆ·å–æ¶ˆæ“ä½œ{Style.RESET_ALL}")
                                return
                else:
                    print(f"{Fore.RED}âŒ æ— æ³•æ£€æµ‹æ£€æŸ¥ç‚¹é…ç½®ï¼Œå°†ä½¿ç”¨å…¼å®¹æ€§æ£€æŸ¥å™¨{Style.RESET_ALL}")
                    # å›é€€åˆ°åŸæ¥çš„å…¼å®¹æ€§æ£€æŸ¥
                    is_compatible, message = self.compatibility_checker.check_model_compatibility(checkpoint_path, self.config)
                    
                    if not is_compatible:
                        print(f"{Fore.YELLOW}âš ï¸  {message}{Style.RESET_ALL}")
                        adjust = input(f"{Fore.CYAN}æ˜¯å¦è°ƒæ•´æ¨¡å‹ä»¥é€‚åº”å½“å‰é…ç½®? (y/n): {Style.RESET_ALL}").lower().strip()
                        
                        if adjust == 'y':
                            print(f"{Fore.CYAN}ğŸ”§ æ­£åœ¨è°ƒæ•´æ¨¡å‹...{Style.RESET_ALL}")
                            
                            # å°è¯•æ£€æµ‹æ£€æŸ¥ç‚¹é…ç½®è¿›è¡Œæ™ºèƒ½è°ƒæ•´
                            checkpoint_config = self._detect_checkpoint_config(checkpoint_path)
                            if checkpoint_config:
                                current_blocks = self.config['model']['num_blocks']
                                current_features = self.config['model']['num_features']
                                checkpoint_blocks = checkpoint_config['num_blocks']
                                checkpoint_features = checkpoint_config['num_features']
                                
                                # å¦‚æœåªæ˜¯ç‰¹å¾æ•°ä¸åŒ¹é…ï¼Œä½¿ç”¨æ™ºèƒ½ç‰¹å¾è°ƒæ•´
                                if current_blocks == checkpoint_blocks and current_features != checkpoint_features:
                                    print(f"{Fore.CYAN}ğŸ¯ ä½¿ç”¨æ™ºèƒ½ç‰¹å¾è°ƒæ•´: {checkpoint_features} -> {current_features}{Style.RESET_ALL}")
                                    success, result = self.compatibility_checker.smart_adjust_features_enhanced(
                                        checkpoint_path, current_features
                                    )
                                else:
                                    # ä½¿ç”¨é€šç”¨è°ƒæ•´æ–¹æ³•
                                    success, result = self.compatibility_checker.adjust_checkpoint_for_new_config(
                                        checkpoint_path, self.config
                                    )
                            else:
                                # å›é€€åˆ°é€šç”¨è°ƒæ•´æ–¹æ³•
                                success, result = self.compatibility_checker.adjust_checkpoint_for_new_config(
                                    checkpoint_path, self.config
                                )
                            
                            if success:
                                checkpoint_path = result
                                print(f"{Fore.GREEN}âœ… æ¨¡å‹è°ƒæ•´æˆåŠŸ: {os.path.basename(result)}{Style.RESET_ALL}")
                            else:
                                print(f"{Fore.RED}âŒ æ¨¡å‹è°ƒæ•´å¤±è´¥: {result}{Style.RESET_ALL}")
                                return
                        else:
                            print(f"{Fore.YELLOW}âŒ ç”¨æˆ·å–æ¶ˆè°ƒæ•´{Style.RESET_ALL}")
                            return
                
                # åœ¨æ–°çº¿ç¨‹ä¸­å¯åŠ¨è®­ç»ƒ
                print(f"\n{Fore.GREEN}ğŸš€ å¯åŠ¨å¢é‡è®­ç»ƒ...{Style.RESET_ALL}")
                
                def training_worker():
                    try:
                        from src.training.train_manager import MemoryOptimizedTrainingManager
                        trainer = MemoryOptimizedTrainingManager(self.config)
                        trainer.start_incremental_training(checkpoint_path)
                    except Exception as e:
                        print(f"{Fore.RED}âŒ è®­ç»ƒè¿‡ç¨‹å‡ºé”™: {e}{Style.RESET_ALL}")
                        import traceback
                        traceback.print_exc()
                
                import threading
                training_thread = threading.Thread(target=training_worker)
                training_thread.daemon = True
                training_thread.start()
                
                print(f"{Fore.GREEN}âœ… å¢é‡è®­ç»ƒå·²åœ¨åå°å¯åŠ¨{Style.RESET_ALL}")
                print(f"{Fore.YELLOW}ğŸ’¡ æ‚¨å¯ä»¥ç»§ç»­ä½¿ç”¨å…¶ä»–åŠŸèƒ½ï¼Œè®­ç»ƒå°†åœ¨åå°è¿›è¡Œ{Style.RESET_ALL}")
                
            else:
                print(f"{Fore.RED}âŒ æ— æ•ˆé€‰æ‹©{Style.RESET_ALL}")
                
        except ValueError:
            print(f"{Fore.RED}âŒ è¯·è¾“å…¥æœ‰æ•ˆæ•°å­—{Style.RESET_ALL}")
        except Exception as e:
            print(f"{Fore.RED}âŒ å¢é‡è®­ç»ƒå¯åŠ¨å¤±è´¥: {e}{Style.RESET_ALL}")
            import traceback
            traceback.print_exc()
        
        input(f"\n{Fore.YELLOW}æŒ‰å›è½¦é”®ç»§ç»­...{Style.RESET_ALL}")

    def _detect_checkpoint_config(self, checkpoint_path):
        """æ£€æµ‹æ£€æŸ¥ç‚¹çš„æ¨¡å‹é…ç½®"""
        try:
            print(f"{Fore.CYAN}ğŸ” æ­£åœ¨åˆ†ææ£€æŸ¥ç‚¹æ–‡ä»¶: {os.path.basename(checkpoint_path)}{Style.RESET_ALL}")
            checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)
            
            # å°è¯•å¤šç§å¯èƒ½çš„çŠ¶æ€å­—å…¸é”®
            state_dict = None
            if 'generator_state_dict' in checkpoint:
                state_dict = checkpoint['generator_state_dict']
                print(f"{Fore.GREEN}âœ… æ‰¾åˆ°generator_state_dict{Style.RESET_ALL}")
            elif 'model_state_dict' in checkpoint:
                state_dict = checkpoint['model_state_dict']
                print(f"{Fore.GREEN}âœ… æ‰¾åˆ°model_state_dict{Style.RESET_ALL}")
            elif 'state_dict' in checkpoint:
                state_dict = checkpoint['state_dict']
                print(f"{Fore.GREEN}âœ… æ‰¾åˆ°state_dict{Style.RESET_ALL}")
            else:
                # æ£€æŸ¥æ˜¯å¦ç›´æ¥æ˜¯çŠ¶æ€å­—å…¸
                if any(key.startswith(('conv_first', 'rrdb_blocks', 'conv_last')) for key in checkpoint.keys()):
                    state_dict = checkpoint
                    print(f"{Fore.GREEN}âœ… ç›´æ¥ä½¿ç”¨checkpointä½œä¸ºstate_dict{Style.RESET_ALL}")
                else:
                    print(f"{Fore.YELLOW}âš ï¸  æœªæ‰¾åˆ°æ ‡å‡†çš„çŠ¶æ€å­—å…¸{Style.RESET_ALL}")
                    return None
            
            if state_dict is None:
                return None
            
            # æ£€æµ‹ç‰¹å¾æ•°
            num_features = None
            for key, tensor in state_dict.items():
                if 'conv_first.weight' in key:
                    num_features = tensor.shape[0]  # è¾“å‡ºé€šé“æ•°
                    print(f"{Fore.GREEN}âœ… ä»conv_first.weightæ£€æµ‹åˆ°ç‰¹å¾æ•°: {num_features}{Style.RESET_ALL}")
                    break
            
            # æ£€æµ‹å—æ•°
            num_blocks = 0
            rrdb_keys = []
            for key in state_dict.keys():
                if 'rrdb_blocks.' in key:
                    rrdb_keys.append(key)
                    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–å—ç¼–å·
                    import re
                    block_match = re.search(r'rrdb_blocks\.(\d+)\.', key)
                    if block_match:
                        block_num = int(block_match.group(1))
                        num_blocks = max(num_blocks, block_num + 1)
            
            if rrdb_keys:
                print(f"{Fore.GREEN}âœ… ä½¿ç”¨æ¨¡å¼'rrdb_blocks.'æ£€æµ‹åˆ°RRDBå—æ•°: {num_blocks}{Style.RESET_ALL}")
                print(f"{Fore.CYAN}ğŸ“‹ æ‰¾åˆ° {len(rrdb_keys)} ä¸ªRRDBç›¸å…³æƒé‡{Style.RESET_ALL}")
                
                # æ˜¾ç¤ºä¸€äº›ç¤ºä¾‹é”®
                unique_blocks = set()
                for key in rrdb_keys[:20]:  # åªæ˜¾ç¤ºå‰20ä¸ª
                    block_match = re.search(r'rrdb_blocks\.(\d+)', key)
                    if block_match:
                        unique_blocks.add(f"rrdb_blocks.{block_match.group(1)}")
                
                if unique_blocks:
                    print(f"{Fore.CYAN}ğŸ“‹ ç¤ºä¾‹RRDBé”®:{Style.RESET_ALL}")
                    for block in sorted(list(unique_blocks))[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                        print(f"  - {block}")
            
            if num_blocks > 0 and num_features is not None:
                return {
                    'num_blocks': num_blocks,
                    'num_features': num_features
                }
            else:
                print(f"{Fore.YELLOW}âš ï¸  æ— æ³•å®Œå…¨æ£€æµ‹é…ç½®: blocks={num_blocks}, features={num_features}{Style.RESET_ALL}")
                return None
                
        except Exception as e:
            print(f"{Fore.RED}âŒ æ£€æµ‹æ£€æŸ¥ç‚¹é…ç½®å¤±è´¥: {str(e)}{Style.RESET_ALL}")
            import traceback
            traceback.print_exc()
            return None

    def _adjust_config_to_match_checkpoint(self, checkpoint_config):
        """è°ƒæ•´å½“å‰é…ç½®ä»¥åŒ¹é…æ£€æŸ¥ç‚¹"""
        # æ›´æ–°æ¨¡å‹é…ç½®
        self.config['model']['num_blocks'] = checkpoint_config['num_blocks']
        self.config['model']['num_features'] = checkpoint_config['num_features']
        
        # æ ¹æ®æ–°çš„æ¨¡å‹é…ç½®è°ƒæ•´è®­ç»ƒå‚æ•°
        gpu_memory = self.gpu_info.get("memory", 8.0)
        
        # æ ¹æ®å—æ•°å’Œæ˜¾å­˜è°ƒæ•´æ‰¹æ¬¡å¤§å°
        if checkpoint_config['num_blocks'] >= 8:
            # 8å—æ¨¡å‹éœ€è¦æ›´å¤šæ˜¾å­˜
            if gpu_memory >= 12:
                self.config['training']['batch_size'] = 4
            elif gpu_memory >= 8:
                self.config['training']['batch_size'] = 2
            else:
                self.config['training']['batch_size'] = 1
                if 'gradient_accumulation_steps' not in self.config['training']:
                    self.config['training']['gradient_accumulation_steps'] = 8
                else:
                    self.config['training']['gradient_accumulation_steps'] = 8
        elif checkpoint_config['num_blocks'] >= 6:
            # 6å—æ¨¡å‹
            if gpu_memory >= 8:
                self.config['training']['batch_size'] = 4
            elif gpu_memory >= 6:
                self.config['training']['batch_size'] = 2
            else:
                self.config['training']['batch_size'] = 1
                if 'gradient_accumulation_steps' not in self.config['training']:
                    self.config['training']['gradient_accumulation_steps'] = 4
                else:
                    self.config['training']['gradient_accumulation_steps'] = 4
        
        print(f"{Fore.CYAN}å·²è°ƒæ•´é…ç½®: {checkpoint_config['num_blocks']}å—, {checkpoint_config['num_features']}ç‰¹å¾{Style.RESET_ALL}")
        print(f"{Fore.CYAN}æ‰¹æ¬¡å¤§å°: {self.config['training']['batch_size']}{Style.RESET_ALL}")

    def _check_data_directories(self):
        """æ£€æŸ¥æ•°æ®ç›®å½•"""
        required_dirs = [
            self.config["data"]["train_lr_dir"],
            self.config["data"]["train_hr_dir"],
            self.config["data"]["val_lr_dir"],
            self.config["data"]["val_hr_dir"]
        ]
        
        missing_dirs = []
        for dir_path in required_dirs:
            if not os.path.exists(dir_path):
                missing_dirs.append(dir_path)
        
        if missing_dirs:
            print(f"{Fore.RED}âŒ ç¼ºå°‘ä»¥ä¸‹æ•°æ®ç›®å½•:{Style.RESET_ALL}")
            for dir_path in missing_dirs:
                print(f"  - {dir_path}")
            return False
        
        return True

    def gpu_optimization_menu(self):
        """GPUä¼˜åŒ–è®¾ç½®èœå•"""
        while True:
            self.clear_screen()
            self.print_header()
            print(f"\n{Fore.CYAN}ğŸš€ GPUä¼˜åŒ–è®¾ç½®{Style.RESET_ALL}")
            print(f"{Fore.CYAN}{'='*60}{Style.RESET_ALL}")
            
            # æ˜¾ç¤ºå½“å‰GPUä¿¡æ¯
            self.print_gpu_info()
            
            print(f"\n{Fore.CYAN}å¯ç”¨æ“ä½œ:{Style.RESET_ALL}")
            print(f"{Fore.WHITE}1.{Style.RESET_ALL} å¯ç”¨/ç¦ç”¨TF32åŠ é€Ÿ")
            print(f"{Fore.WHITE}2.{Style.RESET_ALL} å¯ç”¨/ç¦ç”¨æ¨¡å‹ç¼–è¯‘")
            print(f"{Fore.WHITE}3.{Style.RESET_ALL} è‡ªåŠ¨è°ƒæ•´æ‰¹æ¬¡å¤§å°")
            print(f"{Fore.WHITE}4.{Style.RESET_ALL} åŠ è½½RTX 4090é…ç½®")
            print(f"{Fore.WHITE}5.{Style.RESET_ALL} æ˜¾å­˜é…ç½®å»ºè®®")
            print(f"{Fore.WHITE}6.{Style.RESET_ALL} è¿”å›ä¸»èœå•")
            
            choice = input(f"\n{Fore.CYAN}è¯·é€‰æ‹©æ“ä½œ (1-6): {Style.RESET_ALL}").strip()
            
            if choice == '1':
                self._toggle_tf32()
            elif choice == '2':
                self._toggle_compile()
            elif choice == '3':
                self._auto_adjust_batch_size()
            elif choice == '4':
                self._load_rtx_4090_config()
            elif choice == '5':
                self._show_memory_recommendations()
            elif choice == '6':
                break
            else:
                print(f"{Fore.RED}âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡è¯•{Style.RESET_ALL}")
                time.sleep(1)

    def _toggle_tf32(self):
        """åˆ‡æ¢TF32è®¾ç½®"""
        if self.gpu_optimizer.tf32_enabled:
            self.gpu_optimizer.disable_tf32()
        else:
            self.gpu_optimizer.enable_tf32()
        input(f"\n{Fore.YELLOW}æŒ‰å›è½¦é”®ç»§ç»­...{Style.RESET_ALL}")

    def _toggle_compile(self):
        """åˆ‡æ¢æ¨¡å‹ç¼–è¯‘è®¾ç½®"""
        if self.gpu_optimizer.compile_enabled:
            self.gpu_optimizer.disable_compile()
        else:
            self.gpu_optimizer.enable_compile()
        input(f"\n{Fore.YELLOW}æŒ‰å›è½¦é”®ç»§ç»­...{Style.RESET_ALL}")

    def _auto_adjust_batch_size(self):
        """è‡ªåŠ¨è°ƒæ•´æ‰¹æ¬¡å¤§å°"""
        try:
            from src.models.esrgan import LiteRealESRGAN
            model = LiteRealESRGAN(
                num_blocks=self.config['model']['num_blocks'],
                num_features=self.config['model']['num_features']
            ).cuda()
            
            optimal_batch_size = self.gpu_optimizer.get_optimal_batch_size(
                model, (1, 3, 64, 64), self.gpu_info["memory"]
            )
            
            self.config['training']['batch_size'] = optimal_batch_size
            print(f"{Fore.GREEN}âœ… æ‰¹æ¬¡å¤§å°å·²è°ƒæ•´ä¸º: {optimal_batch_size}{Style.RESET_ALL}")
            
        except Exception as e:
            print(f"{Fore.RED}âŒ è‡ªåŠ¨è°ƒæ•´å¤±è´¥: {e}{Style.RESET_ALL}")
        
        input(f"\n{Fore.YELLOW}æŒ‰å›è½¦é”®ç»§ç»­...{Style.RESET_ALL}")

    def _load_rtx_4090_config(self):
        """åŠ è½½RTX 4090é…ç½®"""
        self.config = load_rtx_4090_config()
        print(f"{Fore.GREEN}âœ… å·²åŠ è½½RTX 4090ä¸“ç”¨é…ç½®{Style.RESET_ALL}")
        
        # è‡ªåŠ¨å¯ç”¨ä¼˜åŒ–
        if self.config.get("rtx_4090", {}).get("tf32_enabled", False):
            self.gpu_optimizer.enable_tf32()
        if self.config.get("rtx_4090", {}).get("compile_enabled", False):
            self.gpu_optimizer.enable_compile()
        
        input(f"\n{Fore.YELLOW}æŒ‰å›è½¦é”®ç»§ç»­...{Style.RESET_ALL}")

    def _show_memory_recommendations(self):
        """æ˜¾ç¤ºæ˜¾å­˜é…ç½®å»ºè®®"""
        gpu_memory = self.gpu_info["memory"]
        print(f"\n{Fore.CYAN}ğŸ’¡ æ˜¾å­˜é…ç½®å»ºè®® (å½“å‰: {gpu_memory:.1f}GB):{Style.RESET_ALL}")
        
        if gpu_memory < 4.5:
            print(f"{Fore.YELLOW}â€¢ å»ºè®®ä½¿ç”¨4GBé…ç½®{Style.RESET_ALL}")
            print(f"â€¢ æ‰¹æ¬¡å¤§å°: 1")
            print(f"â€¢ æ¨¡å‹å—æ•°: 3")
            print(f"â€¢ ç‰¹å¾æ•°: 24")
        elif gpu_memory < 6.5:
            print(f"{Fore.YELLOW}â€¢ å»ºè®®ä½¿ç”¨6GBé…ç½®{Style.RESET_ALL}")
            print(f"â€¢ æ‰¹æ¬¡å¤§å°: 2")
            print(f"â€¢ æ¨¡å‹å—æ•°: 4")
            print(f"â€¢ ç‰¹å¾æ•°: 32")
        elif gpu_memory < 8.5:
            print(f"{Fore.GREEN}â€¢ å»ºè®®ä½¿ç”¨8GBé…ç½®{Style.RESET_ALL}")
            print(f"â€¢ æ‰¹æ¬¡å¤§å°: 4")
            print(f"â€¢ æ¨¡å‹å—æ•°: 6")
            print(f"â€¢ ç‰¹å¾æ•°: 48")
        elif gpu_memory >= 20:
            print(f"{Fore.GREEN}â€¢ å»ºè®®ä½¿ç”¨RTX 4090é…ç½®{Style.RESET_ALL}")
            print(f"â€¢ æ‰¹æ¬¡å¤§å°: 12")
            print(f"â€¢ æ¨¡å‹å—æ•°: 8")
            print(f"â€¢ ç‰¹å¾æ•°: 64")
            print(f"â€¢ TF32åŠ é€Ÿ: å¯ç”¨")
            print(f"â€¢ æ¨¡å‹ç¼–è¯‘: å¯ç”¨")
        else:
            print(f"{Fore.GREEN}â€¢ å»ºè®®ä½¿ç”¨é«˜æ˜¾å­˜é…ç½®{Style.RESET_ALL}")
            print(f"â€¢ æ‰¹æ¬¡å¤§å°: 6-8")
            print(f"â€¢ æ¨¡å‹å—æ•°: 6")
            print(f"â€¢ ç‰¹å¾æ•°: 64")
        
        input(f"\n{Fore.YELLOW}æŒ‰å›è½¦é”®ç»§ç»­...{Style.RESET_ALL}")

    def run(self):
        """è¿è¡Œä¸»ç¨‹åº"""
        while True:
            self.clear_screen()
            self.print_header()
            self.print_gpu_info()
            self.print_main_menu()
            
            choice = input(f"\n{Fore.CYAN}è¯·é€‰æ‹©æ“ä½œ (1-8): {Style.RESET_ALL}").strip()
            
            if choice == '1':
                self.start_new_training()
            elif choice == '2':
                self.start_incremental_training()
            elif choice == '3':
                self.validate_model()
            elif choice == '4':
                self.config_management_menu()
            elif choice == '5':
                self.gpu_optimization_menu()
            elif choice == '6':
                self.checkpoint_management_menu()
            elif choice == '7':
                self.performance_monitoring_menu()
            elif choice == '8':
                print(f"{Fore.GREEN}ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ï¼{Style.RESET_ALL}")
                break
            else:
                print(f"{Fore.RED}âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡è¯•{Style.RESET_ALL}")
                time.sleep(1)

    def start_new_training(self):
        """å¼€å§‹æ–°è®­ç»ƒ"""
        try:
            print(f"{Fore.CYAN}ğŸš€ å¼€å§‹æ–°è®­ç»ƒ{Style.RESET_ALL}")
            print(f"{Fore.CYAN}{'='*60}{Style.RESET_ALL}")
            
            # æ£€æŸ¥æ•°æ®ç›®å½•
            if not self._check_data_directories():
                input(f"\n{Fore.YELLOW}æŒ‰å›è½¦é”®ç»§ç»­...{Style.RESET_ALL}")
                return
            
            # æ˜¾ç¤ºå½“å‰é…ç½®
            print(f"\n{Fore.CYAN}ğŸ“‹ å½“å‰è®­ç»ƒé…ç½®:{Style.RESET_ALL}")
            print(f"â€¢ æ¨¡å‹å—æ•°: {self.config['model']['num_blocks']}")
            print(f"â€¢ ç‰¹å¾æ•°: {self.config['model']['num_features']}")
            print(f"â€¢ æ‰¹æ¬¡å¤§å°: {self.config['training']['batch_size']}")
            print(f"â€¢ è®­ç»ƒè½®æ•°: {self.config['training']['num_epochs']}")
            print(f"â€¢ å­¦ä¹ ç‡: {self.config['training']['learning_rate']}")
            print(f"â€¢ ä¿å­˜é¢‘ç‡: {self.config['training']['save_frequency']} epochs")
            
            # ç¡®è®¤å¼€å§‹è®­ç»ƒ
            confirm = input(f"\n{Fore.CYAN}æ˜¯å¦ä½¿ç”¨å½“å‰é…ç½®å¼€å§‹æ–°è®­ç»ƒ? (y/n): {Style.RESET_ALL}").strip().lower()
            if confirm != 'y':
                print(f"{Fore.YELLOW}âŒ ç”¨æˆ·å–æ¶ˆè®­ç»ƒ{Style.RESET_ALL}")
                input(f"\n{Fore.YELLOW}æŒ‰å›è½¦é”®ç»§ç»­...{Style.RESET_ALL}")
                return
            
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ£€æŸ¥ç‚¹æ–‡ä»¶ï¼Œè¯¢é—®æ˜¯å¦æ¸…ç†
            checkpoint_files = [f for f in os.listdir('checkpoints') if f.endswith('.pth')]
            if checkpoint_files:
                print(f"\n{Fore.YELLOW}âš ï¸  æ£€æµ‹åˆ°ç°æœ‰æ£€æŸ¥ç‚¹æ–‡ä»¶:{Style.RESET_ALL}")
                for f in checkpoint_files[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                    print(f"  - {f}")
                if len(checkpoint_files) > 5:
                    print(f"  ... è¿˜æœ‰ {len(checkpoint_files) - 5} ä¸ªæ–‡ä»¶")
                
                clean_choice = input(f"\n{Fore.CYAN}æ˜¯å¦æ¸…ç†ç°æœ‰æ£€æŸ¥ç‚¹? (y/n): {Style.RESET_ALL}").strip().lower()
                if clean_choice == 'y':
                    try:
                        for f in checkpoint_files:
                            os.remove(os.path.join('checkpoints', f))
                        print(f"{Fore.GREEN}âœ… å·²æ¸…ç† {len(checkpoint_files)} ä¸ªæ£€æŸ¥ç‚¹æ–‡ä»¶{Style.RESET_ALL}")
                    except Exception as e:
                        print(f"{Fore.RED}âŒ æ¸…ç†æ£€æŸ¥ç‚¹å¤±è´¥: {e}{Style.RESET_ALL}")
                        input(f"\n{Fore.YELLOW}æŒ‰å›è½¦é”®ç»§ç»­...{Style.RESET_ALL}")
                        return
            
            # å¯åŠ¨æ–°è®­ç»ƒ
            print(f"\n{Fore.GREEN}ğŸš€ å¯åŠ¨æ–°è®­ç»ƒ...{Style.RESET_ALL}")
            
            def training_worker():
                try:
                    from src.training.train_manager import MemoryOptimizedTrainingManager
                    trainer = MemoryOptimizedTrainingManager(self.config)
                    
                    # å¼€å§‹æ–°è®­ç»ƒï¼ˆä¸ä¼ é€’æ£€æŸ¥ç‚¹è·¯å¾„ï¼‰
                    trainer.start_training()
                    
                except Exception as e:
                    print(f"{Fore.RED}âŒ è®­ç»ƒè¿‡ç¨‹å‡ºé”™: {e}{Style.RESET_ALL}")
                    import traceback
                    traceback.print_exc()
            
            # åœ¨æ–°çº¿ç¨‹ä¸­å¯åŠ¨è®­ç»ƒ
            import threading
            training_thread = threading.Thread(target=training_worker)
            training_thread.daemon = True
            training_thread.start()
            
            print(f"{Fore.GREEN}âœ… æ–°è®­ç»ƒå·²åœ¨åå°å¯åŠ¨{Style.RESET_ALL}")
            print(f"{Fore.YELLOW}ğŸ’¡ æ‚¨å¯ä»¥ç»§ç»­ä½¿ç”¨å…¶ä»–åŠŸèƒ½ï¼Œè®­ç»ƒå°†åœ¨åå°è¿›è¡Œ{Style.RESET_ALL}")
            print(f"{Fore.CYAN}ğŸ“Š è®­ç»ƒè¿›åº¦å°†åœ¨ç»ˆç«¯ä¸­æ˜¾ç¤º{Style.RESET_ALL}")
            
            input(f"\n{Fore.YELLOW}æŒ‰å›è½¦é”®ç»§ç»­...{Style.RESET_ALL}")
            
        except Exception as e:
            print(f"{Fore.RED}âŒ æ–°è®­ç»ƒå¯åŠ¨å¤±è´¥: {e}{Style.RESET_ALL}")
            import traceback
            traceback.print_exc()
            input(f"\n{Fore.YELLOW}æŒ‰å›è½¦é”®ç»§ç»­...{Style.RESET_ALL}")

    def validate_model(self):
        """éªŒè¯æ¨¡å‹"""
        try:
            print(f"{Fore.CYAN}ğŸ” æ¨¡å‹éªŒè¯{Style.RESET_ALL}")
            print(f"{Fore.CYAN}{'='*60}{Style.RESET_ALL}")
            
            # é€‰æ‹©æ£€æŸ¥ç‚¹æ–‡ä»¶
            checkpoint_files = [f for f in os.listdir('checkpoints') if f.endswith('.pth')]
            if not checkpoint_files:
                print(f"{Fore.RED}âŒ æ²¡æœ‰æ‰¾åˆ°æ£€æŸ¥ç‚¹æ–‡ä»¶{Style.RESET_ALL}")
                input(f"\n{Fore.YELLOW}æŒ‰å›è½¦é”®ç»§ç»­...{Style.RESET_ALL}")
                return
            
            print(f"\n{Fore.CYAN}ğŸ“ å¯ç”¨çš„æ£€æŸ¥ç‚¹æ–‡ä»¶:{Style.RESET_ALL}")
            for i, file in enumerate(checkpoint_files, 1):
                print(f"{Fore.WHITE}{i}.{Style.RESET_ALL} {file}")
            
            try:
                choice = int(input(f"\n{Fore.CYAN}è¯·é€‰æ‹©æ£€æŸ¥ç‚¹æ–‡ä»¶ (1-{len(checkpoint_files)}): {Style.RESET_ALL}"))
                if 1 <= choice <= len(checkpoint_files):
                    checkpoint_path = os.path.join('checkpoints', checkpoint_files[choice-1])
                    
                    print(f"\n{Fore.GREEN}ğŸš€ å¯åŠ¨æ¨¡å‹éªŒè¯...{Style.RESET_ALL}")
                    
                    # å¯åŠ¨éªŒè¯å™¨
                    import subprocess
                    import sys
                    
                    # ä½¿ç”¨éªŒè¯å™¨.pyè¿›è¡ŒéªŒè¯
                    validator_path = os.path.join(os.path.dirname(__file__), "éªŒè¯å™¨.py")
                    if os.path.exists(validator_path):
                        print(f"{Fore.CYAN}ğŸ“Š å¯åŠ¨éªŒè¯å™¨ç•Œé¢...{Style.RESET_ALL}")
                        subprocess.Popen([sys.executable, validator_path])
                        print(f"{Fore.GREEN}âœ… éªŒè¯å™¨å·²å¯åŠ¨{Style.RESET_ALL}")
                    else:
                        print(f"{Fore.RED}âŒ éªŒè¯å™¨æ–‡ä»¶ä¸å­˜åœ¨: {validator_path}{Style.RESET_ALL}")
                else:
                    print(f"{Fore.RED}âŒ æ— æ•ˆé€‰æ‹©{Style.RESET_ALL}")
                    
            except ValueError:
                print(f"{Fore.RED}âŒ è¯·è¾“å…¥æœ‰æ•ˆæ•°å­—{Style.RESET_ALL}")
                
        except Exception as e:
            print(f"{Fore.RED}âŒ éªŒè¯å¯åŠ¨å¤±è´¥: {e}{Style.RESET_ALL}")
            import traceback
            traceback.print_exc()
        
        input(f"\n{Fore.YELLOW}æŒ‰å›è½¦é”®ç»§ç»­...{Style.RESET_ALL}")

    def config_management_menu(self):
        """é…ç½®ç®¡ç†èœå•"""
        while True:
            self.clear_screen()
            self.print_header()
            print(f"\n{Fore.CYAN}âš™ï¸  é…ç½®ç®¡ç†{Style.RESET_ALL}")
            print(f"{Fore.CYAN}{'='*60}{Style.RESET_ALL}")
            
            print(f"\n{Fore.CYAN}å¯ç”¨æ“ä½œ:{Style.RESET_ALL}")
            print(f"{Fore.WHITE}1.{Style.RESET_ALL} æŸ¥çœ‹å½“å‰é…ç½®")
            print(f"{Fore.WHITE}2.{Style.RESET_ALL} ç¼–è¾‘é…ç½®å‚æ•°")
            print(f"{Fore.WHITE}3.{Style.RESET_ALL} åŠ è½½é»˜è®¤é…ç½®")
            print(f"{Fore.WHITE}4.{Style.RESET_ALL} åŠ è½½ä½æ˜¾å­˜é…ç½®")
            print(f"{Fore.WHITE}5.{Style.RESET_ALL} åŠ è½½é«˜æ˜¾å­˜é…ç½®")
            print(f"{Fore.WHITE}6.{Style.RESET_ALL} åŠ è½½RTX 4090é…ç½®")
            print(f"{Fore.WHITE}7.{Style.RESET_ALL} ä¿å­˜å½“å‰é…ç½®")
            print(f"{Fore.WHITE}8.{Style.RESET_ALL} è¿”å›ä¸»èœå•")
            
            choice = input(f"\n{Fore.CYAN}è¯·é€‰æ‹©æ“ä½œ (1-8): {Style.RESET_ALL}").strip()
            
            if choice == '1':
                self._show_current_config()
            elif choice == '2':
                self._edit_config()
            elif choice == '3':
                self.config = get_default_config()
                print(f"{Fore.GREEN}âœ… å·²åŠ è½½é»˜è®¤é…ç½®{Style.RESET_ALL}")
                input(f"\n{Fore.YELLOW}æŒ‰å›è½¦é”®ç»§ç»­...{Style.RESET_ALL}")
            elif choice == '4':
                self.config = load_low_memory_config()
                print(f"{Fore.GREEN}âœ… å·²åŠ è½½ä½æ˜¾å­˜é…ç½®{Style.RESET_ALL}")
                input(f"\n{Fore.YELLOW}æŒ‰å›è½¦é”®ç»§ç»­...{Style.RESET_ALL}")
            elif choice == '5':
                self.config = load_high_memory_config()
                print(f"{Fore.GREEN}âœ… å·²åŠ è½½é«˜æ˜¾å­˜é…ç½®{Style.RESET_ALL}")
                input(f"\n{Fore.YELLOW}æŒ‰å›è½¦é”®ç»§ç»­...{Style.RESET_ALL}")
            elif choice == '6':
                self.config = load_rtx_4090_config()
                print(f"{Fore.GREEN}âœ… å·²åŠ è½½RTX 4090é…ç½®{Style.RESET_ALL}")
                input(f"\n{Fore.YELLOW}æŒ‰å›è½¦é”®ç»§ç»­...{Style.RESET_ALL}")
            elif choice == '7':
                try:
                    save_config(self.config)
                    print(f"{Fore.GREEN}âœ… é…ç½®å·²ä¿å­˜{Style.RESET_ALL}")
                except Exception as e:
                    print(f"{Fore.RED}âŒ ä¿å­˜å¤±è´¥: {e}{Style.RESET_ALL}")
                input(f"\n{Fore.YELLOW}æŒ‰å›è½¦é”®ç»§ç»­...{Style.RESET_ALL}")
            elif choice == '8':
                break
            else:
                print(f"{Fore.RED}âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡è¯•{Style.RESET_ALL}")
                time.sleep(1)

    def _edit_config(self):
        """ç¼–è¾‘é…ç½®å‚æ•°"""
        while True:
            self.clear_screen()
            self.print_header()
            print(f"\n{Fore.CYAN}âœï¸  ç¼–è¾‘é…ç½®å‚æ•°{Style.RESET_ALL}")
            print(f"{Fore.CYAN}{'='*60}{Style.RESET_ALL}")
            
            print(f"\n{Fore.CYAN}å¯ç¼–è¾‘çš„é…ç½®ç±»åˆ«:{Style.RESET_ALL}")
            print(f"{Fore.WHITE}1.{Style.RESET_ALL} æ¨¡å‹é…ç½® (å—æ•°ã€ç‰¹å¾æ•°)")
            print(f"{Fore.WHITE}2.{Style.RESET_ALL} è®­ç»ƒé…ç½® (æ‰¹æ¬¡å¤§å°ã€è½®æ•°ã€å­¦ä¹ ç‡ç­‰)")
            print(f"{Fore.WHITE}3.{Style.RESET_ALL} æ•°æ®è·¯å¾„é…ç½®")
            print(f"{Fore.WHITE}4.{Style.RESET_ALL} è¾“å‡ºè·¯å¾„é…ç½®")
            print(f"{Fore.WHITE}5.{Style.RESET_ALL} è¿”å›é…ç½®ç®¡ç†")
            
            choice = input(f"\n{Fore.CYAN}è¯·é€‰æ‹©è¦ç¼–è¾‘çš„ç±»åˆ« (1-5): {Style.RESET_ALL}").strip()
            
            if choice == '1':
                self._edit_model_config()
            elif choice == '2':
                self._edit_training_config()
            elif choice == '3':
                self._edit_data_paths()
            elif choice == '4':
                self._edit_output_paths()
            elif choice == '5':
                break
            else:
                print(f"{Fore.RED}âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡è¯•{Style.RESET_ALL}")
                time.sleep(1)

    def _edit_model_config(self):
        """ç¼–è¾‘æ¨¡å‹é…ç½®"""
        print(f"\n{Fore.CYAN}ğŸ—ï¸  ç¼–è¾‘æ¨¡å‹é…ç½®{Style.RESET_ALL}")
        print(f"{Fore.CYAN}{'='*40}{Style.RESET_ALL}")
        
        # æ˜¾ç¤ºå½“å‰å€¼
        print(f"\n{Fore.YELLOW}å½“å‰æ¨¡å‹é…ç½®:{Style.RESET_ALL}")
        print(f"  å—æ•°: {self.config['model']['num_blocks']}")
        print(f"  ç‰¹å¾æ•°: {self.config['model']['num_features']}")
        
        try:
            # ç¼–è¾‘å—æ•°
            new_blocks = input(f"\n{Fore.CYAN}æ–°çš„å—æ•° (å½“å‰: {self.config['model']['num_blocks']}, å›è½¦ä¿æŒä¸å˜): {Style.RESET_ALL}").strip()
            if new_blocks:
                blocks = int(new_blocks)
                if 1 <= blocks <= 20:
                    self.config['model']['num_blocks'] = blocks
                    print(f"{Fore.GREEN}âœ… å—æ•°å·²æ›´æ–°ä¸º: {blocks}{Style.RESET_ALL}")
                else:
                    print(f"{Fore.RED}âŒ å—æ•°åº”åœ¨1-20ä¹‹é—´{Style.RESET_ALL}")
            
            # ç¼–è¾‘ç‰¹å¾æ•°
            new_features = input(f"\n{Fore.CYAN}æ–°çš„ç‰¹å¾æ•° (å½“å‰: {self.config['model']['num_features']}, å›è½¦ä¿æŒä¸å˜): {Style.RESET_ALL}").strip()
            if new_features:
                features = int(new_features)
                if 16 <= features <= 128:
                    self.config['model']['num_features'] = features
                    print(f"{Fore.GREEN}âœ… ç‰¹å¾æ•°å·²æ›´æ–°ä¸º: {features}{Style.RESET_ALL}")
                else:
                    print(f"{Fore.RED}âŒ ç‰¹å¾æ•°åº”åœ¨16-128ä¹‹é—´{Style.RESET_ALL}")
                    
        except ValueError:
            print(f"{Fore.RED}âŒ è¯·è¾“å…¥æœ‰æ•ˆæ•°å­—{Style.RESET_ALL}")
        
        input(f"\n{Fore.YELLOW}æŒ‰å›è½¦é”®ç»§ç»­...{Style.RESET_ALL}")

    def _edit_training_config(self):
        """ç¼–è¾‘è®­ç»ƒé…ç½®"""
        print(f"\n{Fore.CYAN}ğŸ¯ ç¼–è¾‘è®­ç»ƒé…ç½®{Style.RESET_ALL}")
        print(f"{Fore.CYAN}{'='*40}{Style.RESET_ALL}")
        
        # æ˜¾ç¤ºå½“å‰å€¼
        print(f"\n{Fore.YELLOW}å½“å‰è®­ç»ƒé…ç½®:{Style.RESET_ALL}")
        print(f"  æ‰¹æ¬¡å¤§å°: {self.config['training']['batch_size']}")
        print(f"  è®­ç»ƒè½®æ•°: {self.config['training']['num_epochs']}")
        print(f"  å­¦ä¹ ç‡: {self.config['training']['learning_rate']}")
        print(f"  ä¿å­˜é¢‘ç‡: {self.config['training']['save_frequency']} epochs")
        
        try:
            # ç¼–è¾‘æ‰¹æ¬¡å¤§å°
            new_batch = input(f"\n{Fore.CYAN}æ–°çš„æ‰¹æ¬¡å¤§å° (å½“å‰: {self.config['training']['batch_size']}, å›è½¦ä¿æŒä¸å˜): {Style.RESET_ALL}").strip()
            if new_batch:
                batch_size = int(new_batch)
                if 1 <= batch_size <= 32:
                    self.config['training']['batch_size'] = batch_size
                    print(f"{Fore.GREEN}âœ… æ‰¹æ¬¡å¤§å°å·²æ›´æ–°ä¸º: {batch_size}{Style.RESET_ALL}")
                else:
                    print(f"{Fore.RED}âŒ æ‰¹æ¬¡å¤§å°åº”åœ¨1-32ä¹‹é—´{Style.RESET_ALL}")
            
            # ç¼–è¾‘è®­ç»ƒè½®æ•°
            new_epochs = input(f"\n{Fore.CYAN}æ–°çš„è®­ç»ƒè½®æ•° (å½“å‰: {self.config['training']['num_epochs']}, å›è½¦ä¿æŒä¸å˜): {Style.RESET_ALL}").strip()
            if new_epochs:
                epochs = int(new_epochs)
                if 1 <= epochs <= 1000:
                    self.config['training']['num_epochs'] = epochs
                    print(f"{Fore.GREEN}âœ… è®­ç»ƒè½®æ•°å·²æ›´æ–°ä¸º: {epochs}{Style.RESET_ALL}")
                else:
                    print(f"{Fore.RED}âŒ è®­ç»ƒè½®æ•°åº”åœ¨1-1000ä¹‹é—´{Style.RESET_ALL}")
            
            # ç¼–è¾‘å­¦ä¹ ç‡
            new_lr = input(f"\n{Fore.CYAN}æ–°çš„å­¦ä¹ ç‡ (å½“å‰: {self.config['training']['learning_rate']}, å›è½¦ä¿æŒä¸å˜): {Style.RESET_ALL}").strip()
            if new_lr:
                learning_rate = float(new_lr)
                if 1e-6 <= learning_rate <= 1e-1:
                    self.config['training']['learning_rate'] = learning_rate
                    print(f"{Fore.GREEN}âœ… å­¦ä¹ ç‡å·²æ›´æ–°ä¸º: {learning_rate}{Style.RESET_ALL}")
                else:
                    print(f"{Fore.RED}âŒ å­¦ä¹ ç‡åº”åœ¨1e-6åˆ°1e-1ä¹‹é—´{Style.RESET_ALL}")
            
            # ç¼–è¾‘ä¿å­˜é¢‘ç‡
            new_save_freq = input(f"\n{Fore.CYAN}æ–°çš„ä¿å­˜é¢‘ç‡ (å½“å‰: {self.config['training']['save_frequency']} epochs, å›è½¦ä¿æŒä¸å˜): {Style.RESET_ALL}").strip()
            if new_save_freq:
                save_freq = int(new_save_freq)
                if 1 <= save_freq <= 50:
                    self.config['training']['save_frequency'] = save_freq
                    print(f"{Fore.GREEN}âœ… ä¿å­˜é¢‘ç‡å·²æ›´æ–°ä¸º: {save_freq} epochs{Style.RESET_ALL}")
                else:
                    print(f"{Fore.RED}âŒ ä¿å­˜é¢‘ç‡åº”åœ¨1-50ä¹‹é—´{Style.RESET_ALL}")
                    
        except ValueError:
            print(f"{Fore.RED}âŒ è¯·è¾“å…¥æœ‰æ•ˆæ•°å­—{Style.RESET_ALL}")
        
        input(f"\n{Fore.YELLOW}æŒ‰å›è½¦é”®ç»§ç»­...{Style.RESET_ALL}")

    def _edit_data_paths(self):
        """ç¼–è¾‘æ•°æ®è·¯å¾„é…ç½®"""
        print(f"\n{Fore.CYAN}ğŸ“ ç¼–è¾‘æ•°æ®è·¯å¾„é…ç½®{Style.RESET_ALL}")
        print(f"{Fore.CYAN}{'='*40}{Style.RESET_ALL}")
        
        # æ˜¾ç¤ºå½“å‰å€¼
        print(f"\n{Fore.YELLOW}å½“å‰æ•°æ®è·¯å¾„:{Style.RESET_ALL}")
        print(f"  è®­ç»ƒLR: {self.config['data']['train_lr_dir']}")
        print(f"  è®­ç»ƒHR: {self.config['data']['train_hr_dir']}")
        print(f"  éªŒè¯LR: {self.config['data']['val_lr_dir']}")
        print(f"  éªŒè¯HR: {self.config['data']['val_hr_dir']}")
        
        # ç¼–è¾‘å„ä¸ªè·¯å¾„
        paths = [
            ('train_lr_dir', 'è®­ç»ƒLRç›®å½•'),
            ('train_hr_dir', 'è®­ç»ƒHRç›®å½•'),
            ('val_lr_dir', 'éªŒè¯LRç›®å½•'),
            ('val_hr_dir', 'éªŒè¯HRç›®å½•')
        ]
        
        for key, name in paths:
            new_path = input(f"\n{Fore.CYAN}æ–°çš„{name} (å½“å‰: {self.config['data'][key]}, å›è½¦ä¿æŒä¸å˜): {Style.RESET_ALL}").strip()
            if new_path:
                if os.path.exists(new_path):
                    self.config['data'][key] = new_path
                    print(f"{Fore.GREEN}âœ… {name}å·²æ›´æ–°ä¸º: {new_path}{Style.RESET_ALL}")
                else:
                    print(f"{Fore.RED}âŒ è·¯å¾„ä¸å­˜åœ¨: {new_path}{Style.RESET_ALL}")
        
        input(f"\n{Fore.YELLOW}æŒ‰å›è½¦é”®ç»§ç»­...{Style.RESET_ALL}")

    def _edit_output_paths(self):
        """ç¼–è¾‘è¾“å‡ºè·¯å¾„é…ç½®"""
        print(f"\n{Fore.CYAN}ğŸ’¾ ç¼–è¾‘è¾“å‡ºè·¯å¾„é…ç½®{Style.RESET_ALL}")
        print(f"{Fore.CYAN}{'='*40}{Style.RESET_ALL}")
        
        # æ˜¾ç¤ºå½“å‰å€¼
        print(f"\n{Fore.YELLOW}å½“å‰è¾“å‡ºè·¯å¾„:{Style.RESET_ALL}")
        print(f"  æ£€æŸ¥ç‚¹ç›®å½•: {self.config['paths']['checkpoint_dir']}")
        print(f"  æ—¥å¿—ç›®å½•: {self.config['paths']['log_dir']}")
        print(f"  è¾“å‡ºç›®å½•: {self.config['paths']['output_dir']}")
        print(f"  ä¿å­˜ç›®å½•: {self.config['paths']['save_dir']}")
        
        # ç¼–è¾‘å„ä¸ªè·¯å¾„
        paths = [
            ('checkpoint_dir', 'æ£€æŸ¥ç‚¹ç›®å½•'),
            ('log_dir', 'æ—¥å¿—ç›®å½•'),
            ('output_dir', 'è¾“å‡ºç›®å½•'),
            ('save_dir', 'ä¿å­˜ç›®å½•')
        ]
        
        for key, name in paths:
            new_path = input(f"\n{Fore.CYAN}æ–°çš„{name} (å½“å‰: {self.config['paths'][key]}, å›è½¦ä¿æŒä¸å˜): {Style.RESET_ALL}").strip()
            if new_path:
                # åˆ›å»ºç›®å½•å¦‚æœä¸å­˜åœ¨
                try:
                    os.makedirs(new_path, exist_ok=True)
                    self.config['paths'][key] = new_path
                    print(f"{Fore.GREEN}âœ… {name}å·²æ›´æ–°ä¸º: {new_path}{Style.RESET_ALL}")
                except Exception as e:
                    print(f"{Fore.RED}âŒ æ— æ³•åˆ›å»ºç›®å½•: {e}{Style.RESET_ALL}")
        
        input(f"\n{Fore.YELLOW}æŒ‰å›è½¦é”®ç»§ç»­...{Style.RESET_ALL}")

    def _show_current_config(self):
        """æ˜¾ç¤ºå½“å‰é…ç½®"""
        print(f"\n{Fore.CYAN}ğŸ“‹ å½“å‰é…ç½®è¯¦æƒ…:{Style.RESET_ALL}")
        
        # æ¨¡å‹é…ç½®
        print(f"\n{Fore.YELLOW}ğŸ—ï¸  æ¨¡å‹é…ç½®:{Style.RESET_ALL}")
        print(f"  å—æ•°: {self.config['model']['num_blocks']}")
        print(f"  ç‰¹å¾æ•°: {self.config['model']['num_features']}")
        
        # è®­ç»ƒé…ç½®
        print(f"\n{Fore.YELLOW}ğŸ¯ è®­ç»ƒé…ç½®:{Style.RESET_ALL}")
        print(f"  æ‰¹æ¬¡å¤§å°: {self.config['training']['batch_size']}")
        print(f"  è®­ç»ƒè½®æ•°: {self.config['training']['num_epochs']}")
        print(f"  å­¦ä¹ ç‡: {self.config['training']['learning_rate']}")
        print(f"  ä¿å­˜é¢‘ç‡: {self.config['training']['save_frequency']} epochs")
        
        # æ•°æ®é…ç½®
        print(f"\n{Fore.YELLOW}ğŸ“ æ•°æ®è·¯å¾„:{Style.RESET_ALL}")
        print(f"  è®­ç»ƒLR: {self.config['data']['train_lr_dir']}")
        print(f"  è®­ç»ƒHR: {self.config['data']['train_hr_dir']}")
        print(f"  éªŒè¯LR: {self.config['data']['val_lr_dir']}")
        print(f"  éªŒè¯HR: {self.config['data']['val_hr_dir']}")
        
        # è·¯å¾„é…ç½®
        print(f"\n{Fore.YELLOW}ğŸ’¾ è¾“å‡ºè·¯å¾„:{Style.RESET_ALL}")
        print(f"  æ£€æŸ¥ç‚¹: {self.config['paths']['checkpoint_dir']}")
        print(f"  æ—¥å¿—: {self.config['paths']['log_dir']}")
        print(f"  è¾“å‡º: {self.config['paths']['output_dir']}")
        
        input(f"\n{Fore.YELLOW}æŒ‰å›è½¦é”®ç»§ç»­...{Style.RESET_ALL}")

    def checkpoint_management_menu(self):
        """æ£€æŸ¥ç‚¹ç®¡ç†èœå•"""
        while True:
            self.clear_screen()
            self.print_header()
            print(f"\n{Fore.CYAN}ğŸ’¾ æ£€æŸ¥ç‚¹ç®¡ç†{Style.RESET_ALL}")
            print(f"{Fore.CYAN}{'='*60}{Style.RESET_ALL}")
            
            # æ˜¾ç¤ºæ£€æŸ¥ç‚¹æ–‡ä»¶
            checkpoint_files = [f for f in os.listdir('checkpoints') if f.endswith('.pth')]
            if checkpoint_files:
                print(f"\n{Fore.CYAN}ğŸ“ ç°æœ‰æ£€æŸ¥ç‚¹æ–‡ä»¶ ({len(checkpoint_files)} ä¸ª):{Style.RESET_ALL}")
                for i, file in enumerate(checkpoint_files[:10], 1):  # åªæ˜¾ç¤ºå‰10ä¸ª
                    file_path = os.path.join('checkpoints', file)
                    file_size = os.path.getsize(file_path) / (1024*1024)  # MB
                    print(f"  {i:2d}. {file} ({file_size:.1f}MB)")
                if len(checkpoint_files) > 10:
                    print(f"      ... è¿˜æœ‰ {len(checkpoint_files) - 10} ä¸ªæ–‡ä»¶")
            else:
                print(f"\n{Fore.YELLOW}ğŸ“ æ²¡æœ‰æ‰¾åˆ°æ£€æŸ¥ç‚¹æ–‡ä»¶{Style.RESET_ALL}")
            
            print(f"\n{Fore.CYAN}å¯ç”¨æ“ä½œ:{Style.RESET_ALL}")
            print(f"{Fore.WHITE}1.{Style.RESET_ALL} æ£€æŸ¥æ£€æŸ¥ç‚¹è¯¦æƒ…")
            print(f"{Fore.WHITE}2.{Style.RESET_ALL} åˆ é™¤æ£€æŸ¥ç‚¹æ–‡ä»¶")
            print(f"{Fore.WHITE}3.{Style.RESET_ALL} æ¸…ç†æ‰€æœ‰æ£€æŸ¥ç‚¹")
            print(f"{Fore.WHITE}4.{Style.RESET_ALL} å¤‡ä»½æ£€æŸ¥ç‚¹")
            print(f"{Fore.WHITE}5.{Style.RESET_ALL} è¿”å›ä¸»èœå•")
            
            choice = input(f"\n{Fore.CYAN}è¯·é€‰æ‹©æ“ä½œ (1-5): {Style.RESET_ALL}").strip()
            
            if choice == '1':
                self._check_checkpoint_details()
            elif choice == '2':
                self._delete_checkpoint()
            elif choice == '3':
                self._clean_all_checkpoints()
            elif choice == '4':
                self._backup_checkpoint()
            elif choice == '5':
                break
            else:
                print(f"{Fore.RED}âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡è¯•{Style.RESET_ALL}")
                time.sleep(1)

    def _check_checkpoint_details(self):
        """æ£€æŸ¥æ£€æŸ¥ç‚¹è¯¦æƒ…"""
        checkpoint_files = [f for f in os.listdir('checkpoints') if f.endswith('.pth')]
        if not checkpoint_files:
            print(f"{Fore.RED}âŒ æ²¡æœ‰æ‰¾åˆ°æ£€æŸ¥ç‚¹æ–‡ä»¶{Style.RESET_ALL}")
            input(f"\n{Fore.YELLOW}æŒ‰å›è½¦é”®ç»§ç»­...{Style.RESET_ALL}")
            return
        
        print(f"\n{Fore.CYAN}é€‰æ‹©è¦æ£€æŸ¥çš„æ–‡ä»¶:{Style.RESET_ALL}")
        for i, file in enumerate(checkpoint_files, 1):
            print(f"{Fore.WHITE}{i}.{Style.RESET_ALL} {file}")
        
        try:
            choice = int(input(f"\n{Fore.CYAN}è¯·é€‰æ‹©æ–‡ä»¶ (1-{len(checkpoint_files)}): {Style.RESET_ALL}"))
            if 1 <= choice <= len(checkpoint_files):
                file_path = os.path.join('checkpoints', checkpoint_files[choice-1])
                
                # å¯åŠ¨æ£€æŸ¥ç‚¹æ£€æŸ¥å™¨
                import subprocess
                import sys
                checker_path = os.path.join(os.path.dirname(__file__), "æ£€æŸ¥æ¨¡å‹æ£€æŸ¥ç‚¹.py")
                if os.path.exists(checker_path):
                    print(f"{Fore.GREEN}ğŸš€ å¯åŠ¨æ£€æŸ¥ç‚¹æ£€æŸ¥å™¨...{Style.RESET_ALL}")
                    subprocess.Popen([sys.executable, checker_path])
                else:
                    print(f"{Fore.RED}âŒ æ£€æŸ¥å™¨æ–‡ä»¶ä¸å­˜åœ¨{Style.RESET_ALL}")
            else:
                print(f"{Fore.RED}âŒ æ— æ•ˆé€‰æ‹©{Style.RESET_ALL}")
        except ValueError:
            print(f"{Fore.RED}âŒ è¯·è¾“å…¥æœ‰æ•ˆæ•°å­—{Style.RESET_ALL}")
        
        input(f"\n{Fore.YELLOW}æŒ‰å›è½¦é”®ç»§ç»­...{Style.RESET_ALL}")

    def _delete_checkpoint(self):
        """åˆ é™¤æ£€æŸ¥ç‚¹æ–‡ä»¶"""
        checkpoint_files = [f for f in os.listdir('checkpoints') if f.endswith('.pth')]
        if not checkpoint_files:
            print(f"{Fore.RED}âŒ æ²¡æœ‰æ‰¾åˆ°æ£€æŸ¥ç‚¹æ–‡ä»¶{Style.RESET_ALL}")
            input(f"\n{Fore.YELLOW}æŒ‰å›è½¦é”®ç»§ç»­...{Style.RESET_ALL}")
            return
        
        print(f"\n{Fore.CYAN}é€‰æ‹©è¦åˆ é™¤çš„æ–‡ä»¶:{Style.RESET_ALL}")
        for i, file in enumerate(checkpoint_files, 1):
            print(f"{Fore.WHITE}{i}.{Style.RESET_ALL} {file}")
        
        try:
            choice = int(input(f"\n{Fore.CYAN}è¯·é€‰æ‹©æ–‡ä»¶ (1-{len(checkpoint_files)}): {Style.RESET_ALL}"))
            if 1 <= choice <= len(checkpoint_files):
                file_to_delete = checkpoint_files[choice-1]
                confirm = input(f"\n{Fore.RED}ç¡®è®¤åˆ é™¤ '{file_to_delete}'? (y/n): {Style.RESET_ALL}").strip().lower()
                if confirm == 'y':
                    os.remove(os.path.join('checkpoints', file_to_delete))
                    print(f"{Fore.GREEN}âœ… å·²åˆ é™¤: {file_to_delete}{Style.RESET_ALL}")
                else:
                    print(f"{Fore.YELLOW}âŒ å–æ¶ˆåˆ é™¤{Style.RESET_ALL}")
            else:
                print(f"{Fore.RED}âŒ æ— æ•ˆé€‰æ‹©{Style.RESET_ALL}")
        except ValueError:
            print(f"{Fore.RED}âŒ è¯·è¾“å…¥æœ‰æ•ˆæ•°å­—{Style.RESET_ALL}")
        except Exception as e:
            print(f"{Fore.RED}âŒ åˆ é™¤å¤±è´¥: {e}{Style.RESET_ALL}")
        
        input(f"\n{Fore.YELLOW}æŒ‰å›è½¦é”®ç»§ç»­...{Style.RESET_ALL}")

    def _clean_all_checkpoints(self):
        """æ¸…ç†æ‰€æœ‰æ£€æŸ¥ç‚¹"""
        checkpoint_files = [f for f in os.listdir('checkpoints') if f.endswith('.pth')]
        if not checkpoint_files:
            print(f"{Fore.YELLOW}ğŸ“ æ²¡æœ‰æ£€æŸ¥ç‚¹æ–‡ä»¶éœ€è¦æ¸…ç†{Style.RESET_ALL}")
            input(f"\n{Fore.YELLOW}æŒ‰å›è½¦é”®ç»§ç»­...{Style.RESET_ALL}")
            return
        
        print(f"\n{Fore.RED}âš ï¸  è­¦å‘Š: å°†åˆ é™¤æ‰€æœ‰ {len(checkpoint_files)} ä¸ªæ£€æŸ¥ç‚¹æ–‡ä»¶{Style.RESET_ALL}")
        confirm = input(f"{Fore.RED}ç¡®è®¤æ¸…ç†æ‰€æœ‰æ£€æŸ¥ç‚¹? (è¾“å…¥ 'DELETE' ç¡®è®¤): {Style.RESET_ALL}").strip()
        
        if confirm == 'DELETE':
            try:
                deleted_count = 0
                for file in checkpoint_files:
                    os.remove(os.path.join('checkpoints', file))
                    deleted_count += 1
                print(f"{Fore.GREEN}âœ… å·²æ¸…ç† {deleted_count} ä¸ªæ£€æŸ¥ç‚¹æ–‡ä»¶{Style.RESET_ALL}")
            except Exception as e:
                print(f"{Fore.RED}âŒ æ¸…ç†å¤±è´¥: {e}{Style.RESET_ALL}")
        else:
            print(f"{Fore.YELLOW}âŒ å–æ¶ˆæ¸…ç†{Style.RESET_ALL}")
        
        input(f"\n{Fore.YELLOW}æŒ‰å›è½¦é”®ç»§ç»­...{Style.RESET_ALL}")

    def _backup_checkpoint(self):
        """å¤‡ä»½æ£€æŸ¥ç‚¹"""
        checkpoint_files = [f for f in os.listdir('checkpoints') if f.endswith('.pth')]
        if not checkpoint_files:
            print(f"{Fore.RED}âŒ æ²¡æœ‰æ‰¾åˆ°æ£€æŸ¥ç‚¹æ–‡ä»¶{Style.RESET_ALL}")
            input(f"\n{Fore.YELLOW}æŒ‰å›è½¦é”®ç»§ç»­...{Style.RESET_ALL}")
            return
        
        print(f"\n{Fore.CYAN}é€‰æ‹©è¦å¤‡ä»½çš„æ–‡ä»¶:{Style.RESET_ALL}")
        for i, file in enumerate(checkpoint_files, 1):
            print(f"{Fore.WHITE}{i}.{Style.RESET_ALL} {file}")
        
        try:
            choice = int(input(f"\n{Fore.CYAN}è¯·é€‰æ‹©æ–‡ä»¶ (1-{len(checkpoint_files)}): {Style.RESET_ALL}"))
            if 1 <= choice <= len(checkpoint_files):
                source_file = checkpoint_files[choice-1]
                backup_name = f"{os.path.splitext(source_file)[0]}_backup.pth"
                
                import shutil
                shutil.copy2(
                    os.path.join('checkpoints', source_file),
                    os.path.join('checkpoints', backup_name)
                )
                print(f"{Fore.GREEN}âœ… å·²å¤‡ä»½ä¸º: {backup_name}{Style.RESET_ALL}")
            else:
                print(f"{Fore.RED}âŒ æ— æ•ˆé€‰æ‹©{Style.RESET_ALL}")
        except ValueError:
            print(f"{Fore.RED}âŒ è¯·è¾“å…¥æœ‰æ•ˆæ•°å­—{Style.RESET_ALL}")
        except Exception as e:
            print(f"{Fore.RED}âŒ å¤‡ä»½å¤±è´¥: {e}{Style.RESET_ALL}")
        
        input(f"\n{Fore.YELLOW}æŒ‰å›è½¦é”®ç»§ç»­...{Style.RESET_ALL}")

    def performance_monitoring_menu(self):
        """æ€§èƒ½ç›‘æ§èœå•"""
        print(f"{Fore.CYAN}ğŸ“Š æ€§èƒ½ç›‘æ§{Style.RESET_ALL}")
        print(f"{Fore.CYAN}{'='*60}{Style.RESET_ALL}")
        
        # æ˜¾ç¤ºGPUä¿¡æ¯
        self.print_gpu_info()
        
        # æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯
        import psutil
        print(f"\n{Fore.CYAN}ğŸ’» ç³»ç»Ÿä¿¡æ¯:{Style.RESET_ALL}")
        print(f"  CPUä½¿ç”¨ç‡: {psutil.cpu_percent():.1f}%")
        print(f"  å†…å­˜ä½¿ç”¨: {psutil.virtual_memory().percent:.1f}%")
        print(f"  å¯ç”¨å†…å­˜: {psutil.virtual_memory().available / (1024**3):.1f}GB")
        
        # æ˜¾ç¤ºç£ç›˜ä¿¡æ¯
        disk_usage = psutil.disk_usage('.')
        print(f"  ç£ç›˜ä½¿ç”¨: {disk_usage.percent:.1f}%")
        print(f"  å¯ç”¨ç©ºé—´: {disk_usage.free / (1024**3):.1f}GB")
        
        input(f"\n{Fore.YELLOW}æŒ‰å›è½¦é”®ç»§ç»­...{Style.RESET_ALL}")

    def _smart_adjust_features(self, checkpoint_path, old_features, new_features):
        """
        æ™ºèƒ½ç‰¹å¾æ•°è°ƒæ•´ - é›†æˆåˆ°æ§åˆ¶å°è®­ç»ƒå™¨ä¸­
        æ”¯æŒä»»æ„ç‰¹å¾æ•°çš„è°ƒæ•´ï¼Œå¦‚70->72, 64->72ç­‰
        """
        try:
            # 1. æ£€æµ‹å½“å‰ç‰¹å¾æ•°
            detected_config = self._detect_checkpoint_config(checkpoint_path)
            if not detected_config:
                return False, "æ— æ³•æ£€æµ‹æ£€æŸ¥ç‚¹é…ç½®"
            
            old_features = detected_config['num_features']
            print(f"{Fore.CYAN}ğŸš€ å¼€å§‹æ™ºèƒ½ç‰¹å¾æ•°è°ƒæ•´: {old_features} -> {new_features}{Style.RESET_ALL}")
            
            # 2. åŠ è½½åŸå§‹æ£€æŸ¥ç‚¹
            checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)
            old_state_dict = checkpoint['generator_state_dict']
            
            # 3. åˆ›å»ºæ–°æ¨¡å‹ä»¥è·å–ç›®æ ‡çŠ¶æ€å­—å…¸ç»“æ„
            from src.models.esrgan import LiteRealESRGAN
            new_model = LiteRealESRGAN(
                num_blocks=6,  # ä½¿ç”¨é»˜è®¤å€¼è€Œä¸æ˜¯self.config
                num_features=new_features
            )
            new_state_dict = new_model.state_dict()
            
            # 4. æ™ºèƒ½æƒé‡è°ƒæ•´
            print(f"{Fore.CYAN}ğŸ”§ å¼€å§‹æƒé‡è°ƒæ•´...{Style.RESET_ALL}")
            adjusted_state_dict = self._adjust_features_weights(old_state_dict, new_state_dict, old_features, new_features)
            
            # 5. æ›´æ–°æ£€æŸ¥ç‚¹
            checkpoint['generator_state_dict'] = adjusted_state_dict
            
            # ğŸ”¥ é‡è¦ï¼šç§»é™¤ä¼˜åŒ–å™¨çŠ¶æ€ä»¥é¿å…ç»´åº¦ä¸åŒ¹é…
            optimizer_removed = False
            if 'g_optimizer_state_dict' in checkpoint:
                del checkpoint['g_optimizer_state_dict']
                optimizer_removed = True
                print(f"{Fore.YELLOW}ğŸ§¹ å·²æ¸…ç†ç”Ÿæˆå™¨ä¼˜åŒ–å™¨çŠ¶æ€(é¿å…ç»´åº¦ä¸åŒ¹é…){Style.RESET_ALL}")
            
            if 'd_optimizer_state_dict' in checkpoint:
                del checkpoint['d_optimizer_state_dict']
                optimizer_removed = True
                print(f"{Fore.YELLOW}ğŸ§¹ å·²æ¸…ç†åˆ¤åˆ«å™¨ä¼˜åŒ–å™¨çŠ¶æ€(é¿å…ç»´åº¦ä¸åŒ¹é…){Style.RESET_ALL}")
            
            if 'g_scheduler_state_dict' in checkpoint:
                del checkpoint['g_scheduler_state_dict']
                print(f"{Fore.YELLOW}ğŸ§¹ å·²æ¸…ç†ç”Ÿæˆå™¨è°ƒåº¦å™¨çŠ¶æ€{Style.RESET_ALL}")
            
            if 'd_scheduler_state_dict' in checkpoint:
                del checkpoint['d_scheduler_state_dict']
                print(f"{Fore.YELLOW}ğŸ§¹ å·²æ¸…ç†åˆ¤åˆ«å™¨è°ƒåº¦å™¨çŠ¶æ€{Style.RESET_ALL}")
            
            # ä¿ç•™è®­ç»ƒå…ƒæ•°æ®
            epoch = checkpoint.get('epoch', 0)
            best_psnr = checkpoint.get('best_psnr', 0.0)
            print(f"âœ… ä¿ç•™è®­ç»ƒå…ƒæ•°æ®: epoch={epoch}, best_psnr={best_psnr:.4f}")
            
            # 6. ç”Ÿæˆè¾“å‡ºè·¯å¾„
            base_name = os.path.splitext(os.path.basename(checkpoint_path))[0]
            output_path = os.path.join(
                os.path.dirname(checkpoint_path),
                f"{base_name}_features_{new_features}.pth"
            )
            
            # 7. ä¿å­˜è°ƒæ•´åçš„æ£€æŸ¥ç‚¹
            torch.save(checkpoint, output_path)
            print(f"{Fore.GREEN}âœ… è°ƒæ•´å®Œæˆ! æ–°æ£€æŸ¥ç‚¹ä¿å­˜è‡³: {os.path.basename(output_path)}{Style.RESET_ALL}")
            
            # 8. éªŒè¯è°ƒæ•´ç»“æœ
            self._verify_feature_adjustment(output_path, new_features)
            
            # 9. æ ¹æ®ç‰¹å¾æ•°å˜åŒ–è°ƒæ•´å­¦ä¹ ç‡
            if 'learning_rate' in self.config['training']:
                feature_ratio = new_features / old_features
                if feature_ratio > 1.2:  # ç‰¹å¾æ•°å¢åŠ è¶…è¿‡20%
                    suggested_lr = self.config['training']['learning_rate'] * 0.8
                    print(f"{Fore.CYAN}ğŸ’¡ ç‰¹å¾æ•°å¤§å¹…å¢åŠ ï¼Œå»ºè®®é™ä½å­¦ä¹ ç‡: {self.config['training']['learning_rate']:.6f} -> {suggested_lr:.6f}{Style.RESET_ALL}")
                    self.config['training']['learning_rate'] = suggested_lr
                    print(f"{Fore.GREEN}âœ… å­¦ä¹ ç‡å·²è°ƒæ•´ä¸º: {suggested_lr}{Style.RESET_ALL}")
            
            return True, output_path
            
        except Exception as e:
            print(f"{Fore.RED}âŒ æ™ºèƒ½ç‰¹å¾æ•°è°ƒæ•´å¤±è´¥: {str(e)}{Style.RESET_ALL}")
            import traceback
            traceback.print_exc()
            return False, str(e)

    

    
    def _verify_feature_adjustment(self, checkpoint_path, expected_features):
        """
        éªŒè¯ç‰¹å¾æ•°è°ƒæ•´ç»“æœ
        """
        try:
            print(f"{Fore.CYAN}ğŸ” éªŒè¯è°ƒæ•´ç»“æœ...{Style.RESET_ALL}")
            
            # 1. æ£€æµ‹ç‰¹å¾æ•°
            detected_config = self._detect_checkpoint_config(checkpoint_path)
            if detected_config and detected_config['num_features'] == expected_features:
                print(f"{Fore.GREEN}âœ… ç‰¹å¾æ•°éªŒè¯é€šè¿‡: {expected_features}{Style.RESET_ALL}")
            else:
                print(f"{Fore.RED}âŒ ç‰¹å¾æ•°éªŒè¯å¤±è´¥{Style.RESET_ALL}")
                return False
            
            # 2. æµ‹è¯•æ¨¡å‹åŠ è½½
            from src.models.esrgan import LiteRealESRGAN
            model = LiteRealESRGAN(
                num_blocks=6,  # ä½¿ç”¨é»˜è®¤å€¼è€Œä¸æ˜¯self.config
                num_features=expected_features
            )
            
            checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)
            model.load_state_dict(checkpoint['generator_state_dict'])
            print(f"{Fore.GREEN}âœ… æ¨¡å‹åŠ è½½éªŒè¯é€šè¿‡{Style.RESET_ALL}")
            
            # 3. æµ‹è¯•å‰å‘ä¼ æ’­
            model.eval()
            test_input = torch.randn(1, 3, 64, 64)
            with torch.no_grad():
                output = model(test_input)
            print(f"{Fore.GREEN}âœ… å‰å‘ä¼ æ’­éªŒè¯é€šè¿‡: {test_input.shape} -> {output.shape}{Style.RESET_ALL}")
            
            return True
            
        except Exception as e:
            print(f"{Fore.RED}âŒ éªŒè¯å¤±è´¥: {str(e)}{Style.RESET_ALL}")
            return False


if __name__ == "__main__":
    try:
        trainer = ConsoleTrainer()
        trainer.run()
    except KeyboardInterrupt:
        print(f"\n{Fore.YELLOW}âš ï¸  ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­{Style.RESET_ALL}")
    except Exception as e:
        print(f"\n{Fore.RED}âŒ ç¨‹åºè¿è¡Œå‡ºé”™: {e}{Style.RESET_ALL}")
        import traceback
        traceback.print_exc()